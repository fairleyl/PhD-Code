{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0c967fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions\n",
    "using Random\n",
    "using Plots\n",
    "using PyPlot\n",
    "using StatsBase\n",
    "using StatsPlots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b1ef523",
   "metadata": {},
   "source": [
    "# Problem-Suite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebbc7791",
   "metadata": {},
   "source": [
    "Problem-Suite is a large structured notebook containing all of the functions created so far for this project.\n",
    "\n",
    "Sections:\n",
    "\n",
    "-[Miscellaneous Functions](#Miscellaneous-Functions)\n",
    "\n",
    "-[Pre-requisite functions for uniformised AVI](#Pre-requisite-functions-for-uniformised-AVI)\n",
    "\n",
    "-[Uniformised AVI functions](#Uniformised-AVI-functions)\n",
    "\n",
    "-[Pre-requisite functions for SMARVI](#Pre-requisite-functions-for-SMARVI)\n",
    "\n",
    "-[SMARVI Functions](#SMARVI-Functions)\n",
    "\n",
    "-[Pre-requisite Functions for Exact DP on Homogeneous Problems](#Pre-requisite-Functions-for-Exact-DP-on-Homogeneous-Problems)\n",
    "\n",
    "-[Exact DP on Homogeneous Problems (RVIA and PE/PI)](#Exact-DP-for-Homogeneous-problem)\n",
    "\n",
    "-[Pre-requisite Functions for Exact DP on Inhomogeneous Problems](#Pre-requisite-Functions-for-Exact-DP-on-Inhomogeneous-Problems)\n",
    "\n",
    "-[Exact DP on Inhomogeneous Problems (RVIA and PE/PI)](#Exact-DP-for-Inhomogeneous-Problem-(using-exact-h-or-VFA))\n",
    "\n",
    "-[Evaluation via simulation](#Evaluation-via-simulation)\n",
    "\n",
    "-[APE on Fully Active Policy](#APE-on-Fully-Active-Policy)\n",
    "\n",
    "-[SMARPE](#SMARPE)\n",
    "\n",
    "-[Tabular SMARVI and gEval](#tabular-smarvi-and-geval)\n",
    "\n",
    "-[SMART Functions](#SMART-Functions)\n",
    "\n",
    "-[SMARVI - New VFA](#SMARVI---New-VFA)\n",
    "\n",
    "-[Tests](#Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12fe12",
   "metadata": {},
   "source": [
    "# Miscellaneous Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2556d9f",
   "metadata": {},
   "source": [
    "-Functions for enumerating state and action spaces\n",
    "\n",
    "-Functions for calculating flows given a state or state-action pair\n",
    "\n",
    "-Function for evaluating a VFA at a given state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "26a0da98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arrayToString (generic function with 1 method)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#produce an array of array representations of all possible states\n",
    "function enumerateStates(N::Int64)\n",
    "    if N==1\n",
    "        return [[1],[2],[3]]\n",
    "    end\n",
    "    \n",
    "    output = []\n",
    "    lower = enumerateStates(N-1)\n",
    "    for s in lower\n",
    "        new1 = append!([1],s)\n",
    "        new2 = append!([2],s)\n",
    "        new3 = append!([3],s)\n",
    "        append!(output,[new1])\n",
    "        append!(output,[new2])\n",
    "        append!(output,[new3])\n",
    "    end\n",
    "    \n",
    "    return output\n",
    "end\n",
    "\n",
    "#produce an array of array representations of all possible actions\n",
    "function enumerateActions(N::Int64)\n",
    "    if N==1\n",
    "        return [[0],[1]]\n",
    "    end\n",
    "    \n",
    "    output = []\n",
    "    lower = enumerateActions(N-1)\n",
    "    for a in lower\n",
    "        new1 = append!([0],a)\n",
    "        new2 = append!([1],a)\n",
    "        append!(output,[new1])\n",
    "        append!(output,[new2])\n",
    "    end\n",
    "    \n",
    "    return output\n",
    "end    \n",
    "\n",
    "#produce array of array representations of all restricted, or single-repair, actions\n",
    "function enumerateRestrictedActions(N::Int64)\n",
    "    if N==1\n",
    "        return [[0],[1]]\n",
    "    end\n",
    "    \n",
    "    output = [zeros(Int64,N)]\n",
    "    for i in 1:N\n",
    "        temp = zeros(N)\n",
    "        temp[i] = 1\n",
    "        append!(output,[temp])\n",
    "    end\n",
    "    \n",
    "    return output\n",
    "end\n",
    "\n",
    "#convert all array elements to string, then concatanate all elements (DEPRECATED AS DICTS CAN TAKE ARRAYS AS KEYS)\n",
    "function arrayToString(x)\n",
    "    return join(string.(x))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "57ba543e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculateFlows (generic function with 2 methods)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function for calculating the flows given a state\n",
    "function calculateFlows(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    #update flows\n",
    "    flows = zeros(N)\n",
    "    healthy = sum(i == 1 for i in s)\n",
    "    \n",
    "    #if no links are healthy, return \n",
    "    if healthy == 0\n",
    "        return flows, c1\n",
    "    end\n",
    "    \n",
    "    #otherwise, find best route, and return\n",
    "    bestCost = maximum(c0) + 1\n",
    "    usedLink = 0\n",
    "    for k in 1:N\n",
    "        if s[k] == 1 && c0[k] < bestCost\n",
    "            bestCost = c0[k]\n",
    "            usedLink = k\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[usedLink] = beta\n",
    "    \n",
    "    return flows, bestCost\n",
    "end\n",
    "\n",
    "#function for calculating the flows given a state-action pair\n",
    "function calculateFlows(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    sPrime = s - a\n",
    "    return calculateFlows(sPrime,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "127d3f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v (generic function with 4 methods)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate a VFA at a given state\n",
    "function v(s::Vector{Int64}, params::Vector{Float64}, features::Vector{Function})\n",
    "    numFeatures = length(features)\n",
    "    return params[1] + sum(params[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "960bf4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v (generic function with 4 methods)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version of v that takes flows for the features\n",
    "function v(s::Vector{Int64}, flows::Vector{Float64}, params::Vector{Float64}, features::Vector{Function})\n",
    "    N = length(params)\n",
    "    return params[1] + sum(params[i]*features[i-1](s, flows) for i in 2:N)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b05d0fc",
   "metadata": {},
   "source": [
    "# Pre-requisite functions for uniformised AVI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c56072f",
   "metadata": {},
   "source": [
    "This section contains functions used within the AVI algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "476755cd",
   "metadata": {},
   "source": [
    "Given a state-action pair, return the next random pre-decision state, the instant cost, and the updated flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1d157b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updateStateAndFlowsUnif (generic function with 1 method)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function updateStateAndFlowsUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    #observe exogenous information\n",
    "    w = rand(Uniform(0, 1))\n",
    "    \n",
    "    #interpret exog info: is it a demand deg, rare deg, or completed repair \n",
    "    found = false\n",
    "    runningTotal = 0\n",
    "    \n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        if runningTotal <= w <= runningTotal + flows[k]*alpha_d[k]*del\n",
    "            found = true\n",
    "            sPrime[k] = 3\n",
    "            #println(\"Demand Deg at \"*string.(k))\n",
    "            break\n",
    "        end\n",
    "        runningTotal = runningTotal + flows[k]*alpha_d[k]*del\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    if found == false\n",
    "        for k in 1:N\n",
    "            if runningTotal <= w <= runningTotal + alpha_r[k]*del\n",
    "                found = true\n",
    "                sPrime[k] = 3\n",
    "                #println(\"Rare Deg at \"*string.(k))\n",
    "                break\n",
    "            end\n",
    "            runningTotal = runningTotal + alpha_r[k]*del\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if found == false && repair > 0\n",
    "        if runningTotal <= w <= runningTotal + tau(repair)*del\n",
    "            found = true\n",
    "            #find all repairing links\n",
    "            repairing = []\n",
    "            for k in 1:N\n",
    "                if sPrime[k] == 2\n",
    "                    append!(repairing,[k])\n",
    "                end\n",
    "            end\n",
    "            repaired = sample(repairing)\n",
    "            sPrime[repaired] = 1\n",
    "            #println(\"Repair completed at \"*string.(repaired))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if found == false\n",
    "        #println(\"No Event\")\n",
    "    end\n",
    "    \n",
    "    #update flows\n",
    "    flowUpdate = calculateFlows(sPrime,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    newFlows = flowUpdate[1]\n",
    "    bestCost = flowUpdate[2]\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    \n",
    "    return sPrime, (beta*bestCost + sum(r[k]*(sPrime[k]==2) for k in 1:N))*del, newFlows\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "836f070e",
   "metadata": {},
   "source": [
    "Given a state action pair, return the instant cost over the delta timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "685eb320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instantCostUnif (generic function with 1 method)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instant cost over the timestep\n",
    "function instantCostUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(sPrime[i] == 1 for i in 1:N)\n",
    "    repair = sum(sPrime[i] == 2 for i in 1:N)\n",
    "    damaged = sum(sPrime[i] == 3 for i in 1:N)\n",
    "    \n",
    "    #update flows\n",
    "    flowUpdate = calculateFlows(sPrime,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    newFlows = flowUpdate[1]\n",
    "    bestCost = flowUpdate[2]\n",
    "    \n",
    "    return (beta*bestCost + sum(r[k]*(sPrime[k]==2) for k in 1:N))*del\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9603d5cd",
   "metadata": {},
   "source": [
    "Given a state-action pair and a VFA, calculate the expected value of the value function after one timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3f0a307f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueUnif (generic function with 2 methods)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculates E(h(s')) given a state-action pair, and a VFA for h. Also used in Exact PE/PI when using a VFA\n",
    "#One version takes flows as an argument, the other calculates the flows\n",
    "function expectedNextValueUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    runningTotal = 0.0\n",
    "    runningTotalProb = 0.0\n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*v(sNext, vParams, features)\n",
    "        runningTotalProb += flows[k]*alpha_d[k]*del\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            runningTotal += alpha_r[k]*del*v(sNext, vParams, features)\n",
    "            runningTotalProb += alpha_r[k]*del\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                runningTotal += (tau(repair)/repair)*del*v(sNext, vParams, features)\n",
    "                runningTotalProb += (tau(repair)/repair)*del\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal + (1 - runningTotalProb)*v(sPrime, vParams, features)\n",
    "end  \n",
    "\n",
    "function expectedNextValueUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, vParams, features)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    flows = calculateFlows(sPrime,N,alpha_d, alpha_r, beta, tau, c0, c1, r)[1]\n",
    "    runningTotal = 0.0\n",
    "    runningTotalProb = 0.0\n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*v(sNext, vParams, features)\n",
    "        runningTotalProb += flows[k]*alpha_d[k]*del\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            runningTotal += alpha_r[k]*del*v(sNext, vParams, features)\n",
    "            runningTotalProb += alpha_r[k]*del\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                runningTotal += (tau(repair)/repair)*del*v(sNext, vParams, features)\n",
    "                runningTotalProb += (tau(repair)/repair)*del\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal + (1 - runningTotalProb)*v(sPrime, vParams, features)\n",
    "end  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3920172",
   "metadata": {},
   "source": [
    "# Uniformised AVI functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80cbe1e5",
   "metadata": {},
   "source": [
    "Algorithms that perform RAVI on the uniformised version of the problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5310d49c",
   "metadata": {},
   "source": [
    "Given some parallel link problem and VFA architecture, perform RAVI, approximating E(h(s')) for update targets using just h(s'), where s' is the next simulated state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f83714d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aviApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in uniformised setting, approximating E(h(s')) for update targets using just h(s'), where s' is the next simulated state\n",
    "function aviApprox(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; delScale = 1.0, printProgress = false, modCounter = 100000, forceActive = false)\n",
    "    #initialise\n",
    "    del = 1.0/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        optV = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features) - g\n",
    "        \n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #Fix random link if optA is passive for [3,3,...,3]\n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64, N)\n",
    "            optA[1] = 1\n",
    "            optV = v(s-optA, vParams, features)\n",
    "            \n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        c = instantCostUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "        bestV = c + v(sPrime, vParams, features) - v(s0, vParams,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = v(s, vParams, features)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        c = result[2]\n",
    "        s = sPrime\n",
    "        flows = result[3]\n",
    "        g += (1/n)*(c - g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "718d21d7",
   "metadata": {},
   "source": [
    "Given some parallel link problem and VFA architecture, perform RAVI, using a full expectation for update targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6fb36c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aviFull (generic function with 1 method)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in uniformised setting, approximating E(h(s')) using all possible transitions\n",
    "function aviFull(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; delScale = 1.0, printProgress = false, modCounter = 100000, forceActive = false)\n",
    "    #initialise\n",
    "    del = 1.0/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        optV = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features) - g\n",
    "        \n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #Fix random link if optA is passive for [3,3,...,3]\n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64, N)\n",
    "            optA[1] = 1\n",
    "            optV = v(s-optA, vParams, features)\n",
    "            \n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        c = instantCostUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "        bestV = c + expectedNextValueUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features) - v(s0, vParams,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = v(s, vParams, features)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        c = result[2]\n",
    "        s = sPrime\n",
    "        flows = result[3]\n",
    "        g += (1/n)*(c - g)\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d76fa41",
   "metadata": {},
   "source": [
    "Similar to above, but only uses the Binary Action Space (BAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5ebdac30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aviUnifBAS (generic function with 1 method)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI with BAS in uniformised setting, approximating E(h(s')) using all possible transitions\n",
    "function aviUnifBAS(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; delScale = 1.0, printProgress = false, modCounter = 100000, forceActive = false)\n",
    "    #initialise\n",
    "    del = 1.0/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        vs0 = v(s0, vParams, features)\n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        optV = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features) - vs0\n",
    "        \n",
    "        testA = faAction(s)\n",
    "        testV = instantCostUnif(s,testA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s,testA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features) - vs0\n",
    "        if testV <= optV\n",
    "            optV = testV\n",
    "            optA = testA\n",
    "        end\n",
    "        \n",
    "        #Fix random link if optA is passive for [3,3,...,3]\n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64, N)\n",
    "            optA = testA\n",
    "            optV = testV\n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = v(s, vParams, features)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        c = result[2]\n",
    "        s = sPrime\n",
    "        flows = result[3]\n",
    "        g += (1/n)*(c - g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f587fd5b",
   "metadata": {},
   "source": [
    "# Pre-requisite functions for SMARVI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2008a2c4",
   "metadata": {},
   "source": [
    "Helper functions for the SMARVI algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1f36cda",
   "metadata": {},
   "source": [
    "Given a state-action pair and pre-calculated flows, return the expected sojourn time for the state-action pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1506350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sojournTime (generic function with 1 method)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the expected sojourn time of a state-action pair\n",
    "function sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    s = s - a\n",
    "    if s == fill(3,N)\n",
    "        return 1/(beta*sum(alpha_d) + sum(alpha_r) + tau(N))\n",
    "    end\n",
    "    \n",
    "    numRep = sum(i == 2 for i in s)\n",
    "    cumulativeRate = 0.0\n",
    "    for i in 1:N\n",
    "        if s[i] == 1\n",
    "            cumulativeRate += flows[i]*alpha_d[i] + alpha_r[i]\n",
    "        elseif s[i] == 2\n",
    "            cumulativeRate += alpha_r[i] + tau(numRep)/numRep\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return 1/cumulativeRate\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb2c6d2b",
   "metadata": {},
   "source": [
    "Given a state-action pair and flows, calculate the expected cost accumulated until a transition occurs, or calculate the simulated cost accumulated over a simulated time del."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "66c5307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instantCostCont (generic function with 1 method)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the expected cost accumulated until a transition \n",
    "function instantCostCont(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows; del = 0)\n",
    "    if del == 0\n",
    "        del = sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    end\n",
    "    \n",
    "    return instantCostUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ecc13f2",
   "metadata": {},
   "source": [
    "Given a state-action pair, return the next random pre-decision state, the cost accumulated over the sojourn time, and the updated flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75587424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updateStateAndFlowsCont (generic function with 1 method)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Given a state-action pair, return the next random pre-decision state, the cost accumulated over the sojourn time, and the updated flows\n",
    "function updateStateAndFlowsCont(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "    del = sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    actualTime = rand(Exponential(del))\n",
    "    result = updateStateAndFlowsUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "    return result[1], instantCostCont(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows; del = actualTime), result[3], actualTime\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae4efc43",
   "metadata": {},
   "source": [
    "Given a state-action pair, precalculated flows, and a VFA, return the expected value of the VFA after a transition has occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "60cda4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueCont (generic function with 1 method)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculates E(h(s')) given a state-action pair, and a VFA for h\n",
    "function expectedNextValueCont(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features)\n",
    "    del = sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    #different treatment for all-damaged state\n",
    "    if sPrime == fill(3,N)\n",
    "        return v(sPrime,vParams,features)\n",
    "    end\n",
    "    \n",
    "    runningTotal = 0\n",
    "    \n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*v(sNext, vParams, features)\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            runningTotal += alpha_r[k]*del*v(sNext, vParams, features)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                runningTotal += (tau(repair)/repair)*del*v(sNext, vParams, features)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal\n",
    "end   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc5b77a7",
   "metadata": {},
   "source": [
    "Similar to above, but assumes the features of the VFA take precalcuated flows as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "488f16a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueContFlows (generic function with 1 method)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculates E(h(s')) given a state-action pair, and a VFA for h\n",
    "#Assumes the VFA is constructed with features taking arguments (s, flows), so flows are precalculated\n",
    "function expectedNextValueContFlows(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features)\n",
    "    del = sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    #different treatment for all-damaged state\n",
    "    if sPrime == fill(3,N)\n",
    "        return v(sPrime, flows, vParams,features)\n",
    "    end\n",
    "    \n",
    "    runningTotal = 0\n",
    "    \n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        flowsNext = calculateFlows(sNext,N,alpha_d, alpha_r, beta, tau, c0, c1, r)[1]\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*v(sNext, flowsNext, vParams, features)\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            flowsNext = calculateFlows(sNext,N,alpha_d, alpha_r, beta, tau, c0, c1, r)[1]\n",
    "            runningTotal += alpha_r[k]*del*v(sNext, flowsNext, vParams, features)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                flowsNext = calculateFlows(sNext,N,alpha_d, alpha_r, beta, tau, c0, c1, r)[1]\n",
    "                runningTotal += (tau(repair)/repair)*del*v(sNext, flowsNext, vParams, features)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal\n",
    "end   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a2e614d",
   "metadata": {},
   "source": [
    "Given a state, flows, and a VFA-g pair, return the optimal action and associated V value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "97b01347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarActionAndVFromVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smarActionAndVFromVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, vParams, features, g)\n",
    "    #formulate optimal action and calculate optV\n",
    "    optA = zeros(Int64,N)\n",
    "    t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t\n",
    "    \n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64, N)\n",
    "            a[i] = 1\n",
    "            testV = v(s-a, vParams, features)\n",
    "            if testV <= optV\n",
    "                optV = testV\n",
    "                optA = a\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #If wanted, force a repair if optA is passive for [3,3,...,3]\n",
    "    if s == fill(3,N) && optA == zeros(Int64, N)\n",
    "        optA = zeros(Int64,N)\n",
    "        optA[1] = 1\n",
    "        optV = v(s-optA, vParams, features)\n",
    "        \n",
    "        for i in 2:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                testV = v(s-a, vParams, features)\n",
    "                if testV <= optV\n",
    "                    optV = testV\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return optA, optV\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f824e",
   "metadata": {},
   "source": [
    "# SMARVI Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dbccab0",
   "metadata": {},
   "source": [
    "Variety of functions which perform the SMARVI algorithm, with different additional features.\n",
    "For clarity, the \"state-trace\" is a method which collects a sequence of states connected by instantaneous actions together, and ensures they all have the same update target. For example, if in state s we take action a!=0, and in the resulting state s+a we take action 0, both s and s+a will have update target (c + E(V(s')) - gt)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39c05112",
   "metadata": {},
   "source": [
    "Given a problem and a VFA architecture, perform SMARVI, with no e-greedy action selection or state trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ea289cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarvi (generic function with 1 method)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs SMARVI\n",
    "function smarvi(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action and calculate optV\n",
    "        optAandV = smarActionAndVFromVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, vParams, features, g)\n",
    "        \n",
    "        bestA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        if bestA == zeros(Int64,N)\n",
    "            bestV = optV - v(s0, vParams,features)\n",
    "        else\n",
    "            bestV = optV - v(s0, vParams,features)\n",
    "        end \n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5c6e48e",
   "metadata": {},
   "source": [
    "Perform SMARVI with a state trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2005234a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviST (generic function with 1 method)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in continuous time setting, approximating E(h(s')) as h(s') where s' is the next simulated state\n",
    "function smarviST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    \n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    stateTrace = []\n",
    "    actionFlag = false\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        #update stateTrace\n",
    "        append!(stateTrace, [s])\n",
    "        \n",
    "        #formulate optimal action and calculate optV\n",
    "        optAandV = smarActionAndVFromVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, vParams, features, g)\n",
    "        \n",
    "        bestA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #if optimal action is passive, update VFA for all states in the stateTrace, and simulate the next state\n",
    "        if bestA == zeros(Int64, N)\n",
    "            \n",
    "            #find simulated next state\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "        \n",
    "            bestV = optV - v(s0, vParams, features)\n",
    "            \n",
    "            #update VFA\n",
    "            traceLength = length(stateTrace)\n",
    "            for sTrace in stateTrace\n",
    "                currentEst = v(sTrace, vParams, features)\n",
    "                grad = append!([1.0],[features[i](sTrace) for i in 1:numFeatures])\n",
    "                vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "                append!(paramHist,[vParams])\n",
    "            end\n",
    "            \n",
    "            #reset stateTrace\n",
    "            stateTrace = []\n",
    "            \n",
    "            #update flows and average\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "            \n",
    "        #if some action is optimal, simply update the state\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58458323",
   "metadata": {},
   "source": [
    "Performs SMARVI with a given fixed value of g0 for action selection. This prevents bad initial estimates of g from severely impacting the algorithm, but restricts the policy space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1840b7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarvi_g0 (generic function with 1 method)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in the continuous time setting, approximating E(h(s')) using all possible transitions, and controlling action selection using some fixed g0\n",
    "function smarvi_g0(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features, g0; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optAandV = smarActionAndVFromVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, vParams, features, g0)\n",
    "        \n",
    "        bestA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        if bestA == zeros(Int64,N)\n",
    "            bestV = optV + g0*t - g*t - v(s0, vParams,features)\n",
    "        else\n",
    "            bestV = v(s - bestA, vParams, features) - v(s0, vParams,features)\n",
    "        end \n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25861988",
   "metadata": {},
   "source": [
    "Similar to regular SMARVI, but only using the BAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "318f0267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviBAS (generic function with 1 method)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI with BAS in the continuous time setting, approximating E(h(s')) using all possible transitions\n",
    "function smarviBAS(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000, forceActive = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        tPassive = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*tPassive\n",
    "        \n",
    "        testA = faAction(s)\n",
    "        tActive = sojournTime(s, testA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        testV = instantCostCont(s,testA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,testA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*tActive\n",
    "        \n",
    "        if testV <= optV\n",
    "            optV = testV\n",
    "            optA = testA\n",
    "        end\n",
    "        \n",
    "        #Ignore passive action for broken network\n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64, N)\n",
    "            optV = testV\n",
    "            optA = testA\n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV - v(s0, vParams,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d439d00",
   "metadata": {},
   "source": [
    "Similar to regular SMARVI, but where flows are assumes to be passed to the VFA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0daaef33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviFlows (generic function with 1 method)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version of smarvi where flows are passed to features\n",
    "function smarviFlows(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    flows0 = copy(flows)\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContFlows(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t\n",
    "        \n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                \n",
    "                if vParams[1] + sum(vParams[i+1]*features[i](s-a, flows) for i in 1:numFeatures) <= optV\n",
    "                    optV = vParams[1] + sum(vParams[i+1]*features[i](s-a, flows) for i in 1:numFeatures)\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #Fix random link if optA is passive for [3,3,...,3]\n",
    "        if s == fill(3,N) && optA == zeros(Int64, N)\n",
    "            optA[1] = 1\n",
    "            optV = v(s-optA, flows, vParams, features)\n",
    "            \n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    testV = v(s-a, flows, vParams, features)\n",
    "                    if testV <= optV\n",
    "                        optV = testV\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        if bestA == zeros(Int64,N)\n",
    "            bestV = optV - v(s0, flows0, vParams,features)\n",
    "        else\n",
    "            bestV = optV - v(s0, flows0, vParams,features)\n",
    "        end \n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s, flows) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s, flows) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8365b78",
   "metadata": {},
   "source": [
    "## e-greedy SMARVI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f3cba33",
   "metadata": {},
   "source": [
    "Helper functions and main algorithm for e-greedy SMARVI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fd55c88",
   "metadata": {},
   "source": [
    "Samples a random feasible action for a state s of length N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d2fd2e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "randomActionAllDamaged (generic function with 1 method)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate random action\n",
    "function randomAction(s,N)\n",
    "    #deal with all-damaged case\n",
    "    if s == fill(3,N)\n",
    "        return randomActionAllDamaged(N)\n",
    "    end\n",
    "\n",
    "    damaged = [0]\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            append!(damaged, [i])\n",
    "        end\n",
    "    end\n",
    "            \n",
    "    choice = sample(damaged)\n",
    "    optA = zeros(Int64, N)\n",
    "    if choice == 0\n",
    "        return optA\n",
    "    else\n",
    "        optA[choice] = 1\n",
    "        return optA\n",
    "    end\n",
    "end\n",
    "\n",
    "#calculate random action for [3,3...,3] state\n",
    "function randomActionAllDamaged(N)\n",
    "    choice = sample(1:N)\n",
    "    a = zeros(Int64, N)\n",
    "    a[choice] = 1\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48f72466",
   "metadata": {},
   "source": [
    "Performs an e-greedy version of SMARVI, with e_n = b/b+n for some given b. Allows SMARVI to perform some exploratory actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7a38d016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarvi_epsGreedy (generic function with 1 method)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in the continuous time setting, approximating E(h(s')) using all possible transitions\n",
    "#actions are choosen via e-greedy action selection, where a random action is chosen with probability b/b+n\n",
    "function smarvi_epsGreedy(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; b = 1.0, printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate e-greedy action\n",
    "        if rand(Uniform(0,1)) <= b/(b + n) \n",
    "            optA = randomAction(s,N)\n",
    "            if optA == zeros(Int64, N)\n",
    "                t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "                optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t\n",
    "            else\n",
    "                optV = v(s-optA, vParams, features)\n",
    "            end\n",
    "        else                \n",
    "            optAandV = smarActionAndVFromVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, vParams, features, g)\n",
    "        \n",
    "            optA = optAandV[1]\n",
    "            optV = optAandV[2]\n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV - v(s0, vParams,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eaa235",
   "metadata": {},
   "source": [
    "# Pre-requisite Functions for Exact DP on Homogeneous Problems "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7b7c104",
   "metadata": {},
   "source": [
    "Helper functions for Homogeneous Exact DP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1801225",
   "metadata": {},
   "source": [
    "Calculates instant cost for homogeneous problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "22678b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instantCostHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instant cost function strictly for homogeneous problem\n",
    "function instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    #immediate change\n",
    "    i1Prime = i1 - a\n",
    "    i2Prime = i2 + a\n",
    "    \n",
    "    #if no links are healthy, return \n",
    "    if N - i1 - i2 == 0\n",
    "        return (beta*c1 + r*i2Prime)*del\n",
    "    end\n",
    "    \n",
    "    \n",
    "    return (beta*c0 + r*i2Prime)*del\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94e504b7",
   "metadata": {},
   "source": [
    "Given state (i_1, i_2) and action a, calculates the expected next value function after one timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a17eacf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates E(h(s')) from s,a strictly for a homogeneous problem\n",
    "function expectedNextValueHomog(i1,i2, h, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    #immediate change\n",
    "    i1Prime = i1 - a\n",
    "    i2Prime = i2 + a\n",
    "    thisH = h[i1+1,i2+1]\n",
    "    \n",
    "    #if all are damaged\n",
    "    if i1Prime == N\n",
    "        return thisH\n",
    "    end\n",
    "    \n",
    "    #if none are healthy\n",
    "    if N - i1 - i2 == 0\n",
    "        return thisH + tau(i2Prime)*del*(h[i1Prime+1,i2Prime-1+1] - thisH) + i2Prime*del*alpha_r*(h[i1Prime+1+1, i2Prime-1+1] - thisH)\n",
    "    end\n",
    "    \n",
    "    #if none are repairing\n",
    "    if i2Prime == 0\n",
    "        return thisH + (beta*alpha_d + (N - i1 - i2)*alpha_r)*del*(h[i1Prime+1+1,i2Prime+1] - thisH)\n",
    "    end\n",
    "    \n",
    "    return thisH + (beta*alpha_d + (N - i1 - i2)*alpha_r)*del*(h[i1Prime+1+1,i2Prime+1] - thisH) + i2Prime*alpha_r*del*(h[i1Prime+1+1,i2Prime-1+1] - thisH) + tau(i2Prime)*del*(h[i1Prime+1,i2Prime-1+1] - thisH)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68c7af12",
   "metadata": {},
   "source": [
    "Given state (i_1,i_2) and value function h, calculates and returns the best action for the state using full expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "beeb2b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates the exact PI action strictly for a homogeneous problem\n",
    "function piActionHomog(i1, i2, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del; forceActive = false)\n",
    "    if i1 == 0\n",
    "        return 0\n",
    "    end\n",
    "    \n",
    "    if i1 == N && forceActive\n",
    "        optA = 1\n",
    "        optH = instantCostHomog(i1,i2,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "        for a in 2:i1\n",
    "            testH = instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "            if testH <= optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "        return optA\n",
    "    end\n",
    "    \n",
    "    optA = 0\n",
    "    optH = instantCostHomog(i1,i2,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    for a in 1:i1\n",
    "        testH = instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "        if testH <= optH\n",
    "            optA = a\n",
    "            optH = testH\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71928099",
   "metadata": {},
   "source": [
    "Similar to above, but uses the approximation Q(s,a) = h(s+a) for a!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b58a1177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionHomogApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates the approx PI action based on instantaneous approximation, strictly for a homogeneous problem\n",
    "function piActionHomogApprox(i1, i2, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g; forceActive = false)\n",
    "    #deal with \"nothing damaged\" edge case\n",
    "    if i1 == 0\n",
    "        return 0\n",
    "    end\n",
    "    \n",
    "    #deal with \"everything damaged\" edge case\n",
    "    if i1 == N && forceActive\n",
    "        optA = 1\n",
    "        optH = h[i1-optA+1,i2+optA+1]\n",
    "        for a in 2:i1\n",
    "            testH = h[i1-a+1,i2+a+1]\n",
    "            if testH <= optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "        return optA\n",
    "    end\n",
    "    \n",
    "    optA = 0\n",
    "    optH = instantCostHomog(i1,i2,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) - g*del\n",
    "    for a in 1:i1\n",
    "        testH = h[i1-a+1,i2+a+1]\n",
    "        if testH <= optH\n",
    "            optA = a\n",
    "            optH = testH\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8ab05cf",
   "metadata": {},
   "source": [
    "Given h, constructs optimal policy using exact PI method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6335a065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates the exact PI policy strictly for a homogeneous problem\n",
    "function piPolicyHomog(h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del; forceActive = false)\n",
    "    policy = zeros(Int64, N+1, N+1)\n",
    "    for i1 in 0:N\n",
    "        for i2 in 0:(N - i1)\n",
    "            policy[i1+1,i2+1] = piActionHomog(i1, i2, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del; forceActive = forceActive)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34525984",
   "metadata": {},
   "source": [
    "Given h, constructs optimal policy using Q(s,a) = h(s,a) for a!=0 approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "404bfec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyHomogApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates the approx PI policy based on instantaneous approximation, strictly for a homogeneous problem\n",
    "function piPolicyHomogApprox(h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g; forceActive = false)\n",
    "    policy = zeros(Int64, N+1, N+1)\n",
    "    for i1 in 0:N\n",
    "        for i2 in 0:(N - i1)\n",
    "            policy[i1+1,i2+1] = piActionHomogApprox(i1, i2, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g; forceActive = forceActive)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "905b77bf",
   "metadata": {},
   "source": [
    "Constructs a h table from a VFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "42156f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hFromVFAHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function hFromVFAHomog(N, params, features)\n",
    "    #construct hIn table\n",
    "    hIn = zeros(Float64, N+1, N+1)\n",
    "    for i1 in 0:N\n",
    "        for i2 in 0:(N - i1)\n",
    "            s = fill(1,N)\n",
    "            if i1 > 0\n",
    "                for i in 1:i1\n",
    "                    s[i] = 3\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            if i2 > 0\n",
    "                for i in (i1+1):(i1+i2)\n",
    "                    s[i] = 2\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            hIn[i1+1,i2+1] = v(s, params, features)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return hIn\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c11abe",
   "metadata": {},
   "source": [
    "# Exact DP for Homogeneous problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fc32308",
   "metadata": {},
   "source": [
    "Actual DP algorithms "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99f7e6cf",
   "metadata": {},
   "source": [
    "Given a h table, performs PE on PI policy derived from h, and returns g, h, n (number of iterations), and the PI policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fc148338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a PI policy based on a given exact h function, strictly for a homogeneous problem \n",
    "function rpiHomog(N::Int64, hIn, alpha_d::Float64, alpha_r::Float64, beta::Float64, tau, c0::Float64, c1::Float64, r::Float64, epsilon::Float64; nMax = 0, delScale = 1, forceActive = false)\n",
    "    #calculate stepsize and initialise h,w,and policy vectors\n",
    "    del = 1/(delScale*(beta*alpha_d + N*alpha_r + tau(N)))\n",
    "    h = zeros(Float64, N+1, N+1)\n",
    "    w = zeros(Float64, N+1, N+1)\n",
    "    policy = piPolicyHomog(hIn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del; forceActive = forceActive)\n",
    "    n = 0\n",
    "    #repeat until epsilion-convergence or n = nMax\n",
    "    while true\n",
    "        n = n + 1\n",
    "        #calculate new w values\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                a = policy[i1+1,i2+1]\n",
    "                w[i1+1,i2+1] = instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        \n",
    "        #calculate new relative values\n",
    "        hNew = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                hNew[i1+1,i2+1] = w[i1+1,i2+1] - w[1,1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #check for convergence\n",
    "        deltas = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:N-i1\n",
    "                deltas[i1+1,i2+1] = hNew[i1+1,i2+1] - h[i1+1,i2+1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        h = hNew\n",
    "        if maximum(deltas) < epsilon || n == nMax\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    v = beta*c0*del + (beta*alpha_d + (N)*alpha_r)*del*h[1+1,0+1] + (1 - (beta*alpha_d + (N)*alpha_r)*del)*h[0+1,0+1]\n",
    "    \n",
    "    return v/del, h, n, policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b8046e6",
   "metadata": {},
   "source": [
    "Performs PE on the fully active policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e39012f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpeFAHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates the fully active policy, strictly for a homogeneous problem \n",
    "function rpeFAHomog(N::Int64, alpha_d::Float64, alpha_r::Float64, beta::Float64, tau, c0::Float64, c1::Float64, r::Float64, epsilon::Float64; nMax = 0, delScale = 1, forceActive = false)\n",
    "    #calculate stepsize and initialise h,w,and policy vectors\n",
    "    del = 1/(delScale*(beta*alpha_d + N*alpha_r + tau(N)))\n",
    "    h = zeros(Float64, N+1, N+1)\n",
    "    w = zeros(Float64, N+1, N+1)\n",
    "    n = 0\n",
    "    #repeat until epsilion-convergence or n = nMax\n",
    "    while true\n",
    "        n = n + 1\n",
    "        #calculate new w values\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                a = i1\n",
    "                w[i1+1,i2+1] = instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        \n",
    "        #calculate new relative values\n",
    "        hNew = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                hNew[i1+1,i2+1] = w[i1+1,i2+1] - w[1,1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #check for convergence\n",
    "        deltas = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:N-i1\n",
    "                deltas[i1+1,i2+1] = hNew[i1+1,i2+1] - h[i1+1,i2+1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        h = hNew\n",
    "        if maximum(deltas) < epsilon || n == nMax\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    v = beta*c0*del + (beta*alpha_d + (N)*alpha_r)*del*h[1+1,0+1] + (1 - (beta*alpha_d + (N)*alpha_r)*del)*h[0+1,0+1]\n",
    "    \n",
    "    return v/del, h, n\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c051660",
   "metadata": {},
   "source": [
    "Similar to rpiHomog, but uses Q(s,a) = h(s,a) approximation for PI step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "964c01ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiHomogApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates an approximate PI policy based on a given exact h function and instananeous actions, strictly for a homogeneous problem \n",
    "function rpiHomogApprox(N::Int64, hIn, alpha_d::Float64, alpha_r::Float64, beta::Float64, tau, c0::Float64, c1::Float64, r::Float64, epsilon::Float64, g::Float64; nMax = 0, delScale = 1, forceActive = false)\n",
    "    #calculate stepsize and initialise h,w,and policy vectors\n",
    "    del = 1/(delScale*(beta*alpha_d + N*alpha_r + tau(N)))\n",
    "    h = zeros(Float64, N+1, N+1)\n",
    "    w = zeros(Float64, N+1, N+1)\n",
    "    policy = piPolicyHomogApprox(hIn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g; forceActive = forceActive)\n",
    "    n = 0\n",
    "    #repeat until epsilion-convergence or n = nMax\n",
    "    while true\n",
    "        n = n + 1\n",
    "        #calculate new w values\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                a = policy[i1+1,i2+1]\n",
    "                w[i1+1,i2+1] = instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        \n",
    "        #calculate new relative values\n",
    "        hNew = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                hNew[i1+1,i2+1] = w[i1+1,i2+1] - w[1,1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #check for convergence\n",
    "        deltas = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:N-i1\n",
    "                deltas[i1+1,i2+1] = hNew[i1+1,i2+1] - h[i1+1,i2+1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        h = hNew\n",
    "        if maximum(deltas) < epsilon || n == nMax\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    v = beta*c0*del + (beta*alpha_d + (N)*alpha_r)*del*h[1+1,0+1] + (1 - (beta*alpha_d + (N)*alpha_r)*del)*h[0+1,0+1]\n",
    "    \n",
    "    return v/del, h, n, policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15e1c1de",
   "metadata": {},
   "source": [
    "Similar to above, but uses VFA as input h, and uses Q(s,a) = h(s+a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7146cc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiHomogVFAApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a PI policy based on a given VFA, using instananeous approximation, strictly for a homogeneous problem \n",
    "function rpiHomogVFAApprox(N::Int64, params, features, alpha_d::Float64, alpha_r::Float64, beta::Float64, tau, c0::Float64, c1::Float64, r::Float64, epsilon::Float64, g::Float64; nMax = 0, delScale = 1, forceActive = false)\n",
    "    \n",
    "    #construct hIn table\n",
    "    hIn = zeros(Float64, N+1, N+1)\n",
    "    for i1 in 0:N\n",
    "        for i2 in 0:(N - i1)\n",
    "            s = fill(1,N)\n",
    "            if i1 > 0\n",
    "                for i in 1:i1\n",
    "                    s[i] = 3\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            if i2 > 0\n",
    "                for i in (i1+1):(i1+i2)\n",
    "                    s[i] = 2\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            hIn[i1+1,i2+1] = v(s, params, features)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #run standard function\n",
    "    return rpiHomogApprox(N, hIn, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon, g; nMax = nMax, delScale = delScale, forceActive = forceActive)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54d455db",
   "metadata": {},
   "source": [
    "Similar to above, WITHOUT Q(s,a) = h(s+a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "04dc9704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiHomogVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a PI policy based on a given VFA, strictly for a homogeneous problem \n",
    "function rpiHomogVFA(N::Int64, params, features, alpha_d::Float64, alpha_r::Float64, beta::Float64, tau, c0::Float64, c1::Float64, r::Float64, epsilon::Float64; nMax = 0, delScale = 1, forceActive = false)\n",
    "    \n",
    "    #construct hIn table\n",
    "    hIn = zeros(Float64, N+1, N+1)\n",
    "    for i1 in 0:N\n",
    "        for i2 in 0:(N - i1)\n",
    "            s = fill(1,N)\n",
    "            if i1 > 0\n",
    "                for i in 1:i1\n",
    "                    s[i] = 3\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            if i2 > 0\n",
    "                for i in (i1+1):(i1+i2)\n",
    "                    s[i] = 2\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            hIn[i1+1,i2+1] = v(s, params, features)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #run standard function\n",
    "    return rpiHomog(N, hIn, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = nMax, delScale = delScale, forceActive = forceActive)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "690683ed",
   "metadata": {},
   "source": [
    "Performs RVIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "939c3f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rviHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs RVIA \n",
    "function rviHomog(N::Int64, alpha_d::Float64, alpha_r::Float64, beta::Float64, tau, c0::Float64, c1::Float64, r::Float64, epsilon::Float64; nMax = 0, delScale = 1, forceActive = false)\n",
    "    #calculate stepsize and initialise h,w,and policy vectors\n",
    "    del = 1/(delScale*(beta*alpha_d + N*alpha_r + tau(N)))\n",
    "    h = zeros(Float64, N+1, N+1)\n",
    "    w = zeros(Float64, N+1, N+1)\n",
    "    n = 0\n",
    "    #repeat until epsilion-convergence or n = nMax\n",
    "    while true\n",
    "        n = n + 1\n",
    "        #calculate new w values\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                a = piActionHomog(i1, i2, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del; forceActive = forceActive)\n",
    "                w[i1+1,i2+1] = instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        \n",
    "        #calculate new relative values\n",
    "        hNew = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                hNew[i1+1,i2+1] = w[i1+1,i2+1] - w[1,1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #check for convergence\n",
    "        deltas = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:N-i1\n",
    "                deltas[i1+1,i2+1] = hNew[i1+1,i2+1] - h[i1+1,i2+1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        h = hNew\n",
    "        if maximum(deltas) < epsilon || n == nMax\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    v = beta*c0*del + (beta*alpha_d + (N)*alpha_r)*del*h[1+1,0+1] + (1 - (beta*alpha_d + (N)*alpha_r)*del)*h[0+1,0+1]\n",
    "    \n",
    "    return v/del, h, n\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b3849",
   "metadata": {},
   "source": [
    "# Pre-requisite Functions for Exact DP on Inhomogeneous Problems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1e53ece",
   "metadata": {},
   "source": [
    "Helper functions for inhomogeneous exact DP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14ea586f",
   "metadata": {},
   "source": [
    "Given a state-action pair and h, calculates the expected next value of the value function after one timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d45adbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueExact (generic function with 1 method)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates E(h(s')) from s,a using exact h table\n",
    "function expectedNextValueExact(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, h)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    runningTotal = 0.0\n",
    "    runningTotalProb = 0.0\n",
    "    \n",
    "    flows = zeros(Float64, N)\n",
    "    if healthy > 0\n",
    "        #otherwise, find best route, and return\n",
    "        bestCost = maximum(c0) + 1\n",
    "        usedLink = 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 1 && c0[k] < bestCost\n",
    "                bestCost = c0[k]\n",
    "                usedLink = k\n",
    "            end \n",
    "        end\n",
    "        \n",
    "        flows[usedLink] = beta\n",
    "    end\n",
    "    \n",
    "    \n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*h[sNext]\n",
    "        runningTotalProb += flows[k]*alpha_d[k]*del\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            runningTotal += alpha_r[k]*del*h[sNext]\n",
    "            runningTotalProb += alpha_r[k]*del\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                runningTotal += (tau(repair)/repair)*del*h[sNext]\n",
    "                runningTotalProb += (tau(repair)/repair)*del\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal + (1 - runningTotalProb)*h[sPrime]\n",
    "end "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f2dad95",
   "metadata": {},
   "source": [
    "Given a state and a h table, calculates the PI action for s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4b71c013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionExact (generic function with 1 method)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI action using exact h table\n",
    "function piActionExact(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    if s == fill(1, N)\n",
    "        return zeros(Int64, N)\n",
    "    end\n",
    "    \n",
    "    optA = zeros(Int64, N)\n",
    "    optH = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del,h)\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64,N)\n",
    "            a[i] = 1\n",
    "            testH = instantCostUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del,h)\n",
    "            if testH < optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2cb0d43",
   "metadata": {},
   "source": [
    "Similar to above, but uses the approximation Q(s,a) = h(s+a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "17b1bbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionExactInstant (generic function with 1 method)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI action using exact h table, based off instananeous actions\n",
    "function piActionExactInstant(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    if s == fill(1, N)\n",
    "        return zeros(Int64, N)\n",
    "    end\n",
    "    \n",
    "    optA = zeros(Int64, N)\n",
    "    optH = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del,h) - g*del\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64,N)\n",
    "            a[i] = 1\n",
    "            testH = h[s-a]\n",
    "            if testH < optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7eb2f91a",
   "metadata": {},
   "source": [
    "Similar to above, but uses a VFA instead of a h table, WITHOUT Q(s,a) = h(s+a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2bab1aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI action using a VFA\n",
    "function piActionVFA(s, params, features, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    if s == fill(1, N)\n",
    "        return zeros(Int64, N)\n",
    "    end\n",
    "    \n",
    "    optA = zeros(Int64, N)\n",
    "    optH = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del,params,features)\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64,N)\n",
    "            a[i] = 1\n",
    "            testH = instantCostUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del,params,features)\n",
    "            if testH < optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4096d38",
   "metadata": {},
   "source": [
    "Similar to above, WITH Q(s,a) = h(s,a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "604bf237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionVFAInstant (generic function with 1 method)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI action using a VFA and instananeous actions\n",
    "function piActionVFAInstant(s, params, features, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    if s == fill(1, N)\n",
    "        return zeros(Int64, N)\n",
    "    end\n",
    "    \n",
    "    optA = zeros(Int64, N)\n",
    "    optH = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del,params,features) - g*del\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64,N)\n",
    "            a[i] = 1\n",
    "            testH = v(s-a,params,features)\n",
    "            if testH < optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "884618d7",
   "metadata": {},
   "source": [
    "Constructs PI policy using h table and no approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e1dfe8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyExact (generic function with 1 method)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI policy using exact h table\n",
    "function piPolicyExact(h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    policy = Dict()\n",
    "    stateSpace = enumerateStates(N)\n",
    "    for s in stateSpace\n",
    "        policy[s] = piActionExact(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    end\n",
    "    \n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8842b6de",
   "metadata": {},
   "source": [
    "Constructs PI policy using h table and Q(s,a) = h(s+a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bfb9dcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyExactInstant (generic function with 1 method)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI policy using exact h table, interpretting h with instant actions\n",
    "function piPolicyExactInstant(h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    policy = Dict()\n",
    "    stateSpace = enumerateStates(N)\n",
    "    for s in stateSpace\n",
    "        policy[s] = piActionExactInstant(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    end\n",
    "    \n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44d2fa28",
   "metadata": {},
   "source": [
    "Constructs PI policy using VFA and no approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "72a89a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI policy from a VFA\n",
    "function piPolicyVFA(params, features, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    policy = Dict()\n",
    "    stateSpace = enumerateStates(N)\n",
    "    for s in stateSpace\n",
    "        policy[s] = piActionVFA(s, params, features, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    end\n",
    "    \n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d72cd38",
   "metadata": {},
   "source": [
    "Constructs PI policy using VFA and Q(s,a) = h(s+a) approximation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "14bba9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyVFAInstant (generic function with 1 method)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI policy from a VFA, using instant actions to interpret h\n",
    "function piPolicyVFAInstant(params, features, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    policy = Dict()\n",
    "    stateSpace = enumerateStates(N)\n",
    "    for s in stateSpace\n",
    "        policy[s] = piActionVFAInstant(s, params, features, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    end\n",
    "    \n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f8cc379",
   "metadata": {},
   "source": [
    "Constructs h table from VFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "28d6c8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hFromVFAInhomog (generic function with 1 method)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function hFromVFAInhomog(N, params, features)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    h = Dict()\n",
    "    for s in stateSpace\n",
    "        h[s] = v(s, params. features)\n",
    "    end\n",
    "\n",
    "    return h\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7172ee4",
   "metadata": {},
   "source": [
    "# Exact DP for Inhomogeneous Problem (using exact h or VFA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43e2ee1b",
   "metadata": {},
   "source": [
    "DP algorithms for inhomogeneous problem\n",
    "\n",
    "Note that throughout when we talk of a Q(s,a) = h(s+a) approximation, this only refers to action selection and not update rules, and excludes a=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2225adc2",
   "metadata": {},
   "source": [
    "Given an explicit policy table, performs PE, returns g, h and n (# of iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8b118e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpe (generic function with 1 method)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs PE using exact policy table\n",
    "function rpe(N, policy, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    #calculate stepsize and initialise h,w,and policy dictionaries\n",
    "    del = 1/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    h = Dict()\n",
    "    w = Dict()\n",
    "    stateSpace = enumerateStates(N)\n",
    "    actionSpace = enumerateRestrictedActions(N)\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "        w[s] = 0.0\n",
    "    end\n",
    "    s0  = fill(1, N)\n",
    "    n = 0\n",
    "    \n",
    "    #do until max iterations met or epsilon convergence\n",
    "    while true\n",
    "        n = n + 1\n",
    "        #find updates for every state\n",
    "        for s in stateSpace\n",
    "            a = policy[s]\n",
    "            w[s] = instantCostUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, h)\n",
    "        end\n",
    "        \n",
    "        #calculate relative values and delta\n",
    "        delta = 0\n",
    "        for s in stateSpace\n",
    "            update = w[s] - w[s0]\n",
    "            if delta < update - h[s] || delta == 0\n",
    "                delta = update - h[s]\n",
    "            end\n",
    "            \n",
    "            h[s] = update\n",
    "        end\n",
    "        \n",
    "        #stopping condition\n",
    "        if delta < epsilon || n == nMax\n",
    "            break\n",
    "        end\n",
    "        \n",
    "        if printProgress && n%modCounter == 0\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    a = zeros(Int64, N)\n",
    "    g = instantCostUnif(s0,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s0,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, h) - h[s0]\n",
    "    \n",
    "    return g/del, h, n\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1ad5a2b",
   "metadata": {},
   "source": [
    "Given a h table, constructs PI policy and performs PE, returning g, h, n and the PI policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7c57636f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiExact (generic function with 1 method)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs one round of exact PI and PE using exact h table\n",
    "function rpiExact(N, hIn, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    del = 1/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    policy = piPolicyExact(hIn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    output = rpe(N, policy, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = nMax, delScale = delScale, printProgress = printProgress, modCounter = modCounter)\n",
    "    return output[1], output[2], output[3], policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec78eb5a",
   "metadata": {},
   "source": [
    "Similar to above, but uses Q(s,a) = h(s+a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "266027ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiExactInstant (generic function with 1 method)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs one round of exact PI and PE using exact h table, using instant actions to interpet h\n",
    "function rpiExactInstant(N, hIn, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon, g; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    #calculate stepsize and initialise h,w,and policy dictionaries\n",
    "    del = 1/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    policy = piPolicyExactInstant(hIn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    output = rpe(N, policy, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = nMax, delScale = delScale, printProgress = printProgress, modCounter = modCounter)\n",
    "    return output[1], output[2], output[3], policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0aa6660e",
   "metadata": {},
   "source": [
    "Performs PE on the fully active policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f773f8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpeFA (generic function with 1 method)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs exact PE on the fully-active policy\n",
    "function rpeFA(N, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    policy = Dict()\n",
    "    for s in stateSpace\n",
    "        policy[s] = faAction(s)\n",
    "    end\n",
    "    \n",
    "    return rpe(N, policy, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = nMax, delScale = delScale, printProgress = printProgress, modCounter = modCounter)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c325a927",
   "metadata": {},
   "source": [
    "Performs PE on fully passive policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d304fb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpePassive (generic function with 1 method)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs exact PE on the passive policy\n",
    "function rpePassive(N, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    policy = Dict()\n",
    "    for s in stateSpace\n",
    "        policy[s] = zeros(Int64, N)\n",
    "    end\n",
    "    \n",
    "    return rpe(N, policy, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = nMax, delScale = delScale, printProgress = printProgress, modCounter = modCounter)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c45280",
   "metadata": {},
   "source": [
    "Given a VFA, constructs PI policy and performs PE, returning g, h, n and the PI policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1ec6cacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs one round of exact PI and PE using VFA\n",
    "function rpiVFA(N, params, features, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    hIn = hFromVFAInhomog(N, params, features)\n",
    "    return rpiExact(N, hIn, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = nMax, delScale = delScale, printProgress = printProgress, modCounter = modCounter)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68209e10",
   "metadata": {},
   "source": [
    "Similar to above, but uses Q(s,a) = h(s+a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9a19903b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiVFAInstant (generic function with 1 method)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs one round of exact PI and PE using VFA and instantaneous actions to interpret h\n",
    "function rpiVFAInstant(N, params, features, g, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    hIn = hFromVFAInhomog(N, params, features)\n",
    "    return rpiExactInstant(N, hIn, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon, g; nMax = nMax, delScale = delScale, printProgress = printProgress, modCounter = modCounter)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b0b6c10",
   "metadata": {},
   "source": [
    "Performs RVIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7d38fbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rvi (generic function with 1 method)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs RVIA\n",
    "function rvi(N, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    #calculate stepsize and initialise h,w,and policy dictionaries\n",
    "    del = 1/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    h = Dict()\n",
    "    w = Dict()\n",
    "    policy = Dict()\n",
    "    stateSpace = enumerateStates(N)\n",
    "    actionSpace = enumerateRestrictedActions(N)\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "        w[s] = 0.0\n",
    "        policy[s] = zeros(Int64,N)\n",
    "    end\n",
    "    s0  = fill(1, N)\n",
    "    n = 0\n",
    "    \n",
    "    #do until max iterations met or epsilon convergence\n",
    "    while true\n",
    "        n = n + 1\n",
    "        #find updates for every state\n",
    "        for s in stateSpace\n",
    "            a = piActionExact(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "            w[s] = instantCostUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, h)\n",
    "        end\n",
    "        \n",
    "        #calculate relative values and delta\n",
    "        delta = 0\n",
    "        for s in stateSpace\n",
    "            update = w[s] - w[s0]\n",
    "            if delta < update - h[s] || delta == 0\n",
    "                delta = update - h[s]\n",
    "            end\n",
    "            \n",
    "            h[s] = update\n",
    "        end\n",
    "        \n",
    "        #stopping condition\n",
    "        if delta < epsilon || n == nMax\n",
    "            break\n",
    "        end\n",
    "        \n",
    "        if printProgress && n%modCounter == 0\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    a = zeros(Int64, N)\n",
    "    g = instantCostUnif(s0,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s0,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, h) - h[s0]\n",
    "    \n",
    "    return g/del, h, n, policy\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb424a1e",
   "metadata": {},
   "source": [
    "# Evaluation via simulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bcbbb37",
   "metadata": {},
   "source": [
    "Various evaluation functions for approximating g"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ef631d9",
   "metadata": {},
   "source": [
    "Takes a trained VFA and learns g, using g also for control, starting from state s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8261907a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluation (generic function with 1 method)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a VFA via PI using simulation\n",
    "function gEvaluation(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, vParams, features; printProgress = false, modCounter = 100000, forceActive = false, printState = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if printState\n",
    "            println(s)\n",
    "        end\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t\n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64,N)\n",
    "            optA[1] = 1\n",
    "            t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            optV = v(s-optA, vParams, features)\n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #update state and flows\n",
    "        bestA = optA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(runningTotals, [runningTotal])\n",
    "        append!(times,[timePassed])\n",
    "        append!(gs,[g])\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "320c63e1",
   "metadata": {},
   "source": [
    "Similar to above, but starting from a given state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9fd18438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationFromS (generic function with 1 method)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a VFA using simulation\n",
    "function gEvaluationFromS(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, vParams, features; printProgress = false, modCounter = 100000, forceActive = false, stateTrace = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    flowResult = calculateFlows(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    flows = flowResult[1]\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if stateTrace\n",
    "            println(s)\n",
    "        end \n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t\n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64,N)\n",
    "            optA[1] = 1\n",
    "            t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            optV = v(s-optA, vParams, features)\n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #update state and flows\n",
    "        bestA = optA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(gs,[g])\n",
    "        append!(runningTotals, [runningTotal])\n",
    "        append!(times,[timePassed])\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ceb6a98",
   "metadata": {},
   "source": [
    "Similar to gEvaluation, but uses a fixed g0 for control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ba5ce5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluation_g0 (generic function with 1 method)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a VFA using simulation\n",
    "function gEvaluation_g0(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, vParams, features, g0; printProgress = false, modCounter = 100000, forceActive = false, stateTrace = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if stateTrace\n",
    "            println(s)\n",
    "        end\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g0*t\n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64,N)\n",
    "            optA[1] = 1\n",
    "            optV = v(s-optA, vParams, features)\n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #update state and flows\n",
    "        bestA = optA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(gs,[g])\n",
    "        append!(runningTotals, [runningTotal])\n",
    "        append!(times,[timePassed])\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3cd3eae",
   "metadata": {},
   "source": [
    "Similar to above, but starts from a given state s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b85a37ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationFromS_g0 (generic function with 1 method)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a VFA using simulation\n",
    "function gEvaluationFromS_g0(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, vParams, features, g0; printProgress = false, modCounter = 100000, forceActive = false, stateTrace = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    flowResult = calculateFlows(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    flows = flowResult[1]\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if stateTrace\n",
    "            println(s)\n",
    "        end \n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g0*t\n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64,N)\n",
    "            optA[1] = 1\n",
    "            t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            optV = v(s-optA, vParams, features)\n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #update state and flows\n",
    "        bestA = optA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(runningTotals, [runningTotal])\n",
    "        append!(times,[timePassed])\n",
    "        append!(gs,[g])\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6636431",
   "metadata": {},
   "source": [
    "Finds the g of the fully active policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "33be91d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationFA (generic function with 1 method)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates the FA policy\n",
    "function gEvaluationFA(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax; printProgress = false, modCounter = 100000, forceActive = false, stateTrace = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if stateTrace\n",
    "            println(s)\n",
    "        end\n",
    "        \n",
    "        #formulate FA action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #update state, flows and g\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(gs,[g])\n",
    "        append!(runningTotals, [runningTotal])\n",
    "        append!(times,[timePassed])\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d651dbd0",
   "metadata": {},
   "source": [
    "Similar to gEvaluation, but only uses the BAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b8ba1023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationBAS (generic function with 1 method)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a VFA via PI using simulation\n",
    "function gEvaluationBAS(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, vParams, features; printProgress = false, modCounter = 100000, forceActive = false, stateTrace = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if stateTrace\n",
    "            println(s)\n",
    "        end\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        tPassive = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*tPassive\n",
    "        \n",
    "        testA = faAction(s)\n",
    "        tActive = sojournTime(s, testA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        testV = instantCostCont(s,testA, N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,testA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*tActive\n",
    "        if testV <= optV\n",
    "            optV = testV\n",
    "            optA = testA\n",
    "        end\n",
    "        \n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64,N)\n",
    "            optA = testA\n",
    "            optV = testV\n",
    "        end\n",
    "        \n",
    "        #update state and flows\n",
    "        bestA = optA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            append!(runningTotals, [runningTotal])\n",
    "            timePassed += time\n",
    "            append!(times,[timePassed])\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(gs,[g])\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4d81acf",
   "metadata": {},
   "source": [
    "Similar to gEvaluation_g0, but assumes that flows are passed to the VFA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "862863bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluation_g0_flows (generic function with 1 method)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a VFA using simulation\n",
    "function gEvaluation_g0_flows(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, vParams, features, g0; printProgress = false, modCounter = 100000, forceActive = false, stateTrace = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if stateTrace\n",
    "            println(s)\n",
    "        end\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContFlows(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g0*t\n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, flows, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64,N)\n",
    "            optA[1] = 1\n",
    "            optV = v(s-optA, flows, vParams, features)\n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, flows, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #update state and flows\n",
    "        bestA = optA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(gs,[g])\n",
    "        append!(runningTotals, [runningTotal])\n",
    "        append!(times,[timePassed])\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88307ffe",
   "metadata": {},
   "source": [
    "# APE on Fully Active Policy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7749e9f",
   "metadata": {},
   "source": [
    "Performs APE on the Fully Active Policy using each of the four approaches to estimating a VFA (mixes of uniform/smar and simulated-next-state/expectation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "666815fa",
   "metadata": {},
   "source": [
    "Returns the FA action for a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d1319dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faAction (generic function with 1 method)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computes the Fully Active action for a given state s\n",
    "function faAction(s)\n",
    "    N = length(s)\n",
    "    a = zeros(Int64,N)\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a[i] = 1\n",
    "        end\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9168d0b",
   "metadata": {},
   "source": [
    "Evaluates the FA policy using a VFA and uniformisation, and update targets c + V(s') - gt, where s' is simulated next state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e894ba39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apeFAUnifApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs APE of FA policy in uniformised setting, approximating E(h(s')) for update targets using just h(s'), where s' is the next simulated state\n",
    "function apeFAUnifApprox(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; delScale = 1.0, printProgress = false, modCounter = 100000, forceActive = false)\n",
    "    #initialise\n",
    "    del = 1.0/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        c = instantCostUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "        bestV = c + v(sPrime, vParams, features) - v(s0, vParams,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = v(s, vParams, features)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        c = result[2]\n",
    "        s = sPrime\n",
    "        flows = result[3]\n",
    "        g += (1/n)*(c - g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e96581e",
   "metadata": {},
   "source": [
    "Similar to above, but uses full expectation for updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ccde3d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apeFAUnifFull (generic function with 1 method)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs APE of FA policy in uniformised setting, approximating E(h(s')) using all possible transitions\n",
    "function apeFAUnifFull(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; delScale = 1.0, printProgress = false, modCounter = 100000, forceActive = false)\n",
    "    #initialise\n",
    "    del = 1.0/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        c = instantCostUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "        bestV = c + expectedNextValueUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features) - v(s0, vParams,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = v(s, vParams, features)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        c = result[2]\n",
    "        s = sPrime\n",
    "        flows = result[3]\n",
    "        g += (1/n)*(c - g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d7bdaa9",
   "metadata": {},
   "source": [
    "Performs SMARPE on FA policy, with update target c + V(s') - gt where s' is the next simulated state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bd7df03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeFAApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs SMARPE on FA policy, approximating E(h(s')) as h(s') where s' is the next simulated state\n",
    "function smarpeFAApprox(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        if bestA == zeros(Int64,N)\n",
    "            c = instantCostCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            t = sojournTime(s, bestA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            bestV = c + v(sPrime, vParams, features) - g*t - v(s0, vParams,features)\n",
    "        else\n",
    "            bestV = v(s - bestA, vParams, features) - v(s0, vParams,features)\n",
    "        end \n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af073bb3",
   "metadata": {},
   "source": [
    "Similar to above, but uses full expectation in update target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d8865800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeFAFull (generic function with 1 method)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smarpeFAFull(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        if bestA == zeros(Int64,N)\n",
    "            c = instantCostCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            t = sojournTime(s, bestA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            bestV = c + expectedNextValueCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t - v(s0, vParams,features)\n",
    "        else\n",
    "            bestV = v(s - bestA, vParams, features) - v(s0, vParams,features)\n",
    "        end\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ceece53",
   "metadata": {},
   "source": [
    "Similar to smarpeFAApprox, but incorporates state trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b68eb6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeFAApproxST (generic function with 1 method)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs APE on FA policy in continuous time setting, approximating E(h(s')) as h(s') where s' is the next simulated state\n",
    "#Also incorporates the state trace when actions are taken\n",
    "function smarpeFAApproxST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    stateTrace = []\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        #update state trace\n",
    "        append!(stateTrace, [s])\n",
    "        \n",
    "        #formulate action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #for passive action, do proper update\n",
    "        if bestA == zeros(Int64,N)\n",
    "            #find value of v^n\n",
    "            c = instantCostCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            t = sojournTime(s, bestA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            bestV = c + v(sPrime, vParams, features) - g*t - v(s0, vParams,features)\n",
    "\n",
    "            #update VFA\n",
    "            for sTrace in stateTrace\n",
    "                currentEst = v(sTrace, vParams, features)\n",
    "                grad = append!([1.0],[features[i](sTrace) for i in 1:numFeatures])\n",
    "                vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "                append!(paramHist,[vParams])\n",
    "            end\n",
    "            \n",
    "            stateTrace = []\n",
    "            \n",
    "            #update g, state, and flows\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "\n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "            \n",
    "        #for other action, simply update state and move on\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c19d280d",
   "metadata": {},
   "source": [
    "Similar to above, but uses full expectation for update target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "47d8caaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeFAFullST (generic function with 1 method)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs APE on FA policy in continuous time setting, approximating E(h(s')) using all possible transitions\n",
    "#Also incorporates the state trace when actions are taken\n",
    "function smarpeFAFullST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    stateTrace = []\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        #update state trace\n",
    "        append!(stateTrace, [s])\n",
    "        \n",
    "        #formulate action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #for passive action, do proper update\n",
    "        if bestA == zeros(Int64,N)\n",
    "            #find value of v^n\n",
    "            c = instantCostCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            t = sojournTime(s, bestA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            bestV = c + expectedNextValueCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t - v(s0, vParams,features)\n",
    "\n",
    "            #update VFA\n",
    "            for sTrace in stateTrace\n",
    "                currentEst = v(sTrace, vParams, features)\n",
    "                grad = append!([1.0],[features[i](sTrace) for i in 1:numFeatures])\n",
    "                vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "                append!(paramHist,[vParams])\n",
    "            end\n",
    "            \n",
    "            stateTrace = []\n",
    "            \n",
    "            #update g, state, and flows\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "\n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "            \n",
    "        #for other action, simply update state and move on\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f5b89",
   "metadata": {},
   "source": [
    "# SMARPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54992054",
   "metadata": {},
   "source": [
    "## Semi-Markov Approximate Relative Policy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be11b69",
   "metadata": {},
   "source": [
    "- SMARPE takes some trained VFA as input, and seeks to learn the associated long run cost g and the value function of the policy derived from the given VFA\n",
    "\n",
    "- Standard SMARPE uses the online training value of g for action selection, allowing the policy to vary throughout training\n",
    "\n",
    "- SMARPE_g0 takes a pre-learned value of g0 to be used for action selection, keeping the policy constant throughout. This value of g0 might be taken directly from SMARVI or from some gEval function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffc082",
   "metadata": {},
   "source": [
    "Worth also discussing is the exact behaviour of the gEval functions.\n",
    "\n",
    "- Standard gEval simply evaluates a VFA, and learns g throughout. In turn, this value of g is used for action selection, so the policy may vary throughout evaluation.\n",
    "\n",
    "- gEval_g0 evaluates a VFA-g0 pair, keeping the policy constant throughout. It may be good practice to always follow standard gEval with gEval_g0, due to the lack of policy variability.\n",
    "\n",
    "gEval functions are the part that actually calculate the PI actions based on the VFAs derived from SMARPE."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a0e5de3",
   "metadata": {},
   "source": [
    "Given a VFA-g pair, evaluates the PI policy derived from the pair via a new VFA with the same architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6082e341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpe (generic function with 1 method)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs APE in the continuous time setting, approximating E(h(s')) using all possible transitions, and with a fixed g0 for action selection\n",
    "function smarpe(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, paramsIn, paramsOut, features, g0; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [paramsOut]\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optAandV = smarActionAndVFromVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, paramsIn, features, g0)\n",
    "        \n",
    "        bestA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #recalculate optA in terms of new VFA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, paramsOut, features) - g*t\n",
    "        else\n",
    "            optV = v(s - bestA, paramsOut, features)\n",
    "        end \n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV - v(s0, paramsOut ,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = v(s, paramsOut, features)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        paramsOut = paramsOut + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[paramsOut])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(gs, [g])\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return paramsOut, paramHist, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38d24567",
   "metadata": {},
   "source": [
    "# Tabular SMARVI and gEval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b101ab9",
   "metadata": {},
   "source": [
    "Tabular SMARVI algorithms (non e-greedy, e-greedy, and e-greedt with state trace), associated gEval function, and helper functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a829f15",
   "metadata": {},
   "source": [
    "Given a state s, its flows, and a h-g pair, return the optimal action and V value for s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d500f4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarActionAndVFromTable (generic function with 1 method)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smarActionAndVFromTable(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, h, g)\n",
    "    #find optimal action\n",
    "    optA = zeros(Int64,N)\n",
    "    t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "        \n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64, N)\n",
    "            a[i] = 1\n",
    "               \n",
    "            if h[s-a] <= optV\n",
    "                optV = h[s-a]\n",
    "                optA = a\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "        \n",
    "    #Fix choose optimal non-passive action if state is [3,3,...,3]\n",
    "    if s == fill(3,N) && optA == zeros(Int64, N)\n",
    "        optA[1] = 1\n",
    "        optV = h[s-optA]\n",
    "            \n",
    "        for i in 2:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                testV = h[s-a]\n",
    "                if testV <= optV\n",
    "                    optV = testV\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return optA, optV\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94fd262e",
   "metadata": {},
   "source": [
    "Given a state-action pair and a h table, compute the next expected h value given that a transition has occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bd0e5b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueContTab (generic function with 1 method)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculates E(h(s')) given a state-action pair, and tabular h\n",
    "function expectedNextValueContTab(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h)\n",
    "    del = sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    #different treatment for all-damaged state\n",
    "    if sPrime == fill(3,N)\n",
    "        return h[sPrime]\n",
    "    end\n",
    "    \n",
    "    runningTotal = 0\n",
    "    \n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*h[sNext]\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            runningTotal += alpha_r[k]*del*h[sNext]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                runningTotal += (tau(repair)/repair)*del*h[sNext]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal\n",
    "end   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e27d5cd6",
   "metadata": {},
   "source": [
    "Tabular version of SMARVI, with no state trace or e-greedy actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6447836b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviTab (generic function with 1 method)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in the continuous time setting, approximating E(h(s')) using all possible transitions\n",
    "#Uses tabular representation instead of VFA\n",
    "function smarviTab(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "\n",
    "    h = Dict()\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "    end\n",
    "    \n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #formulate optimal action\n",
    "        optAandV = smarActionAndVFromTable(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, h, g)\n",
    "        bestA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        if bestA == zeros(Int64,N)\n",
    "            bestV = optV - h[s0]\n",
    "        else\n",
    "            bestV = optV - h[s0]\n",
    "        end \n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = h[s]\n",
    "        h[s] += (b/(b + numVisits[s]))*(bestV - currentEst)\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2833561",
   "metadata": {},
   "source": [
    "e-greedy version of the above. e can be chosen to depend on the state or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cf860122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviTab_epsGreedy (generic function with 1 method)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in the continuous time setting, approximating E(h(s')) using all possible transitions\n",
    "#Uses tabular representation instead of VFA and e-greedy action selection\n",
    "function smarviTab_epsGreedy(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; printProgress = false, modCounter = 100000, stateDepEpsilon = false)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "\n",
    "    h = Dict()\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "    end\n",
    "    \n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #formulate optimal action\n",
    "        optAandV = smarActionAndVFromTable(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, h, g)\n",
    "        optA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        epsilon = c/(c + n)\n",
    "        if stateDepEpsilon\n",
    "            epsilon = c/(c + numVisits[s])\n",
    "        end\n",
    "\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            optA = randomAction(s, N)\n",
    "            if optA == zeros(Int64, N)\n",
    "                t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "                optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "            else\n",
    "                optV = h[s - optA]\n",
    "            end    \n",
    "        end \n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV - h[s0]\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = h[s]\n",
    "        h[s] += (b/(b + numVisits[s]))*(bestV - currentEst)\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6f7777e",
   "metadata": {},
   "source": [
    "Similar to above, but incorporates the state trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "de3e948e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviTab_epsGreedyST (generic function with 1 method)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uses tabular representation instead of VFA, e-greedy action selection, and state trace \n",
    "function smarviTab_epsGreedyST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; printProgress = false, modCounter = 100000, stateDepEpsilon = false)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateTrace = []\n",
    "    h = Dict()\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "    end\n",
    "    \n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #formulate optimal action\n",
    "        optAandV = smarActionAndVFromTable(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, h, g)\n",
    "        optA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #choose epsilon\n",
    "        epsilon = c/(c + n)\n",
    "        if stateDepEpsilon\n",
    "            epsilon = c/(c + numVisits[s])\n",
    "        end\n",
    "\n",
    "        #choose actual action\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            optA = randomAction(s, N)\n",
    "            if optA == zeros(Int64, N)\n",
    "                t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "                optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "            else\n",
    "                optV = h[s - optA]\n",
    "            end    \n",
    "        end \n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV - h[s0]\n",
    "        \n",
    "        #update VFA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            for st in stateTrace\n",
    "                currentEst = h[st]\n",
    "                h[st] += (b/(b + numVisits[st]))*(bestV - currentEst)\n",
    "            end\n",
    "            stateTrace = []\n",
    "        end\n",
    "\n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5619d4e1",
   "metadata": {},
   "source": [
    "Similar to above (so e-greedy and state trace), but uses a moving average window to approximate g, allowing old estimates to be discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5e0f86bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviTabMA (generic function with 1 method)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tabular SMARVI with moving average online approximation for g, e-greedy action selection, and state trace\n",
    "function smarviTabMA(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; window = 2500000, printProgress = false, modCounter = 100000, stateDepEpsilon = false)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    totalCosts = [0.0]\n",
    "    timePassed = 0.0\n",
    "    totalTimes = [0.0]\n",
    "    lenTotals = 1\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateTrace = []\n",
    "    h = Dict()\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "    end\n",
    "    \n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #formulate optimal action\n",
    "        optAandV = smarActionAndVFromTable(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, h, g)\n",
    "        optA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #choose epsilon\n",
    "        epsilon = c/(c + n)\n",
    "        if stateDepEpsilon\n",
    "            epsilon = c/(c + numVisits[s])\n",
    "        end\n",
    "\n",
    "        #choose actual action\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            optA = randomAction(s, N)\n",
    "            if optA == zeros(Int64, N)\n",
    "                t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "                optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "            else\n",
    "                optV = h[s - optA]\n",
    "            end    \n",
    "        end \n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV - h[s0]\n",
    "        \n",
    "        #update VFA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            for st in stateTrace\n",
    "                currentEst = h[st]\n",
    "                h[st] += (b/(b + numVisits[st]))*(bestV - currentEst)\n",
    "            end\n",
    "            stateTrace = []\n",
    "        end\n",
    "\n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            push!(totalCosts, runningTotal)\n",
    "            push!(totalTimes, timePassed)\n",
    "            lenTotals += 1\n",
    "            if lenTotals <= window\n",
    "                g = runningTotal/timePassed\n",
    "            else\n",
    "                g = (runningTotal - totalCosts[lenTotals - window])/(timePassed - totalTimes[lenTotals - window])\n",
    "            end\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0ca583e",
   "metadata": {},
   "source": [
    "Given a state, a h table and g, return the PI action for s. Uses the Q(s,a) = h(s+a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a89e1d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionExactCont (generic function with 1 method)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI action using exact h table, based off continuous model\n",
    "function piActionExactCont(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, g)\n",
    "    if s == fill(1, N)\n",
    "        return zeros(Int64, N)\n",
    "    end\n",
    "    \n",
    "    flows = calculateFlows(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r)[1]\n",
    "    \n",
    "    optA = zeros(Int64, N)\n",
    "    t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    optH = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows,h) - g*t\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64,N)\n",
    "            a[i] = 1\n",
    "            testH = h[s-a]\n",
    "            if testH < optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if s == fill(3,N) && optA == zeros(Int64, N)\n",
    "        optA[1] = 1\n",
    "        optH = h[s - optA]\n",
    "\n",
    "        for i in 2:N\n",
    "            a = zeros(Int64, N)\n",
    "            a[i] = 1\n",
    "            testH = h[s - a]\n",
    "            if testH < optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5696a2b2",
   "metadata": {},
   "source": [
    "Constructs a PI policy using the above method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "47ec161d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyExactCont (generic function with 1 method)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function piPolicyExactCont(h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, g)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    policy = Dict()\n",
    "    for s in stateSpace\n",
    "        policy[s] = piActionExactCont(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, g)\n",
    "    end\n",
    "\n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c7cc371",
   "metadata": {},
   "source": [
    "Given a h table and fixed g0, approximates the g of the PI policy derived using the above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "161485ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationTab (generic function with 1 method)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gEvaluationTab(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, h, g0; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    println(\"State Space Completed\")\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    policy = piPolicyExactCont(h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, g0)\n",
    "    println(\"Policy Completed\")\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        bestA = policy[s]\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return g, gs, policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6efb11fd",
   "metadata": {},
   "source": [
    "Returns an array of feasible actions for N-dim state s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c00dff36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enumerateFeasibleActions (generic function with 1 method)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function enumerateFeasibleActions(s,N)\n",
    "    actionSpace = []\n",
    "    if s == fill(3, N)\n",
    "        for i in 1:N\n",
    "            a = zeros(Int64, N)\n",
    "            a[i] = 1\n",
    "            push!(actionSpace, a)\n",
    "        end\n",
    "        return actionSpace\n",
    "    end\n",
    "\n",
    "    push!(actionSpace, zeros(Int64,N))\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64, N)\n",
    "            a[i] = 1\n",
    "            push!(actionSpace, a)\n",
    "        end\n",
    "    end\n",
    "    return actionSpace\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "884ee22f",
   "metadata": {},
   "source": [
    "# SMART Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc90c99f",
   "metadata": {},
   "source": [
    "Tabular SMART algorithm, associated gEvaluation function, and helper functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6bef550",
   "metadata": {},
   "source": [
    "Given a state and a q-table, return optimal action and associated Q-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9b86ab9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actionFromQTab (generic function with 1 method)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function actionFromQTab(s, N, q)\n",
    "    feasibleActions = enumerateFeasibleActions(s,N)\n",
    "\n",
    "    #formulate action\n",
    "    optA = zeros(Int64, N)\n",
    "    if s == fill(3,N)\n",
    "        optA[1] = 1\n",
    "    end\n",
    "    optQ = q[s,optA]\n",
    "    for a in feasibleActions\n",
    "        testQ = q[s,a]\n",
    "        if testQ < optQ\n",
    "            optQ = testQ\n",
    "            optA = a\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return optA, optQ\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93d0c99a",
   "metadata": {},
   "source": [
    "Construct policy using above method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "233657b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyExactContQ (generic function with 1 method)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function piPolicyExactContQ(q, N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    policy = Dict()\n",
    "    for s in stateSpace\n",
    "        policy[s] = actionFromQTab(s, N, q)[1]\n",
    "    end\n",
    "\n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bcb0dda",
   "metadata": {},
   "source": [
    "Performs SMART, using a state-action trace and e-greedy action selection, where e can be chosen to depend on the state or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1f7db3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smartTab (generic function with 1 method)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smartTab(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; printProgress = false, modCounter = 100000, stateDepEpsilon = false)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    actionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateActionTrace = []\n",
    "    q = Dict()\n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        for a in enumerateFeasibleActions(s,N)\n",
    "            q[s,a] = 0.0\n",
    "        end\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    optAandQ = actionFromQTab(s, N, q)\n",
    "    optA = optAandQ[1]\n",
    "    optQ = optAandQ[2]\n",
    "\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        numVisits[s] += 1\n",
    "        \n",
    "        optFlag = true\n",
    "        \n",
    "        #choose e-greedy action\n",
    "        epsilon = c/(c + n)\n",
    "        if stateDepEpsilon\n",
    "            epsilon = c/(c + numVisits[s])\n",
    "        end\n",
    "\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            optA = randomAction(s, N)\n",
    "            optQ = q[s,optA]\n",
    "            optFlag = false\n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        push!(stateActionTrace, (s,bestA))\n",
    "\n",
    "        nextOptA = zeros(Int64, N)\n",
    "        nextOptQ = 0.0\n",
    "        #update q, flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            #simulate transition\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "  \n",
    "            #update g if optimal action taken\n",
    "            if optFlag\n",
    "                runningTotal += c\n",
    "                timePassed += time\n",
    "                g = runningTotal/timePassed\n",
    "            end\n",
    "\n",
    "            #find next optimal action and q value\n",
    "            nextOptAandQ = actionFromQTab(sPrime, N, q)\n",
    "            nextOptA = nextOptAandQ[1]\n",
    "            nextOptQ = nextOptAandQ[2]\n",
    "\n",
    "            for saPair in stateActionTrace\n",
    "                st = saPair[1]\n",
    "                q[saPair] += (b/(b + numVisits[st]))*(c + nextOptQ - g*time - q[saPair])\n",
    "            end\n",
    "\n",
    "            stateActionTrace = []\n",
    "        else\n",
    "            sPrime = s - bestA\n",
    "\n",
    "            nextOptAandQ = actionFromQTab(sPrime, N, q)\n",
    "            nextOptA = nextOptAandQ[1]\n",
    "            nextOptQ = nextOptAandQ[2]\n",
    "        end\n",
    "        \n",
    "        s = sPrime\n",
    "        optA = nextOptA\n",
    "        optQ = nextOptQ\n",
    "\n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return q, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb19c603",
   "metadata": {},
   "source": [
    "Taking a Q table as input, formulates the associated policy and simulates it to approximate g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0943848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationTabQ (generic function with 1 method)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gEvaluationTabQ(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, q; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    println(\"State Space Completed\")\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    policy = piPolicyExactContQ(q, N)\n",
    "    println(\"Policy Completed\")\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        bestA = policy[s]\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return g, gs, policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15b7f9ed",
   "metadata": {},
   "source": [
    "On-Policy equivalent of SMART, using next chosen action instead of next optimal action for the update target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "433d3d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smartOnPolicyTab (generic function with 1 method)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smartOnPolicyTab(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; printProgress = false, modCounter = 100000, stateDepEpsilon = false)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    actionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateActionTrace = []\n",
    "    q = Dict()\n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        for a in enumerateFeasibleActions(s,N)\n",
    "            q[s,a] = 0.0\n",
    "        end\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #choose only action for s = s0\n",
    "    optA = zeros(Int64, N)\n",
    "    optQ = q[s,optA]\n",
    "    optFlag = true\n",
    "\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        numVisits[s] += 1\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        push!(stateActionTrace, (s,bestA))\n",
    "\n",
    "        nextOptA = zeros(Int64, N)\n",
    "        nextOptQ = 0.0\n",
    "\n",
    "        #update q, flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            #simulate transition\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "  \n",
    "            #update g\n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "\n",
    "            #find next e-greedy action and q value\n",
    "            #find optimal action and q-value\n",
    "            optFlag = true\n",
    "            nextOptAandQ = actionFromQTab(sPrime, N, q)\n",
    "            nextOptA = nextOptAandQ[1]\n",
    "            nextOptQ = nextOptAandQ[2]\n",
    "\n",
    "            #choose epsilon\n",
    "            epsilon = c/(c + n)\n",
    "            \n",
    "            if stateDepEpsilon\n",
    "                epsilon = c/(c + numVisits[sPrime])\n",
    "            end\n",
    "\n",
    "            #select random action with probability epsilon\n",
    "            if rand(Uniform(0,1)) < epsilon\n",
    "                nextOptA = randomAction(sPrime, N)\n",
    "                nextOptQ = q[sPrime,nextOptA]\n",
    "                optFlag = false\n",
    "            end\n",
    "            \n",
    "            for saPair in stateActionTrace\n",
    "                st = saPair[1]\n",
    "                q[saPair] += (b/(b + numVisits[st]))*(c + nextOptQ - g*time - q[saPair])\n",
    "            end\n",
    "\n",
    "            stateActionTrace = []\n",
    "        else\n",
    "            sPrime = s - bestA\n",
    "\n",
    "            optFlag = true\n",
    "            nextOptAandQ = actionFromQTab(sPrime, N, q)\n",
    "            nextOptA = nextOptAandQ[1]\n",
    "            nextOptQ = nextOptAandQ[2]\n",
    "\n",
    "            #choose epsilon\n",
    "            epsilon = c/(c + n)\n",
    "            \n",
    "            if stateDepEpsilon\n",
    "                epsilon = c/(c + numVisits[sPrime])\n",
    "            end\n",
    "\n",
    "            #select random action with probability epsilon\n",
    "            if rand(Uniform(0,1)) < epsilon\n",
    "                nextOptA = randomAction(sPrime, N)\n",
    "                nextOptQ = q[sPrime,nextOptA]\n",
    "                optFlag = false\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        s = sPrime\n",
    "        optA = nextOptA\n",
    "        optQ = nextOptQ\n",
    "\n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return q, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70994d31",
   "metadata": {},
   "source": [
    "Version of SMART using moving average window to approximate g, discarding older data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d8fa137b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smartTabMA (generic function with 1 method)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SMART with an MA approximation for g\n",
    "function smartTabMA(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; window = 1000000, printProgress = false, modCounter = 100000, stateDepEpsilon = false)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    actionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    totalCosts = [0.0]\n",
    "    lenTotalCosts = 1\n",
    "    totalTimes = [0.0]\n",
    "    lenTotal = 1\n",
    "    stateActionTrace = []\n",
    "    q = Dict()\n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        for a in enumerateFeasibleActions(s,N)\n",
    "            q[s,a] = 0.0\n",
    "        end\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    optAandQ = actionFromQTab(s, N, q)\n",
    "    optA = optAandQ[1]\n",
    "    optQ = optAandQ[2]\n",
    "\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        numVisits[s] += 1\n",
    "        \n",
    "        optFlag = true\n",
    "        \n",
    "        #choose e-greedy action\n",
    "        epsilon = c/(c + n)\n",
    "        if stateDepEpsilon\n",
    "            epsilon = c/(c + numVisits[s])\n",
    "        end\n",
    "\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            optA = randomAction(s, N)\n",
    "            optQ = q[s,optA]\n",
    "            optFlag = false\n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        push!(stateActionTrace, (s,bestA))\n",
    "\n",
    "        nextOptA = zeros(Int64, N)\n",
    "        nextOptQ = 0.0\n",
    "        #update q, flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            #simulate transition\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "  \n",
    "            #update g if optimal action taken\n",
    "            if optFlag\n",
    "                runningTotal += c\n",
    "                timePassed += time\n",
    "                push!(totalCosts, runningTotal)               \n",
    "                push!(totalTimes, timePassed)\n",
    "                lenTotal += 1\n",
    "                if lenTotal <= window\n",
    "                    g = runningTotal/timePassed\n",
    "                else\n",
    "                    g = (runningTotal - totalCosts[lenTotal - window])/(timePassed - totalTimes[lenTotal - window])\n",
    "                end\n",
    "            end\n",
    "\n",
    "            #find next optimal action and q value\n",
    "            nextOptAandQ = actionFromQTab(sPrime, N, q)\n",
    "            nextOptA = nextOptAandQ[1]\n",
    "            nextOptQ = nextOptAandQ[2]\n",
    "\n",
    "            for saPair in stateActionTrace\n",
    "                st = saPair[1]\n",
    "                q[saPair] += (b/(b + numVisits[st]))*(c + nextOptQ - g*time - q[saPair])\n",
    "            end\n",
    "\n",
    "            stateActionTrace = []\n",
    "        else\n",
    "            sPrime = s - bestA\n",
    "\n",
    "            nextOptAandQ = actionFromQTab(sPrime, N, q)\n",
    "            nextOptA = nextOptAandQ[1]\n",
    "            nextOptQ = nextOptAandQ[2]\n",
    "        end\n",
    "        \n",
    "        s = sPrime\n",
    "        optA = nextOptA\n",
    "        optQ = nextOptQ\n",
    "\n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return q, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "199fc408",
   "metadata": {},
   "source": [
    "# Tabular SMARPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "29ea47f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeTabST (generic function with 1 method)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SMARPE with tabular representation instead of VFA, and state trace \n",
    "function smarpeTabST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, hIn, g0, nMax, b; copyH = false, printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    policy = piPolicyExactCont(hIn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, g0)\n",
    "    println(\"Policy Constructed\")\n",
    "    stateTrace = []\n",
    "    \n",
    "    h = Dict()\n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        if copyH\n",
    "            h[s] = hIn[s]\n",
    "        else\n",
    "            h[s] = 0.0\n",
    "        end\n",
    "        \n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of SMARPE\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #formulate optimal action\n",
    "        optA = policy[s]\n",
    "        if optA == zeros(Int64, N)\n",
    "            t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "        end\n",
    "\n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #if action is passive, update VFA across state trace and simulate the next state, and update g. otherwise, simply update current state\n",
    "        if bestA == zeros(Int64, N)\n",
    "            bestV = optV - h[s0]\n",
    "            for st in stateTrace\n",
    "                currentEst = h[st]\n",
    "                h[st] += (b/(b + numVisits[st]))*(bestV - currentEst)\n",
    "            end\n",
    "            stateTrace = []\n",
    "\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9483ef10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeTabStochST (generic function with 1 method)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uses tabular representation instead of VFA, e-greedy action selection, and state trace \n",
    "function smarpeTabStochST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateTrace = []\n",
    "    \n",
    "    h = Dict()\n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of SMARPE\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #choose random action\n",
    "        optA = randomAction(s,N)\n",
    "        if optA == zeros(Int64, N)\n",
    "            t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "        end\n",
    "\n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #if action is passive, update VFA across state trace and simulate the next state, and update g. otherwise, simply update current state\n",
    "        if bestA == zeros(Int64, N)\n",
    "            bestV = optV - h[s0]\n",
    "            for st in stateTrace\n",
    "                currentEst = h[st]\n",
    "                h[st] += (b/(b + numVisits[st]))*(bestV - currentEst)\n",
    "            end\n",
    "            stateTrace = []\n",
    "\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2da93d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeTabST_epsSoft_onPolicy (generic function with 1 method)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tabular SMARPE with state trace using e-soft policy\n",
    "function smarpeTabST_epsSoft_onPolicy(N,alpha_d, alpha_r, beta, tau, c0, c1, r, hIn, g0, nMax, b, c; copyH = false, printProgress = false, modCounter = 100000, stateDepEpsilon = true)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    policy = piPolicyExactCont(hIn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, g0)\n",
    "    println(\"Policy Constructed\")\n",
    "    stateTrace = []\n",
    "    \n",
    "    h = Dict()\n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        if copyH\n",
    "            h[s] = hIn[s]\n",
    "        else\n",
    "            h[s] = 0.0\n",
    "        end\n",
    "        \n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of SMARPE\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #formulate action\n",
    "        optA = policy[s]\n",
    "        optV = 0.0\n",
    "        if optA == zeros(Int64, N)\n",
    "            t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "        end\n",
    "\n",
    "        #e-greedy action\n",
    "        bestA = optA\n",
    "        epsilon = c/(c + n)\n",
    "        if stateDepEpsilon\n",
    "            epsilon = c/(c + numVisits[s])\n",
    "        end\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            bestA = randomAction(s,N)\n",
    "            if bestA == zeros(Int64, N)\n",
    "                t = sojournTime(s, bestA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "                optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "            end\n",
    "        end\n",
    "\n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #if action is passive, update VFA across state trace and simulate the next state, and update g. otherwise, simply update current state\n",
    "        if bestA == zeros(Int64, N)\n",
    "            bestV = optV - h[s0]\n",
    "            for st in stateTrace\n",
    "                currentEst = h[st]\n",
    "                h[st] += (b/(b + numVisits[st]))*(bestV - currentEst)\n",
    "            end\n",
    "            stateTrace = []\n",
    "\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe61cfb6",
   "metadata": {},
   "source": [
    "# SMARVI - New VFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2411428a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subStates (generic function with 1 method)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns substates of edges in an array, and state of destination node\n",
    "function subStates(s, N, flows)\n",
    "    sis = []\n",
    "    sn = 0\n",
    "    for i in 1:N\n",
    "        if s[i] == 2 || s[i] == 3\n",
    "            push!(sis, s[i])\n",
    "        elseif flows[i] == 0\n",
    "            push!(sis, 0)\n",
    "        else\n",
    "            push!(sis, 1)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if flows == fill(0.0, N)\n",
    "        sn = 1\n",
    "    end\n",
    "    \n",
    "    return sis, sn\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b40410e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v (generic function with 4 methods)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates v from seperate ve and vn tables\n",
    "function v(s::Vector{Int64}, N::Int64, flows::Vector{Float64}, ve::Dict, vn::Dict)\n",
    "    substates = subStates(s, N, flows)\n",
    "    sis = substates[1]\n",
    "    sn = substates[2]\n",
    "\n",
    "    v = 0.0\n",
    "    for i in 1:N\n",
    "        si = sis[i]\n",
    "        v += ve[i,si]\n",
    "    end\n",
    "\n",
    "    v += vn[sn]\n",
    "\n",
    "    return v\n",
    "end\n",
    "\n",
    "function v(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "    flowsAndCost = calculateFlows(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    return v(s, N, flowsAndCost[1], ve, vn)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "bdcbb3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueContNewVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculates E(h(s')) given a state-action pair, and VFA from ve and vn tables\n",
    "function expectedNextValueContNewVFA(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, ve, vn)\n",
    "    del = sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    #different treatment for all-damaged state\n",
    "    if sPrime == fill(3,N)\n",
    "        return v(sPrime,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "    end\n",
    "    \n",
    "    runningTotal = 0\n",
    "    \n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*v(sNext,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            runningTotal += alpha_r[k]*del*v(sNext,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                runningTotal += (tau(repair)/repair)*del*v(sNext,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal\n",
    "end   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e63f3219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarActionAndVFromNewVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smarActionAndVFromNewVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn, g)\n",
    "    #find optimal action\n",
    "    optA = zeros(Int64,N)\n",
    "    t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContNewVFA(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, ve, vn) - g*t\n",
    "    zeroV = optV\n",
    "\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64, N)\n",
    "            a[i] = 1\n",
    "            \n",
    "            testV = v(s-a, N, flows, ve, vn)\n",
    "            if testV <= optV\n",
    "                optV = testV\n",
    "                optA = a\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "        \n",
    "    #Fix choose optimal non-passive action if state is [3,3,...,3]\n",
    "    if s == fill(3,N) && optA == zeros(Int64, N)\n",
    "        optA[1] = 1\n",
    "        optV = v(s-optA, N, flows, ve, vn)\n",
    "            \n",
    "        for i in 2:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "\n",
    "                testV = v(s-a, N, flows, ve, vn)\n",
    "                if testV <= optV\n",
    "                    optV = testV\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return optA, optV, zeroV\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "66a7c3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updateVFA (generic function with 3 methods)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function updateVFA(s, substates, target, ve, vn, numVisitsE, numVisitsN, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "    currentEst = v(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "    sis = substates[1]\n",
    "    sn = substates[2]\n",
    "\n",
    "    for i in 1:N \n",
    "        si = sis[i]\n",
    "        ve[i, si] += (b/(b + numVisitsE[i, si]))*(target - currentEst)\n",
    "    end\n",
    "\n",
    "    vn[sn] += (b/(b + numVisitsN[sn]))*(target - currentEst)\n",
    "\n",
    "    return ve, vn\n",
    "end\n",
    "\n",
    "function updateVFA(s, substates, target, ve, vn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, stepsize)\n",
    "    currentEst = v(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "    sis = substates[1]\n",
    "    sn = substates[2]\n",
    "\n",
    "    for i in 1:N \n",
    "        si = sis[i]\n",
    "        ve[i, si] += stepsize*(target - currentEst)\n",
    "    end\n",
    "\n",
    "    vn[sn] += stepsize*(target - currentEst)\n",
    "\n",
    "    return ve, vn\n",
    "end\n",
    "\n",
    "function updateVFA(s, substates, target, ve, vn, n, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "    currentEst = v(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "    sis = substates[1]\n",
    "    sn = substates[2]\n",
    "\n",
    "    for i in 1:N \n",
    "        si = sis[i]\n",
    "        ve[i, si] += (b/(b + n))*(target - currentEst)\n",
    "    end\n",
    "\n",
    "    vn[sn] += (b/(b + n))*(target - currentEst)\n",
    "\n",
    "    return ve, vn\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "379e3f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviNewVFA_ST (generic function with 1 method)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uses new VFA architecture, e-greedy action selection, and state trace \n",
    "#stepsizeType options: \n",
    "# - varyByNumVisits: uses stepsize b/(b + numVisits)\n",
    "# - varyByIteration: uses stepsize b/(b + n) where n is the iteration modCounter\n",
    "# - constant: uses stepsize b\n",
    "#c is used for calculating epsilon = c/(c + n)\n",
    "#d is used for calculating d/nlog(n), the stepsize for g\n",
    "function smarviNewVFA_ST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c, d; g = 0.0, stepsizeType = \"constant\", printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    gs = [g]\n",
    "    stateTrace = []\n",
    "    \n",
    "    #initialise ve and vn tables\n",
    "    ve = Dict()\n",
    "    numVisitsE = Dict()\n",
    "    for i in 1:N\n",
    "        for si in 0:3\n",
    "            ve[i,si] = 0.0\n",
    "            numVisitsE[i,si] = 0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    vn = Dict()\n",
    "    numVisitsN = Dict()\n",
    "    for i in 0:1\n",
    "        vn[i] = 0.0\n",
    "        numVisitsN[i] = 0\n",
    "    end\n",
    "\n",
    "    numVisitsG = 0\n",
    "    vs0Hist = [0.0]\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    flows0 = copy(flows)\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        substates = subStates(s, N, flows)\n",
    "        sis = substates[1]\n",
    "        sn = substates[2]\n",
    "        for i in 1:N\n",
    "            numVisitsE[i,sis[i]] += 1\n",
    "        end\n",
    "\n",
    "        numVisitsN[sn] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #formulate optimal action and v value\n",
    "        optAandV = smarActionAndVFromNewVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn, g)\n",
    "        optA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        zeroV = optAandV[3]\n",
    "\n",
    "        #choose epsilon\n",
    "        epsilon = c/(c + n)\n",
    "\n",
    "        #if random action chosen, choose action action and v value\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            optA = randomAction(s, N)\n",
    "            if optA == zeros(Int64, N) \n",
    "                optV = zeroV\n",
    "            else \n",
    "                optV = v(s - optA, N, flows, ve, vn)\n",
    "            end \n",
    "        end \n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV \n",
    "        \n",
    "        #update VFA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            for st in stateTrace\n",
    "                if stepsizeType == \"varyByNumVisits\"\n",
    "                    ve,vn = updateVFA(st, substates, bestV, ve, vn, numVisitsE, numVisitsN, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "                elseif stepsizeType == \"constant\"\n",
    "                    ve,vn = updateVFA(st, substates, bestV, ve, vn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "                elseif stepsizeType == \"varyByIteration\"\n",
    "                    ve,vn = updateVFA(st, substates, bestV, ve, vn, n, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "                else\n",
    "                    println(\"Invalid stepsize rule\")\n",
    "                    return 0\n",
    "                end\n",
    "\n",
    "                push!(vs0Hist, v(s0, N, flows0, ve, vn))\n",
    "            end\n",
    "            stateTrace = []\n",
    "        end\n",
    "\n",
    "        #update state, flows and g\n",
    "        if bestA == zeros(Int64, N)\n",
    "            #find simulated next state, cost, flows and sampled sojourn time\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            gTarget = (g*timePassed + c)/(timePassed + time)\n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            numVisitsG += 1\n",
    "            g += d*(gTarget - g)\n",
    "            \n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return ve, vn, g, gs, vs0Hist\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fba49dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationNewVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gEvaluationNewVFA(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, ve, vn, g0; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateTrace = []\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action and v value\n",
    "        optAandV = smarActionAndVFromNewVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn, g)\n",
    "        optA = optAandV[1]\n",
    "\n",
    "        #update state, flows and g\n",
    "        if optA == zeros(Int64, N)\n",
    "            #find simulated next state, cost, flows and sampled sojourn time\n",
    "            result = updateStateAndFlowsCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - optA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9dd63ad",
   "metadata": {},
   "source": [
    "# New Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4f606ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarActionAndVFromNewVFA_fa (generic function with 1 method)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smarActionAndVFromNewVFA_fa(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn, g; forceZeroVCalc = false)\n",
    "    #find optimal action\n",
    "    optA = faAction(s)\n",
    "    optV = 0.0\n",
    "    zeroV = 0.0\n",
    "    \n",
    "    #force calculation of zeroV if required\n",
    "    if forceZeroVCalc\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        zeroV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContNewVFA(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, ve, vn) - g*t\n",
    "    end\n",
    "\n",
    "    #handle different cases for action choice and forceZeroVCalc\n",
    "    if optA == zeros(Int64, N) && forceZeroVCalc\n",
    "        optV = zeroV\n",
    "    elseif optA == zeros(Int64, N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContNewVFA(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, ve, vn) - g*t\n",
    "    else\n",
    "        optV = v(s-optA, N, flows, ve, vn)\n",
    "    end\n",
    "    \n",
    "    #return values based on forceZeroVCalc\n",
    "    if forceZeroVCalc\n",
    "        return optA, optV, zeroV\n",
    "    else\n",
    "        return optA, optV\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a95985e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeNewVFA_ST_fa (generic function with 1 method)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smarpeNewVFA_ST_fa(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, d; g = 0.0, stepsizeType = \"constant\", printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    s3 = [3 for i in 1:N]\n",
    "\n",
    "    flows = zeros(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    gs = [g]\n",
    "    stateTrace = []\n",
    "    \n",
    "    #initialise ve and vn tables\n",
    "    ve = Dict()\n",
    "    numVisitsE = Dict()\n",
    "    for i in 1:N\n",
    "        for si in 0:3\n",
    "            ve[i,si] = 0.0\n",
    "            numVisitsE[i,si] = 0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    vn = Dict()\n",
    "    numVisitsN = Dict()\n",
    "    for i in 0:1\n",
    "        vn[i] = 0.0\n",
    "        numVisitsN[i] = 0\n",
    "    end\n",
    "\n",
    "    numVisitsG = 0\n",
    "    vs0Hist = [0.0]\n",
    "    vs3Hist = [0.0]\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    flows0 = copy(flows)\n",
    "    flows3 = fill(0.0, N)\n",
    "\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        substates = subStates(s, N, flows)\n",
    "        sis = substates[1]\n",
    "        sn = substates[2]\n",
    "        for i in 1:N\n",
    "            numVisitsE[i,sis[i]] += 1\n",
    "        end\n",
    "\n",
    "        numVisitsN[sn] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #formulate fully active action and v value\n",
    "        optAandV = smarActionAndVFromNewVFA_fa(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn, g)\n",
    "        optA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV \n",
    "        \n",
    "        #update VFA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            for st in stateTrace\n",
    "                if stepsizeType == \"varyByNumVisits\"\n",
    "                    ve,vn = updateVFA(st, substates, bestV, ve, vn, numVisitsE, numVisitsN, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "                elseif stepsizeType == \"constant\"\n",
    "                    ve,vn = updateVFA(st, substates, bestV, ve, vn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "                elseif stepsizeType == \"varyByIteration\"\n",
    "                    ve,vn = updateVFA(st, substates, bestV, ve, vn, n, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "                else\n",
    "                    println(\"Invalid stepsize rule\")\n",
    "                    return 0\n",
    "                end\n",
    "\n",
    "                push!(vs0Hist, v(s0, N, flows0, ve, vn))\n",
    "                push!(vs3Hist, v(s3, N, flows3, ve, vn))\n",
    "            end\n",
    "            stateTrace = []\n",
    "        end\n",
    "\n",
    "        #update state, flows and g\n",
    "        if bestA == zeros(Int64, N)\n",
    "            #find simulated next state, cost, flows and sampled sojourn time\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            numVisitsG += 1\n",
    "            g = runningTotal/timePassed #use basic calculation for g due to stationary policy (could be replaced by slower version to reduce noise)\n",
    "            \n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            show(n)\n",
    "            println()\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return ve, vn, g, gs, vs0Hist, vs3Hist\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b30394b",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9a2a5c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 100.0\n",
       " 200.0\n",
       " 300.0\n",
       " 400.0\n",
       " 500.0"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "function tau(x)\n",
    "    return x\n",
    "end\n",
    "\n",
    "alpha_d = [0.01*i for i in 1:N]\n",
    "alpha_r = [0.001*i for i in 1:N] \n",
    "beta=10.0\n",
    "c0=[1.0*i for i in 1:N] \n",
    "c1=100.0\n",
    "r=[100.0*i for i in 1:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "cabf028c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29.733161017644214"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nMax = 10000000\n",
    "result = smarpeNewVFA_ST_fa(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, 0.001, 0.1; printProgress = true, modCounter = 1000000)\n",
    "result[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "eda6df04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x000000007C94CCA0>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = floor(Int64, nMax/10)\n",
    "#start = 1\n",
    "finish = nMax\n",
    "PyPlot.plot(start:finish,result[4][start:finish])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "66a47929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1334.010753781092\n",
      "165.5838917817632\n"
     ]
    }
   ],
   "source": [
    "ve = result[1]\n",
    "vn = result[2]\n",
    "println(v([1,1,1,1,1],N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn))\n",
    "println(v([3,3,3,3,3],N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4dc604ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 2 entries:\n",
       "  0 => -276.831\n",
       "  1 => 165.584"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0c492101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x000000007C98BEB0>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs0Hist = result[5]\n",
    "start = floor(Int64, nMax/10)\n",
    "#start = 1\n",
    "PyPlot.plot(vs0Hist[start:nMax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d78c5621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x000000020B98F6D0>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs3Hist = result[6]\n",
    "start = floor(Int64, nMax/10)\n",
    "#start = 1\n",
    "PyPlot.plot(vs3Hist[start:nMax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "467c8c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.83290795943987"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalNMax = 1000000\n",
    "g0 = result[3]\n",
    "gs = gEvaluationNewVFA(N,alpha_d, alpha_r, beta, tau, c0, c1, r, evalNMax, ve, vn, g0; printProgress = true, modCounter = 100000)\n",
    "gs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "38bfecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x000000007C8CF2B0>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = floor(Int64, evalNMax/10)\n",
    "finish = evalNMax\n",
    "#start = 1\n",
    "PyPlot.plot(gs[2][start:finish])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e89ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

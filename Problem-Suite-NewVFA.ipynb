{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c967fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions\n",
    "using Random\n",
    "using Plots\n",
    "using PyPlot\n",
    "using StatsBase\n",
    "using StatsPlots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b1ef523",
   "metadata": {},
   "source": [
    "# Problem-Suite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebbc7791",
   "metadata": {},
   "source": [
    "Problem-Suite is a large structured notebook containing all of the functions created so far for this project.\n",
    "\n",
    "Sections:\n",
    "\n",
    "-[Miscellaneous Functions](#Miscellaneous-Functions)\n",
    "\n",
    "-[Pre-requisite functions for uniformised AVI](#Pre-requisite-functions-for-uniformised-AVI)\n",
    "\n",
    "-[Uniformised AVI functions](#Uniformised-AVI-functions)\n",
    "\n",
    "-[Pre-requisite functions for SMARVI](#Pre-requisite-functions-for-SMARVI)\n",
    "\n",
    "-[SMARVI Functions](#SMARVI-Functions)\n",
    "\n",
    "-[Pre-requisite Functions for Exact DP on Homogeneous Problems](#Pre-requisite-Functions-for-Exact-DP-on-Homogeneous-Problems)\n",
    "\n",
    "-[Exact DP on Homogeneous Problems (RVIA and PE/PI)](#Exact-DP-for-Homogeneous-problem)\n",
    "\n",
    "-[Pre-requisite Functions for Exact DP on Inhomogeneous Problems](#Pre-requisite-Functions-for-Exact-DP-on-Inhomogeneous-Problems)\n",
    "\n",
    "-[Exact DP on Inhomogeneous Problems (RVIA and PE/PI)](#Exact-DP-for-Inhomogeneous-Problem-(using-exact-h-or-VFA))\n",
    "\n",
    "-[Evaluation via simulation](#Evaluation-via-simulation)\n",
    "\n",
    "-[APE on Fully Active Policy](#APE-on-Fully-Active-Policy)\n",
    "\n",
    "-[SMARPE](#SMARPE)\n",
    "\n",
    "-[Tabular SMARVI and gEval](#tabular-smarvi-and-geval)\n",
    "\n",
    "-[SMART Functions](#SMART-Functions)\n",
    "\n",
    "-[New Functions](#new-functions)\n",
    "\n",
    "-[Tests](#Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12fe12",
   "metadata": {},
   "source": [
    "# Miscellaneous Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2556d9f",
   "metadata": {},
   "source": [
    "-Functions for enumerating state and action spaces\n",
    "\n",
    "-Functions for calculating flows given a state or state-action pair\n",
    "\n",
    "-Function for evaluating a VFA at a given state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a0da98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arrayToString (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#produce an array of array representations of all possible states\n",
    "function enumerateStates(N::Int64)\n",
    "    if N==1\n",
    "        return [[1],[2],[3]]\n",
    "    end\n",
    "    \n",
    "    output = []\n",
    "    lower = enumerateStates(N-1)\n",
    "    for s in lower\n",
    "        new1 = append!([1],s)\n",
    "        new2 = append!([2],s)\n",
    "        new3 = append!([3],s)\n",
    "        append!(output,[new1])\n",
    "        append!(output,[new2])\n",
    "        append!(output,[new3])\n",
    "    end\n",
    "    \n",
    "    return output\n",
    "end\n",
    "\n",
    "#produce an array of array representations of all possible actions\n",
    "function enumerateActions(N::Int64)\n",
    "    if N==1\n",
    "        return [[0],[1]]\n",
    "    end\n",
    "    \n",
    "    output = []\n",
    "    lower = enumerateActions(N-1)\n",
    "    for a in lower\n",
    "        new1 = append!([0],a)\n",
    "        new2 = append!([1],a)\n",
    "        append!(output,[new1])\n",
    "        append!(output,[new2])\n",
    "    end\n",
    "    \n",
    "    return output\n",
    "end    \n",
    "\n",
    "#produce array of array representations of all restricted, or single-repair, actions\n",
    "function enumerateRestrictedActions(N::Int64)\n",
    "    if N==1\n",
    "        return [[0],[1]]\n",
    "    end\n",
    "    \n",
    "    output = [zeros(Int64,N)]\n",
    "    for i in 1:N\n",
    "        temp = zeros(N)\n",
    "        temp[i] = 1\n",
    "        append!(output,[temp])\n",
    "    end\n",
    "    \n",
    "    return output\n",
    "end\n",
    "\n",
    "#convert all array elements to string, then concatanate all elements (DEPRECATED AS DICTS CAN TAKE ARRAYS AS KEYS)\n",
    "function arrayToString(x)\n",
    "    return join(string.(x))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ba543e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculateFlows (generic function with 2 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function for calculating the flows given a state\n",
    "function calculateFlows(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    #update flows\n",
    "    flows = zeros(N)\n",
    "    healthy = sum(i == 1 for i in s)\n",
    "    \n",
    "    #if no links are healthy, return \n",
    "    if healthy == 0\n",
    "        return flows, c1\n",
    "    end\n",
    "    \n",
    "    #otherwise, find best route, and return\n",
    "    bestCost = maximum(c0) + 1\n",
    "    usedLink = 0\n",
    "    for k in 1:N\n",
    "        if s[k] == 1 && c0[k] < bestCost\n",
    "            bestCost = c0[k]\n",
    "            usedLink = k\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[usedLink] = beta\n",
    "    \n",
    "    return flows, bestCost\n",
    "end\n",
    "\n",
    "#function for calculating the flows given a state-action pair\n",
    "function calculateFlows(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    sPrime = s - a\n",
    "    return calculateFlows(sPrime,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "127d3f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate a VFA at a given state\n",
    "function v(s::Vector{Int64}, params::Vector{Float64}, features::Vector{Function})\n",
    "    numFeatures = length(features)\n",
    "    return params[1] + sum(params[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960bf4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v (generic function with 2 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version of v that takes flows for the features\n",
    "function v(s::Vector{Int64}, flows::Vector{Float64}, params::Vector{Float64}, features::Vector{Function})\n",
    "    N = length(params)\n",
    "    return params[1] + sum(params[i]*features[i-1](s, flows) for i in 2:N)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b05d0fc",
   "metadata": {},
   "source": [
    "# Pre-requisite functions for uniformised AVI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c56072f",
   "metadata": {},
   "source": [
    "This section contains functions used within the AVI algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "476755cd",
   "metadata": {},
   "source": [
    "Given a state-action pair, return the next random pre-decision state, the instant cost, and the updated flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d157b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updateStateAndFlowsUnif (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function updateStateAndFlowsUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    #observe exogenous information\n",
    "    w = rand(Uniform(0, 1))\n",
    "    \n",
    "    #interpret exog info: is it a demand deg, rare deg, or completed repair \n",
    "    found = false\n",
    "    runningTotal = 0\n",
    "    \n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        if runningTotal <= w <= runningTotal + flows[k]*alpha_d[k]*del\n",
    "            found = true\n",
    "            sPrime[k] = 3\n",
    "            #println(\"Demand Deg at \"*string.(k))\n",
    "            break\n",
    "        end\n",
    "        runningTotal = runningTotal + flows[k]*alpha_d[k]*del\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    if found == false\n",
    "        for k in 1:N\n",
    "            if runningTotal <= w <= runningTotal + alpha_r[k]*del\n",
    "                found = true\n",
    "                sPrime[k] = 3\n",
    "                #println(\"Rare Deg at \"*string.(k))\n",
    "                break\n",
    "            end\n",
    "            runningTotal = runningTotal + alpha_r[k]*del\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if found == false && repair > 0\n",
    "        if runningTotal <= w <= runningTotal + tau(repair)*del\n",
    "            found = true\n",
    "            #find all repairing links\n",
    "            repairing = []\n",
    "            for k in 1:N\n",
    "                if sPrime[k] == 2\n",
    "                    append!(repairing,[k])\n",
    "                end\n",
    "            end\n",
    "            repaired = sample(repairing)\n",
    "            sPrime[repaired] = 1\n",
    "            #println(\"Repair completed at \"*string.(repaired))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if found == false\n",
    "        #println(\"No Event\")\n",
    "    end\n",
    "    \n",
    "    #update flows\n",
    "    flowUpdate = calculateFlows(sPrime,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    newFlows = flowUpdate[1]\n",
    "    bestCost = flowUpdate[2]\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    \n",
    "    return sPrime, (beta*bestCost + sum(r[k]*(sPrime[k]==2) for k in 1:N))*del, newFlows\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "836f070e",
   "metadata": {},
   "source": [
    "Given a state action pair, return the instant cost over the delta timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "685eb320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instantCostUnif (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instant cost over the timestep\n",
    "function instantCostUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(sPrime[i] == 1 for i in 1:N)\n",
    "    repair = sum(sPrime[i] == 2 for i in 1:N)\n",
    "    damaged = sum(sPrime[i] == 3 for i in 1:N)\n",
    "    \n",
    "    #update flows\n",
    "    flowUpdate = calculateFlows(sPrime,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    newFlows = flowUpdate[1]\n",
    "    bestCost = flowUpdate[2]\n",
    "    \n",
    "    return (beta*bestCost + sum(r[k]*(sPrime[k]==2) for k in 1:N))*del\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9603d5cd",
   "metadata": {},
   "source": [
    "Given a state-action pair and a VFA, calculate the expected value of the value function after one timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0a307f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueUnif (generic function with 2 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculates E(h(s')) given a state-action pair, and a VFA for h. Also used in Exact PE/PI when using a VFA\n",
    "#One version takes flows as an argument, the other calculates the flows\n",
    "function expectedNextValueUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    runningTotal = 0.0\n",
    "    runningTotalProb = 0.0\n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*v(sNext, vParams, features)\n",
    "        runningTotalProb += flows[k]*alpha_d[k]*del\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            runningTotal += alpha_r[k]*del*v(sNext, vParams, features)\n",
    "            runningTotalProb += alpha_r[k]*del\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                runningTotal += (tau(repair)/repair)*del*v(sNext, vParams, features)\n",
    "                runningTotalProb += (tau(repair)/repair)*del\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal + (1 - runningTotalProb)*v(sPrime, vParams, features)\n",
    "end  \n",
    "\n",
    "function expectedNextValueUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, vParams, features)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    flows = calculateFlows(sPrime,N,alpha_d, alpha_r, beta, tau, c0, c1, r)[1]\n",
    "    runningTotal = 0.0\n",
    "    runningTotalProb = 0.0\n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*v(sNext, vParams, features)\n",
    "        runningTotalProb += flows[k]*alpha_d[k]*del\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            runningTotal += alpha_r[k]*del*v(sNext, vParams, features)\n",
    "            runningTotalProb += alpha_r[k]*del\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                runningTotal += (tau(repair)/repair)*del*v(sNext, vParams, features)\n",
    "                runningTotalProb += (tau(repair)/repair)*del\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal + (1 - runningTotalProb)*v(sPrime, vParams, features)\n",
    "end  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3920172",
   "metadata": {},
   "source": [
    "# Uniformised AVI functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80cbe1e5",
   "metadata": {},
   "source": [
    "Algorithms that perform RAVI on the uniformised version of the problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5310d49c",
   "metadata": {},
   "source": [
    "Given some parallel link problem and VFA architecture, perform RAVI, approximating E(h(s')) for update targets using just h(s'), where s' is the next simulated state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f83714d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aviApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in uniformised setting, approximating E(h(s')) for update targets using just h(s'), where s' is the next simulated state\n",
    "function aviApprox(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; delScale = 1.0, printProgress = false, modCounter = 100000, forceActive = false)\n",
    "    #initialise\n",
    "    del = 1.0/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        optV = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features) - g\n",
    "        \n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #Fix random link if optA is passive for [3,3,...,3]\n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64, N)\n",
    "            optA[1] = 1\n",
    "            optV = v(s-optA, vParams, features)\n",
    "            \n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        c = instantCostUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "        bestV = c + v(sPrime, vParams, features) - v(s0, vParams,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = v(s, vParams, features)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        c = result[2]\n",
    "        s = sPrime\n",
    "        flows = result[3]\n",
    "        g += (1/n)*(c - g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "718d21d7",
   "metadata": {},
   "source": [
    "Given some parallel link problem and VFA architecture, perform RAVI, using a full expectation for update targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb36c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aviFull (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in uniformised setting, approximating E(h(s')) using all possible transitions\n",
    "function aviFull(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; delScale = 1.0, printProgress = false, modCounter = 100000, forceActive = false)\n",
    "    #initialise\n",
    "    del = 1.0/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        optV = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features) - g\n",
    "        \n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #Fix random link if optA is passive for [3,3,...,3]\n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64, N)\n",
    "            optA[1] = 1\n",
    "            optV = v(s-optA, vParams, features)\n",
    "            \n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        c = instantCostUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "        bestV = c + expectedNextValueUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features) - v(s0, vParams,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = v(s, vParams, features)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        c = result[2]\n",
    "        s = sPrime\n",
    "        flows = result[3]\n",
    "        g += (1/n)*(c - g)\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d76fa41",
   "metadata": {},
   "source": [
    "Similar to above, but only uses the Binary Action Space (BAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ebdac30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aviUnifBAS (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI with BAS in uniformised setting, approximating E(h(s')) using all possible transitions\n",
    "function aviUnifBAS(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; delScale = 1.0, printProgress = false, modCounter = 100000, forceActive = false)\n",
    "    #initialise\n",
    "    del = 1.0/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        vs0 = v(s0, vParams, features)\n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        optV = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features) - vs0\n",
    "        \n",
    "        testA = faAction(s)\n",
    "        testV = instantCostUnif(s,testA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s,testA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features) - vs0\n",
    "        if testV <= optV\n",
    "            optV = testV\n",
    "            optA = testA\n",
    "        end\n",
    "        \n",
    "        #Fix random link if optA is passive for [3,3,...,3]\n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64, N)\n",
    "            optA = testA\n",
    "            optV = testV\n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = v(s, vParams, features)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        c = result[2]\n",
    "        s = sPrime\n",
    "        flows = result[3]\n",
    "        g += (1/n)*(c - g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f587fd5b",
   "metadata": {},
   "source": [
    "# Pre-requisite functions for SMARVI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2008a2c4",
   "metadata": {},
   "source": [
    "Helper functions for the SMARVI algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1f36cda",
   "metadata": {},
   "source": [
    "Given a state-action pair and pre-calculated flows, return the expected sojourn time for the state-action pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1506350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sojournTime (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the expected sojourn time of a state-action pair\n",
    "function sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    s = s - a\n",
    "    if s == fill(3,N)\n",
    "        return 1/(beta*sum(alpha_d) + sum(alpha_r) + tau(N))\n",
    "    end\n",
    "    \n",
    "    numRep = sum(i == 2 for i in s)\n",
    "    cumulativeRate = 0.0\n",
    "    for i in 1:N\n",
    "        if s[i] == 1\n",
    "            cumulativeRate += flows[i]*alpha_d[i] + alpha_r[i]\n",
    "        elseif s[i] == 2\n",
    "            cumulativeRate += alpha_r[i] + tau(numRep)/numRep\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return 1/cumulativeRate\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb2c6d2b",
   "metadata": {},
   "source": [
    "Given a state-action pair and flows, calculate the expected cost accumulated until a transition occurs, or calculate the simulated cost accumulated over a simulated time del."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66c5307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instantCostCont (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the expected cost accumulated until a transition \n",
    "function instantCostCont(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows; del = 0)\n",
    "    if del == 0\n",
    "        del = sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    end\n",
    "    \n",
    "    return instantCostUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ecc13f2",
   "metadata": {},
   "source": [
    "Given a state-action pair, return the next random pre-decision state, the cost accumulated over the sojourn time, and the updated flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75587424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updateStateAndFlowsCont (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Given a state-action pair, return the next random pre-decision state, the cost accumulated over the sojourn time, and the updated flows\n",
    "function updateStateAndFlowsCont(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "    del = sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    actualTime = rand(Exponential(del))\n",
    "    result = updateStateAndFlowsUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "    return result[1], instantCostCont(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows; del = actualTime), result[3], actualTime\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae4efc43",
   "metadata": {},
   "source": [
    "Given a state-action pair, precalculated flows, and a VFA, return the expected value of the VFA after a transition has occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60cda4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueCont (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculates E(h(s')) given a state-action pair, and a VFA for h\n",
    "function expectedNextValueCont(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features)\n",
    "    del = sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    #different treatment for all-damaged state\n",
    "    if sPrime == fill(3,N)\n",
    "        return v(sPrime,vParams,features)\n",
    "    end\n",
    "    \n",
    "    runningTotal = 0\n",
    "    \n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*v(sNext, vParams, features)\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            runningTotal += alpha_r[k]*del*v(sNext, vParams, features)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                runningTotal += (tau(repair)/repair)*del*v(sNext, vParams, features)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal\n",
    "end   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc5b77a7",
   "metadata": {},
   "source": [
    "Similar to above, but assumes the features of the VFA take precalcuated flows as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "488f16a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueContFlows (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculates E(h(s')) given a state-action pair, and a VFA for h\n",
    "#Assumes the VFA is constructed with features taking arguments (s, flows), so flows are precalculated\n",
    "function expectedNextValueContFlows(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features)\n",
    "    del = sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    #different treatment for all-damaged state\n",
    "    if sPrime == fill(3,N)\n",
    "        return v(sPrime, flows, vParams,features)\n",
    "    end\n",
    "    \n",
    "    runningTotal = 0\n",
    "    \n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        flowsNext = calculateFlows(sNext,N,alpha_d, alpha_r, beta, tau, c0, c1, r)[1]\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*v(sNext, flowsNext, vParams, features)\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            flowsNext = calculateFlows(sNext,N,alpha_d, alpha_r, beta, tau, c0, c1, r)[1]\n",
    "            runningTotal += alpha_r[k]*del*v(sNext, flowsNext, vParams, features)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                flowsNext = calculateFlows(sNext,N,alpha_d, alpha_r, beta, tau, c0, c1, r)[1]\n",
    "                runningTotal += (tau(repair)/repair)*del*v(sNext, flowsNext, vParams, features)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal\n",
    "end   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a2e614d",
   "metadata": {},
   "source": [
    "Given a state, flows, and a VFA-g pair, return the optimal action and associated V value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b01347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarActionAndVFromVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smarActionAndVFromVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, vParams, features, g)\n",
    "    #formulate optimal action and calculate optV\n",
    "    optA = zeros(Int64,N)\n",
    "    t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t\n",
    "    \n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64, N)\n",
    "            a[i] = 1\n",
    "            testV = v(s-a, vParams, features)\n",
    "            if testV <= optV\n",
    "                optV = testV\n",
    "                optA = a\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #If wanted, force a repair if optA is passive for [3,3,...,3]\n",
    "    if s == fill(3,N) && optA == zeros(Int64, N)\n",
    "        optA = zeros(Int64,N)\n",
    "        optA[1] = 1\n",
    "        optV = v(s-optA, vParams, features)\n",
    "        \n",
    "        for i in 2:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                testV = v(s-a, vParams, features)\n",
    "                if testV <= optV\n",
    "                    optV = testV\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return optA, optV\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f824e",
   "metadata": {},
   "source": [
    "# SMARVI Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dbccab0",
   "metadata": {},
   "source": [
    "Variety of functions which perform the SMARVI algorithm, with different additional features.\n",
    "For clarity, the \"state-trace\" is a method which collects a sequence of states connected by instantaneous actions together, and ensures they all have the same update target. For example, if in state s we take action a!=0, and in the resulting state s+a we take action 0, both s and s+a will have update target (c + E(V(s')) - gt)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39c05112",
   "metadata": {},
   "source": [
    "Given a problem and a VFA architecture, perform SMARVI, with no e-greedy action selection or state trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea289cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarvi (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs SMARVI\n",
    "function smarvi(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action and calculate optV\n",
    "        optAandV = smarActionAndVFromVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, vParams, features, g)\n",
    "        \n",
    "        bestA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        if bestA == zeros(Int64,N)\n",
    "            bestV = optV - v(s0, vParams,features)\n",
    "        else\n",
    "            bestV = optV - v(s0, vParams,features)\n",
    "        end \n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5c6e48e",
   "metadata": {},
   "source": [
    "Perform SMARVI with a state trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2005234a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviST (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in continuous time setting, approximating E(h(s')) as h(s') where s' is the next simulated state\n",
    "function smarviST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    \n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    stateTrace = []\n",
    "    actionFlag = false\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        #update stateTrace\n",
    "        append!(stateTrace, [s])\n",
    "        \n",
    "        #formulate optimal action and calculate optV\n",
    "        optAandV = smarActionAndVFromVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, vParams, features, g)\n",
    "        \n",
    "        bestA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #if optimal action is passive, update VFA for all states in the stateTrace, and simulate the next state\n",
    "        if bestA == zeros(Int64, N)\n",
    "            \n",
    "            #find simulated next state\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "        \n",
    "            bestV = optV - v(s0, vParams, features)\n",
    "            \n",
    "            #update VFA\n",
    "            traceLength = length(stateTrace)\n",
    "            for sTrace in stateTrace\n",
    "                currentEst = v(sTrace, vParams, features)\n",
    "                grad = append!([1.0],[features[i](sTrace) for i in 1:numFeatures])\n",
    "                vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "                append!(paramHist,[vParams])\n",
    "            end\n",
    "            \n",
    "            #reset stateTrace\n",
    "            stateTrace = []\n",
    "            \n",
    "            #update flows and average\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "            \n",
    "        #if some action is optimal, simply update the state\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58458323",
   "metadata": {},
   "source": [
    "Performs SMARVI with a given fixed value of g0 for action selection. This prevents bad initial estimates of g from severely impacting the algorithm, but restricts the policy space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1840b7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarvi_g0 (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in the continuous time setting, approximating E(h(s')) using all possible transitions, and controlling action selection using some fixed g0\n",
    "function smarvi_g0(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features, g0; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optAandV = smarActionAndVFromVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, vParams, features, g0)\n",
    "        \n",
    "        bestA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        if bestA == zeros(Int64,N)\n",
    "            bestV = optV + g0*t - g*t - v(s0, vParams,features)\n",
    "        else\n",
    "            bestV = v(s - bestA, vParams, features) - v(s0, vParams,features)\n",
    "        end \n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25861988",
   "metadata": {},
   "source": [
    "Similar to regular SMARVI, but only using the BAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "318f0267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviBAS (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI with BAS in the continuous time setting, approximating E(h(s')) using all possible transitions\n",
    "function smarviBAS(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000, forceActive = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        tPassive = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*tPassive\n",
    "        \n",
    "        testA = faAction(s)\n",
    "        tActive = sojournTime(s, testA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        testV = instantCostCont(s,testA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,testA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*tActive\n",
    "        \n",
    "        if testV <= optV\n",
    "            optV = testV\n",
    "            optA = testA\n",
    "        end\n",
    "        \n",
    "        #Ignore passive action for broken network\n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64, N)\n",
    "            optV = testV\n",
    "            optA = testA\n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV - v(s0, vParams,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d439d00",
   "metadata": {},
   "source": [
    "Similar to regular SMARVI, but where flows are assumes to be passed to the VFA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0daaef33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviFlows (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version of smarvi where flows are passed to features\n",
    "function smarviFlows(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    flows0 = copy(flows)\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContFlows(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t\n",
    "        \n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                \n",
    "                if vParams[1] + sum(vParams[i+1]*features[i](s-a, flows) for i in 1:numFeatures) <= optV\n",
    "                    optV = vParams[1] + sum(vParams[i+1]*features[i](s-a, flows) for i in 1:numFeatures)\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #Fix random link if optA is passive for [3,3,...,3]\n",
    "        if s == fill(3,N) && optA == zeros(Int64, N)\n",
    "            optA[1] = 1\n",
    "            optV = v(s-optA, flows, vParams, features)\n",
    "            \n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    testV = v(s-a, flows, vParams, features)\n",
    "                    if testV <= optV\n",
    "                        optV = testV\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        if bestA == zeros(Int64,N)\n",
    "            bestV = optV - v(s0, flows0, vParams,features)\n",
    "        else\n",
    "            bestV = optV - v(s0, flows0, vParams,features)\n",
    "        end \n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s, flows) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s, flows) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8365b78",
   "metadata": {},
   "source": [
    "## e-greedy SMARVI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f3cba33",
   "metadata": {},
   "source": [
    "Helper functions and main algorithm for e-greedy SMARVI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fd55c88",
   "metadata": {},
   "source": [
    "Samples a random feasible action for a state s of length N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2fd2e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "randomActionAllDamaged (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate random action\n",
    "function randomAction(s,N)\n",
    "    #deal with all-damaged case\n",
    "    if s == fill(3,N)\n",
    "        return randomActionAllDamaged(N)\n",
    "    end\n",
    "\n",
    "    damaged = [0]\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            append!(damaged, [i])\n",
    "        end\n",
    "    end\n",
    "            \n",
    "    choice = sample(damaged)\n",
    "    optA = zeros(Int64, N)\n",
    "    if choice == 0\n",
    "        return optA\n",
    "    else\n",
    "        optA[choice] = 1\n",
    "        return optA\n",
    "    end\n",
    "end\n",
    "\n",
    "#calculate random action for [3,3...,3] state\n",
    "function randomActionAllDamaged(N)\n",
    "    choice = sample(1:N)\n",
    "    a = zeros(Int64, N)\n",
    "    a[choice] = 1\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48f72466",
   "metadata": {},
   "source": [
    "Performs an e-greedy version of SMARVI, with e_n = b/b+n for some given b. Allows SMARVI to perform some exploratory actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a38d016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarvi_epsGreedy (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in the continuous time setting, approximating E(h(s')) using all possible transitions\n",
    "#actions are choosen via e-greedy action selection, where a random action is chosen with probability b/b+n\n",
    "function smarvi_epsGreedy(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; b = 1.0, printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate e-greedy action\n",
    "        if rand(Uniform(0,1)) <= b/(b + n) \n",
    "            optA = randomAction(s,N)\n",
    "            if optA == zeros(Int64, N)\n",
    "                t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "                optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t\n",
    "            else\n",
    "                optV = v(s-optA, vParams, features)\n",
    "            end\n",
    "        else                \n",
    "            optAandV = smarActionAndVFromVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, vParams, features, g)\n",
    "        \n",
    "            optA = optAandV[1]\n",
    "            optV = optAandV[2]\n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV - v(s0, vParams,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eaa235",
   "metadata": {},
   "source": [
    "# Pre-requisite Functions for Exact DP on Homogeneous Problems "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7b7c104",
   "metadata": {},
   "source": [
    "Helper functions for Homogeneous Exact DP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1801225",
   "metadata": {},
   "source": [
    "Calculates instant cost for homogeneous problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22678b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instantCostHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instant cost function strictly for homogeneous problem\n",
    "function instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    #immediate change\n",
    "    i1Prime = i1 - a\n",
    "    i2Prime = i2 + a\n",
    "    \n",
    "    #if no links are healthy, return \n",
    "    if N - i1 - i2 == 0\n",
    "        return (beta*c1 + r*i2Prime)*del\n",
    "    end\n",
    "    \n",
    "    \n",
    "    return (beta*c0 + r*i2Prime)*del\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94e504b7",
   "metadata": {},
   "source": [
    "Given state (i_1, i_2) and action a, calculates the expected next value function after one timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a17eacf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates E(h(s')) from s,a strictly for a homogeneous problem\n",
    "function expectedNextValueHomog(i1,i2, h, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    #immediate change\n",
    "    i1Prime = i1 - a\n",
    "    i2Prime = i2 + a\n",
    "    thisH = h[i1+1,i2+1]\n",
    "    \n",
    "    #if all are damaged\n",
    "    if i1Prime == N\n",
    "        return thisH\n",
    "    end\n",
    "    \n",
    "    #if none are healthy\n",
    "    if N - i1 - i2 == 0\n",
    "        return thisH + tau(i2Prime)*del*(h[i1Prime+1,i2Prime-1+1] - thisH) + i2Prime*del*alpha_r*(h[i1Prime+1+1, i2Prime-1+1] - thisH)\n",
    "    end\n",
    "    \n",
    "    #if none are repairing\n",
    "    if i2Prime == 0\n",
    "        return thisH + (beta*alpha_d + (N - i1 - i2)*alpha_r)*del*(h[i1Prime+1+1,i2Prime+1] - thisH)\n",
    "    end\n",
    "    \n",
    "    return thisH + (beta*alpha_d + (N - i1 - i2)*alpha_r)*del*(h[i1Prime+1+1,i2Prime+1] - thisH) + i2Prime*alpha_r*del*(h[i1Prime+1+1,i2Prime-1+1] - thisH) + tau(i2Prime)*del*(h[i1Prime+1,i2Prime-1+1] - thisH)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68c7af12",
   "metadata": {},
   "source": [
    "Given state (i_1,i_2) and value function h, calculates and returns the best action for the state using full expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "beeb2b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates the exact PI action strictly for a homogeneous problem\n",
    "function piActionHomog(i1, i2, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del; forceActive = false)\n",
    "    if i1 == 0\n",
    "        return 0\n",
    "    end\n",
    "    \n",
    "    if i1 == N && forceActive\n",
    "        optA = 1\n",
    "        optH = instantCostHomog(i1,i2,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "        for a in 2:i1\n",
    "            testH = instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "            if testH <= optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "        return optA\n",
    "    end\n",
    "    \n",
    "    optA = 0\n",
    "    optH = instantCostHomog(i1,i2,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    for a in 1:i1\n",
    "        testH = instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "        if testH <= optH\n",
    "            optA = a\n",
    "            optH = testH\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71928099",
   "metadata": {},
   "source": [
    "Similar to above, but uses the approximation Q(s,a) = h(s+a) for a!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b58a1177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionHomogApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates the approx PI action based on instantaneous approximation, strictly for a homogeneous problem\n",
    "function piActionHomogApprox(i1, i2, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g; forceActive = false)\n",
    "    #deal with \"nothing damaged\" edge case\n",
    "    if i1 == 0\n",
    "        return 0\n",
    "    end\n",
    "    \n",
    "    #deal with \"everything damaged\" edge case\n",
    "    if i1 == N && forceActive\n",
    "        optA = 1\n",
    "        optH = h[i1-optA+1,i2+optA+1]\n",
    "        for a in 2:i1\n",
    "            testH = h[i1-a+1,i2+a+1]\n",
    "            if testH <= optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "        return optA\n",
    "    end\n",
    "    \n",
    "    optA = 0\n",
    "    optH = instantCostHomog(i1,i2,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) - g*del\n",
    "    for a in 1:i1\n",
    "        testH = h[i1-a+1,i2+a+1]\n",
    "        if testH <= optH\n",
    "            optA = a\n",
    "            optH = testH\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8ab05cf",
   "metadata": {},
   "source": [
    "Given h, constructs optimal policy using exact PI method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6335a065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates the exact PI policy strictly for a homogeneous problem\n",
    "function piPolicyHomog(h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del; forceActive = false)\n",
    "    policy = zeros(Int64, N+1, N+1)\n",
    "    for i1 in 0:N\n",
    "        for i2 in 0:(N - i1)\n",
    "            policy[i1+1,i2+1] = piActionHomog(i1, i2, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del; forceActive = forceActive)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34525984",
   "metadata": {},
   "source": [
    "Given h, constructs optimal policy using Q(s,a) = h(s,a) for a!=0 approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "404bfec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyHomogApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates the approx PI policy based on instantaneous approximation, strictly for a homogeneous problem\n",
    "function piPolicyHomogApprox(h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g; forceActive = false)\n",
    "    policy = zeros(Int64, N+1, N+1)\n",
    "    for i1 in 0:N\n",
    "        for i2 in 0:(N - i1)\n",
    "            policy[i1+1,i2+1] = piActionHomogApprox(i1, i2, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g; forceActive = forceActive)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "905b77bf",
   "metadata": {},
   "source": [
    "Constructs a h table from a VFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42156f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hFromVFAHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function hFromVFAHomog(N, params, features)\n",
    "    #construct hIn table\n",
    "    hIn = zeros(Float64, N+1, N+1)\n",
    "    for i1 in 0:N\n",
    "        for i2 in 0:(N - i1)\n",
    "            s = fill(1,N)\n",
    "            if i1 > 0\n",
    "                for i in 1:i1\n",
    "                    s[i] = 3\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            if i2 > 0\n",
    "                for i in (i1+1):(i1+i2)\n",
    "                    s[i] = 2\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            hIn[i1+1,i2+1] = v(s, params, features)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return hIn\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c11abe",
   "metadata": {},
   "source": [
    "# Exact DP for Homogeneous problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fc32308",
   "metadata": {},
   "source": [
    "Actual DP algorithms "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99f7e6cf",
   "metadata": {},
   "source": [
    "Given a h table, performs PE on PI policy derived from h, and returns g, h, n (number of iterations), and the PI policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc148338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a PI policy based on a given exact h function, strictly for a homogeneous problem \n",
    "function rpiHomog(N::Int64, hIn, alpha_d::Float64, alpha_r::Float64, beta::Float64, tau, c0::Float64, c1::Float64, r::Float64, epsilon::Float64; nMax = 0, delScale = 1, forceActive = false)\n",
    "    #calculate stepsize and initialise h,w,and policy vectors\n",
    "    del = 1/(delScale*(beta*alpha_d + N*alpha_r + tau(N)))\n",
    "    h = zeros(Float64, N+1, N+1)\n",
    "    w = zeros(Float64, N+1, N+1)\n",
    "    policy = piPolicyHomog(hIn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del; forceActive = forceActive)\n",
    "    n = 0\n",
    "    #repeat until epsilion-convergence or n = nMax\n",
    "    while true\n",
    "        n = n + 1\n",
    "        #calculate new w values\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                a = policy[i1+1,i2+1]\n",
    "                w[i1+1,i2+1] = instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        \n",
    "        #calculate new relative values\n",
    "        hNew = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                hNew[i1+1,i2+1] = w[i1+1,i2+1] - w[1,1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #check for convergence\n",
    "        deltas = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:N-i1\n",
    "                deltas[i1+1,i2+1] = hNew[i1+1,i2+1] - h[i1+1,i2+1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        h = hNew\n",
    "        if maximum(deltas) < epsilon || n == nMax\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    v = beta*c0*del + (beta*alpha_d + (N)*alpha_r)*del*h[1+1,0+1] + (1 - (beta*alpha_d + (N)*alpha_r)*del)*h[0+1,0+1]\n",
    "    \n",
    "    return v/del, h, n, policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b8046e6",
   "metadata": {},
   "source": [
    "Performs PE on the fully active policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e39012f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpeFAHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates the fully active policy, strictly for a homogeneous problem \n",
    "function rpeFAHomog(N::Int64, alpha_d::Float64, alpha_r::Float64, beta::Float64, tau, c0::Float64, c1::Float64, r::Float64, epsilon::Float64; nMax = 0, delScale = 1, forceActive = false)\n",
    "    #calculate stepsize and initialise h,w,and policy vectors\n",
    "    del = 1/(delScale*(beta*alpha_d + N*alpha_r + tau(N)))\n",
    "    h = zeros(Float64, N+1, N+1)\n",
    "    w = zeros(Float64, N+1, N+1)\n",
    "    n = 0\n",
    "    #repeat until epsilion-convergence or n = nMax\n",
    "    while true\n",
    "        n = n + 1\n",
    "        #calculate new w values\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                a = i1\n",
    "                w[i1+1,i2+1] = instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        \n",
    "        #calculate new relative values\n",
    "        hNew = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                hNew[i1+1,i2+1] = w[i1+1,i2+1] - w[1,1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #check for convergence\n",
    "        deltas = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:N-i1\n",
    "                deltas[i1+1,i2+1] = hNew[i1+1,i2+1] - h[i1+1,i2+1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        h = hNew\n",
    "        if maximum(deltas) < epsilon || n == nMax\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    v = beta*c0*del + (beta*alpha_d + (N)*alpha_r)*del*h[1+1,0+1] + (1 - (beta*alpha_d + (N)*alpha_r)*del)*h[0+1,0+1]\n",
    "    \n",
    "    return v/del, h, n\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c051660",
   "metadata": {},
   "source": [
    "Similar to rpiHomog, but uses Q(s,a) = h(s,a) approximation for PI step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "964c01ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiHomogApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates an approximate PI policy based on a given exact h function and instananeous actions, strictly for a homogeneous problem \n",
    "function rpiHomogApprox(N::Int64, hIn, alpha_d::Float64, alpha_r::Float64, beta::Float64, tau, c0::Float64, c1::Float64, r::Float64, epsilon::Float64, g::Float64; nMax = 0, delScale = 1, forceActive = false)\n",
    "    #calculate stepsize and initialise h,w,and policy vectors\n",
    "    del = 1/(delScale*(beta*alpha_d + N*alpha_r + tau(N)))\n",
    "    h = zeros(Float64, N+1, N+1)\n",
    "    w = zeros(Float64, N+1, N+1)\n",
    "    policy = piPolicyHomogApprox(hIn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g; forceActive = forceActive)\n",
    "    n = 0\n",
    "    #repeat until epsilion-convergence or n = nMax\n",
    "    while true\n",
    "        n = n + 1\n",
    "        #calculate new w values\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                a = policy[i1+1,i2+1]\n",
    "                w[i1+1,i2+1] = instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        \n",
    "        #calculate new relative values\n",
    "        hNew = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                hNew[i1+1,i2+1] = w[i1+1,i2+1] - w[1,1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #check for convergence\n",
    "        deltas = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:N-i1\n",
    "                deltas[i1+1,i2+1] = hNew[i1+1,i2+1] - h[i1+1,i2+1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        h = hNew\n",
    "        if maximum(deltas) < epsilon || n == nMax\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    v = beta*c0*del + (beta*alpha_d + (N)*alpha_r)*del*h[1+1,0+1] + (1 - (beta*alpha_d + (N)*alpha_r)*del)*h[0+1,0+1]\n",
    "    \n",
    "    return v/del, h, n, policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15e1c1de",
   "metadata": {},
   "source": [
    "Similar to above, but uses VFA as input h, and uses Q(s,a) = h(s+a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7146cc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiHomogVFAApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a PI policy based on a given VFA, using instananeous approximation, strictly for a homogeneous problem \n",
    "function rpiHomogVFAApprox(N::Int64, params, features, alpha_d::Float64, alpha_r::Float64, beta::Float64, tau, c0::Float64, c1::Float64, r::Float64, epsilon::Float64, g::Float64; nMax = 0, delScale = 1, forceActive = false)\n",
    "    \n",
    "    #construct hIn table\n",
    "    hIn = zeros(Float64, N+1, N+1)\n",
    "    for i1 in 0:N\n",
    "        for i2 in 0:(N - i1)\n",
    "            s = fill(1,N)\n",
    "            if i1 > 0\n",
    "                for i in 1:i1\n",
    "                    s[i] = 3\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            if i2 > 0\n",
    "                for i in (i1+1):(i1+i2)\n",
    "                    s[i] = 2\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            hIn[i1+1,i2+1] = v(s, params, features)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #run standard function\n",
    "    return rpiHomogApprox(N, hIn, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon, g; nMax = nMax, delScale = delScale, forceActive = forceActive)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54d455db",
   "metadata": {},
   "source": [
    "Similar to above, WITHOUT Q(s,a) = h(s+a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04dc9704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiHomogVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a PI policy based on a given VFA, strictly for a homogeneous problem \n",
    "function rpiHomogVFA(N::Int64, params, features, alpha_d::Float64, alpha_r::Float64, beta::Float64, tau, c0::Float64, c1::Float64, r::Float64, epsilon::Float64; nMax = 0, delScale = 1, forceActive = false)\n",
    "    \n",
    "    #construct hIn table\n",
    "    hIn = zeros(Float64, N+1, N+1)\n",
    "    for i1 in 0:N\n",
    "        for i2 in 0:(N - i1)\n",
    "            s = fill(1,N)\n",
    "            if i1 > 0\n",
    "                for i in 1:i1\n",
    "                    s[i] = 3\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            if i2 > 0\n",
    "                for i in (i1+1):(i1+i2)\n",
    "                    s[i] = 2\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            hIn[i1+1,i2+1] = v(s, params, features)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #run standard function\n",
    "    return rpiHomog(N, hIn, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = nMax, delScale = delScale, forceActive = forceActive)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "690683ed",
   "metadata": {},
   "source": [
    "Performs RVIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "939c3f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rviHomog (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs RVIA \n",
    "function rviHomog(N::Int64, alpha_d::Float64, alpha_r::Float64, beta::Float64, tau, c0::Float64, c1::Float64, r::Float64, epsilon::Float64; nMax = 0, delScale = 1, forceActive = false)\n",
    "    #calculate stepsize and initialise h,w,and policy vectors\n",
    "    del = 1/(delScale*(beta*alpha_d + N*alpha_r + tau(N)))\n",
    "    h = zeros(Float64, N+1, N+1)\n",
    "    w = zeros(Float64, N+1, N+1)\n",
    "    n = 0\n",
    "    #repeat until epsilion-convergence or n = nMax\n",
    "    while true\n",
    "        n = n + 1\n",
    "        #calculate new w values\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                a = piActionHomog(i1, i2, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del; forceActive = forceActive)\n",
    "                w[i1+1,i2+1] = instantCostHomog(i1,i2,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueHomog(i1,i2, h, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        \n",
    "        #calculate new relative values\n",
    "        hNew = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:(N - i1)\n",
    "                hNew[i1+1,i2+1] = w[i1+1,i2+1] - w[1,1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #check for convergence\n",
    "        deltas = zeros(Float64, N+1, N+1)\n",
    "        for i1 in 0:N\n",
    "            for i2 in 0:N-i1\n",
    "                deltas[i1+1,i2+1] = hNew[i1+1,i2+1] - h[i1+1,i2+1]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        h = hNew\n",
    "        if maximum(deltas) < epsilon || n == nMax\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    v = beta*c0*del + (beta*alpha_d + (N)*alpha_r)*del*h[1+1,0+1] + (1 - (beta*alpha_d + (N)*alpha_r)*del)*h[0+1,0+1]\n",
    "    \n",
    "    return v/del, h, n\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b3849",
   "metadata": {},
   "source": [
    "# Pre-requisite Functions for Exact DP on Inhomogeneous Problems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1e53ece",
   "metadata": {},
   "source": [
    "Helper functions for inhomogeneous exact DP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14ea586f",
   "metadata": {},
   "source": [
    "Given a state-action pair and h, calculates the expected next value of the value function after one timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d45adbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueExact (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates E(h(s')) from s,a using exact h table\n",
    "function expectedNextValueExact(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, h)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    runningTotal = 0.0\n",
    "    runningTotalProb = 0.0\n",
    "    \n",
    "    flows = zeros(Float64, N)\n",
    "    if healthy > 0\n",
    "        #otherwise, find best route, and return\n",
    "        bestCost = maximum(c0) + 1\n",
    "        usedLink = 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 1 && c0[k] < bestCost\n",
    "                bestCost = c0[k]\n",
    "                usedLink = k\n",
    "            end \n",
    "        end\n",
    "        \n",
    "        flows[usedLink] = beta\n",
    "    end\n",
    "    \n",
    "    \n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*h[sNext]\n",
    "        runningTotalProb += flows[k]*alpha_d[k]*del\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            runningTotal += alpha_r[k]*del*h[sNext]\n",
    "            runningTotalProb += alpha_r[k]*del\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                runningTotal += (tau(repair)/repair)*del*h[sNext]\n",
    "                runningTotalProb += (tau(repair)/repair)*del\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal + (1 - runningTotalProb)*h[sPrime]\n",
    "end "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f2dad95",
   "metadata": {},
   "source": [
    "Given a state and a h table, calculates the PI action for s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b71c013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionExact (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI action using exact h table\n",
    "function piActionExact(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    if s == fill(1, N)\n",
    "        return zeros(Int64, N)\n",
    "    end\n",
    "    \n",
    "    optA = zeros(Int64, N)\n",
    "    optH = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del,h)\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64,N)\n",
    "            a[i] = 1\n",
    "            testH = instantCostUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del,h)\n",
    "            if testH < optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2cb0d43",
   "metadata": {},
   "source": [
    "Similar to above, but uses the approximation Q(s,a) = h(s+a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17b1bbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionExactInstant (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI action using exact h table, based off instananeous actions\n",
    "function piActionExactInstant(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    if s == fill(1, N)\n",
    "        return zeros(Int64, N)\n",
    "    end\n",
    "    \n",
    "    optA = zeros(Int64, N)\n",
    "    optH = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del,h) - g*del\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64,N)\n",
    "            a[i] = 1\n",
    "            testH = h[s-a]\n",
    "            if testH < optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7eb2f91a",
   "metadata": {},
   "source": [
    "Similar to above, but uses a VFA instead of a h table, WITHOUT Q(s,a) = h(s+a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bab1aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI action using a VFA\n",
    "function piActionVFA(s, params, features, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    if s == fill(1, N)\n",
    "        return zeros(Int64, N)\n",
    "    end\n",
    "    \n",
    "    optA = zeros(Int64, N)\n",
    "    optH = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del,params,features)\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64,N)\n",
    "            a[i] = 1\n",
    "            testH = instantCostUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s, a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del,params,features)\n",
    "            if testH < optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4096d38",
   "metadata": {},
   "source": [
    "Similar to above, WITH Q(s,a) = h(s,a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "604bf237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionVFAInstant (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI action using a VFA and instananeous actions\n",
    "function piActionVFAInstant(s, params, features, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    if s == fill(1, N)\n",
    "        return zeros(Int64, N)\n",
    "    end\n",
    "    \n",
    "    optA = zeros(Int64, N)\n",
    "    optH = instantCostUnif(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueUnif(s, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del,params,features) - g*del\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64,N)\n",
    "            a[i] = 1\n",
    "            testH = v(s-a,params,features)\n",
    "            if testH < optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "884618d7",
   "metadata": {},
   "source": [
    "Constructs PI policy using h table and no approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1dfe8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyExact (generic function with 1 method)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI policy using exact h table\n",
    "function piPolicyExact(h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    policy = Dict()\n",
    "    stateSpace = enumerateStates(N)\n",
    "    for s in stateSpace\n",
    "        policy[s] = piActionExact(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    end\n",
    "    \n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8842b6de",
   "metadata": {},
   "source": [
    "Constructs PI policy using h table and Q(s,a) = h(s+a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bfb9dcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyExactInstant (generic function with 1 method)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI policy using exact h table, interpretting h with instant actions\n",
    "function piPolicyExactInstant(h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    policy = Dict()\n",
    "    stateSpace = enumerateStates(N)\n",
    "    for s in stateSpace\n",
    "        policy[s] = piActionExactInstant(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    end\n",
    "    \n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44d2fa28",
   "metadata": {},
   "source": [
    "Constructs PI policy using VFA and no approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72a89a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI policy from a VFA\n",
    "function piPolicyVFA(params, features, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    policy = Dict()\n",
    "    stateSpace = enumerateStates(N)\n",
    "    for s in stateSpace\n",
    "        policy[s] = piActionVFA(s, params, features, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    end\n",
    "    \n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d72cd38",
   "metadata": {},
   "source": [
    "Constructs PI policy using VFA and Q(s,a) = h(s+a) approximation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14bba9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyVFAInstant (generic function with 1 method)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI policy from a VFA, using instant actions to interpret h\n",
    "function piPolicyVFAInstant(params, features, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    policy = Dict()\n",
    "    stateSpace = enumerateStates(N)\n",
    "    for s in stateSpace\n",
    "        policy[s] = piActionVFAInstant(s, params, features, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    end\n",
    "    \n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f8cc379",
   "metadata": {},
   "source": [
    "Constructs h table from VFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28d6c8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hFromVFAInhomog (generic function with 1 method)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function hFromVFAInhomog(N, params, features)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    h = Dict()\n",
    "    for s in stateSpace\n",
    "        h[s] = v(s, params. features)\n",
    "    end\n",
    "\n",
    "    return h\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7172ee4",
   "metadata": {},
   "source": [
    "# Exact DP for Inhomogeneous Problem (using exact h or VFA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43e2ee1b",
   "metadata": {},
   "source": [
    "DP algorithms for inhomogeneous problem\n",
    "\n",
    "Note that throughout when we talk of a Q(s,a) = h(s+a) approximation, this only refers to action selection and not update rules, and excludes a=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2225adc2",
   "metadata": {},
   "source": [
    "Given an explicit policy table, performs PE, returns g, h and n (# of iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b118e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpe (generic function with 1 method)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs PE using exact policy table\n",
    "function rpe(N, policy, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    #calculate stepsize and initialise h,w,and policy dictionaries\n",
    "    del = 1/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    h = Dict()\n",
    "    w = Dict()\n",
    "    stateSpace = enumerateStates(N)\n",
    "    actionSpace = enumerateRestrictedActions(N)\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "        w[s] = 0.0\n",
    "    end\n",
    "    s0  = fill(1, N)\n",
    "    n = 0\n",
    "    \n",
    "    #do until max iterations met or epsilon convergence\n",
    "    while true\n",
    "        n = n + 1\n",
    "        #find updates for every state\n",
    "        for s in stateSpace\n",
    "            a = policy[s]\n",
    "            w[s] = instantCostUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, h)\n",
    "        end\n",
    "        \n",
    "        #calculate relative values and delta\n",
    "        delta = 0\n",
    "        for s in stateSpace\n",
    "            update = w[s] - w[s0]\n",
    "            if delta < update - h[s] || delta == 0\n",
    "                delta = update - h[s]\n",
    "            end\n",
    "            \n",
    "            h[s] = update\n",
    "        end\n",
    "        \n",
    "        #stopping condition\n",
    "        if delta < epsilon || n == nMax\n",
    "            break\n",
    "        end\n",
    "        \n",
    "        if printProgress && n%modCounter == 0\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    a = zeros(Int64, N)\n",
    "    g = instantCostUnif(s0,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s0,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, h) - h[s0]\n",
    "    \n",
    "    return g/del, h, n\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1ad5a2b",
   "metadata": {},
   "source": [
    "Given a h table, constructs PI policy and performs PE, returning g, h, n and the PI policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c57636f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiExact (generic function with 1 method)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs one round of exact PI and PE using exact h table\n",
    "function rpiExact(N, hIn, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    del = 1/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    policy = piPolicyExact(hIn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "    output = rpe(N, policy, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = nMax, delScale = delScale, printProgress = printProgress, modCounter = modCounter)\n",
    "    return output[1], output[2], output[3], policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec78eb5a",
   "metadata": {},
   "source": [
    "Similar to above, but uses Q(s,a) = h(s+a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "266027ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiExactInstant (generic function with 1 method)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs one round of exact PI and PE using exact h table, using instant actions to interpet h\n",
    "function rpiExactInstant(N, hIn, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon, g; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    #calculate stepsize and initialise h,w,and policy dictionaries\n",
    "    del = 1/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    policy = piPolicyExactInstant(hIn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del, g)\n",
    "    output = rpe(N, policy, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = nMax, delScale = delScale, printProgress = printProgress, modCounter = modCounter)\n",
    "    return output[1], output[2], output[3], policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0aa6660e",
   "metadata": {},
   "source": [
    "Performs PE on the fully active policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f773f8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpeFA (generic function with 1 method)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs exact PE on the fully-active policy\n",
    "function rpeFA(N, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    policy = Dict()\n",
    "    for s in stateSpace\n",
    "        policy[s] = faAction(s)\n",
    "    end\n",
    "    \n",
    "    return rpe(N, policy, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = nMax, delScale = delScale, printProgress = printProgress, modCounter = modCounter)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c325a927",
   "metadata": {},
   "source": [
    "Performs PE on fully passive policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d304fb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpePassive (generic function with 1 method)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs exact PE on the passive policy\n",
    "function rpePassive(N, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    policy = Dict()\n",
    "    for s in stateSpace\n",
    "        policy[s] = zeros(Int64, N)\n",
    "    end\n",
    "    \n",
    "    return rpe(N, policy, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = nMax, delScale = delScale, printProgress = printProgress, modCounter = modCounter)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c45280",
   "metadata": {},
   "source": [
    "Given a VFA, constructs PI policy and performs PE, returning g, h, n and the PI policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ec6cacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs one round of exact PI and PE using VFA\n",
    "function rpiVFA(N, params, features, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    hIn = hFromVFAInhomog(N, params, features)\n",
    "    return rpiExact(N, hIn, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = nMax, delScale = delScale, printProgress = printProgress, modCounter = modCounter)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68209e10",
   "metadata": {},
   "source": [
    "Similar to above, but uses Q(s,a) = h(s+a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a19903b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpiVFAInstant (generic function with 1 method)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs one round of exact PI and PE using VFA and instantaneous actions to interpret h\n",
    "function rpiVFAInstant(N, params, features, g, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    hIn = hFromVFAInhomog(N, params, features)\n",
    "    return rpiExactInstant(N, hIn, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon, g; nMax = nMax, delScale = delScale, printProgress = printProgress, modCounter = modCounter)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b0b6c10",
   "metadata": {},
   "source": [
    "Performs RVIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d38fbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rvi (generic function with 1 method)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs RVIA\n",
    "function rvi(N, alpha_d, alpha_r, beta, tau, c0, c1, r, epsilon; nMax = 0, delScale = 1, printProgress = false, modCounter = 100)\n",
    "    #calculate stepsize and initialise h,w,and policy dictionaries\n",
    "    del = 1/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    h = Dict()\n",
    "    w = Dict()\n",
    "    policy = Dict()\n",
    "    stateSpace = enumerateStates(N)\n",
    "    actionSpace = enumerateRestrictedActions(N)\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "        w[s] = 0.0\n",
    "        policy[s] = zeros(Int64,N)\n",
    "    end\n",
    "    s0  = fill(1, N)\n",
    "    n = 0\n",
    "    \n",
    "    #do until max iterations met or epsilon convergence\n",
    "    while true\n",
    "        n = n + 1\n",
    "        #find updates for every state\n",
    "        for s in stateSpace\n",
    "            a = piActionExact(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "            w[s] = instantCostUnif(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, h)\n",
    "        end\n",
    "        \n",
    "        #calculate relative values and delta\n",
    "        delta = 0\n",
    "        for s in stateSpace\n",
    "            update = w[s] - w[s0]\n",
    "            if delta < update - h[s] || delta == 0\n",
    "                delta = update - h[s]\n",
    "            end\n",
    "            \n",
    "            h[s] = update\n",
    "        end\n",
    "        \n",
    "        #stopping condition\n",
    "        if delta < epsilon || n == nMax\n",
    "            break\n",
    "        end\n",
    "        \n",
    "        if printProgress && n%modCounter == 0\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    a = zeros(Int64, N)\n",
    "    g = instantCostUnif(s0,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del) + expectedNextValueExact(s0,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, h) - h[s0]\n",
    "    \n",
    "    return g/del, h, n, policy\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb424a1e",
   "metadata": {},
   "source": [
    "# Evaluation via simulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bcbbb37",
   "metadata": {},
   "source": [
    "Various evaluation functions for approximating g"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ef631d9",
   "metadata": {},
   "source": [
    "Takes a trained VFA and learns g, using g also for control, starting from state s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8261907a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluation (generic function with 1 method)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a VFA via PI using simulation\n",
    "function gEvaluation(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, vParams, features; printProgress = false, modCounter = 100000, forceActive = false, printState = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if printState\n",
    "            println(s)\n",
    "        end\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t\n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64,N)\n",
    "            optA[1] = 1\n",
    "            t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            optV = v(s-optA, vParams, features)\n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #update state and flows\n",
    "        bestA = optA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(runningTotals, [runningTotal])\n",
    "        append!(times,[timePassed])\n",
    "        append!(gs,[g])\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "320c63e1",
   "metadata": {},
   "source": [
    "Similar to above, but starting from a given state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9fd18438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationFromS (generic function with 1 method)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a VFA using simulation\n",
    "function gEvaluationFromS(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, vParams, features; printProgress = false, modCounter = 100000, forceActive = false, stateTrace = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    flowResult = calculateFlows(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    flows = flowResult[1]\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if stateTrace\n",
    "            println(s)\n",
    "        end \n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t\n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64,N)\n",
    "            optA[1] = 1\n",
    "            t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            optV = v(s-optA, vParams, features)\n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #update state and flows\n",
    "        bestA = optA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(gs,[g])\n",
    "        append!(runningTotals, [runningTotal])\n",
    "        append!(times,[timePassed])\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ceb6a98",
   "metadata": {},
   "source": [
    "Similar to gEvaluation, but uses a fixed g0 for control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba5ce5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluation_g0 (generic function with 1 method)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a VFA using simulation\n",
    "function gEvaluation_g0(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, vParams, features, g0; printProgress = false, modCounter = 100000, forceActive = false, stateTrace = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if stateTrace\n",
    "            println(s)\n",
    "        end\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g0*t\n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64,N)\n",
    "            optA[1] = 1\n",
    "            optV = v(s-optA, vParams, features)\n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #update state and flows\n",
    "        bestA = optA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(gs,[g])\n",
    "        append!(runningTotals, [runningTotal])\n",
    "        append!(times,[timePassed])\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3cd3eae",
   "metadata": {},
   "source": [
    "Similar to above, but starts from a given state s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b85a37ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationFromS_g0 (generic function with 1 method)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a VFA using simulation\n",
    "function gEvaluationFromS_g0(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, vParams, features, g0; printProgress = false, modCounter = 100000, forceActive = false, stateTrace = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    flowResult = calculateFlows(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    flows = flowResult[1]\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if stateTrace\n",
    "            println(s)\n",
    "        end \n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g0*t\n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64,N)\n",
    "            optA[1] = 1\n",
    "            t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            optV = v(s-optA, vParams, features)\n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #update state and flows\n",
    "        bestA = optA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(runningTotals, [runningTotal])\n",
    "        append!(times,[timePassed])\n",
    "        append!(gs,[g])\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6636431",
   "metadata": {},
   "source": [
    "Finds the g of the fully active policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33be91d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationFA (generic function with 1 method)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates the FA policy\n",
    "function gEvaluationFA(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax; printProgress = false, modCounter = 100000, forceActive = false, stateTrace = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if stateTrace\n",
    "            println(s)\n",
    "        end\n",
    "        \n",
    "        #formulate FA action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #update state, flows and g\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(gs,[g])\n",
    "        append!(runningTotals, [runningTotal])\n",
    "        append!(times,[timePassed])\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d651dbd0",
   "metadata": {},
   "source": [
    "Similar to gEvaluation, but only uses the BAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8ba1023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationBAS (generic function with 1 method)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a VFA via PI using simulation\n",
    "function gEvaluationBAS(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, vParams, features; printProgress = false, modCounter = 100000, forceActive = false, stateTrace = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if stateTrace\n",
    "            println(s)\n",
    "        end\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        tPassive = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*tPassive\n",
    "        \n",
    "        testA = faAction(s)\n",
    "        tActive = sojournTime(s, testA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        testV = instantCostCont(s,testA, N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,testA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*tActive\n",
    "        if testV <= optV\n",
    "            optV = testV\n",
    "            optA = testA\n",
    "        end\n",
    "        \n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64,N)\n",
    "            optA = testA\n",
    "            optV = testV\n",
    "        end\n",
    "        \n",
    "        #update state and flows\n",
    "        bestA = optA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            append!(runningTotals, [runningTotal])\n",
    "            timePassed += time\n",
    "            append!(times,[timePassed])\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(gs,[g])\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4d81acf",
   "metadata": {},
   "source": [
    "Similar to gEvaluation_g0, but assumes that flows are passed to the VFA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "862863bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluation_g0_flows (generic function with 1 method)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates a VFA using simulation\n",
    "function gEvaluation_g0_flows(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, vParams, features, g0; printProgress = false, modCounter = 100000, forceActive = false, stateTrace = false)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    runningTotals = [0.0]\n",
    "    times = [0.0]\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        if stateTrace\n",
    "            println(s)\n",
    "        end\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optA = zeros(Int64,N)\n",
    "        t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "        optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContFlows(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g0*t\n",
    "        for i in 1:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                vTest = v(s-a, flows, vParams, features)\n",
    "                if vTest <= optV\n",
    "                    optV = vTest\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if forceActive && s == fill(3,N) && optA == zeros(Int64,N)\n",
    "            optA[1] = 1\n",
    "            optV = v(s-optA, flows, vParams, features)\n",
    "            for i in 2:N\n",
    "                if s[i] == 3\n",
    "                    a = zeros(Int64, N)\n",
    "                    a[i] = 1\n",
    "                    vTest = v(s-a, flows, vParams, features)\n",
    "                    if vTest <= optV\n",
    "                        optV = vTest\n",
    "                        optA = a\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #update state and flows\n",
    "        bestA = optA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            s = result[1]\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(gs,[g])\n",
    "        append!(runningTotals, [runningTotal])\n",
    "        append!(times,[timePassed])\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return gs, runningTotals, times\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88307ffe",
   "metadata": {},
   "source": [
    "# APE on Fully Active Policy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7749e9f",
   "metadata": {},
   "source": [
    "Performs APE on the Fully Active Policy using each of the four approaches to estimating a VFA (mixes of uniform/smar and simulated-next-state/expectation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "666815fa",
   "metadata": {},
   "source": [
    "Returns the FA action for a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1319dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faAction (generic function with 1 method)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computes the Fully Active action for a given state s\n",
    "function faAction(s)\n",
    "    N = length(s)\n",
    "    a = zeros(Int64,N)\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a[i] = 1\n",
    "        end\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9168d0b",
   "metadata": {},
   "source": [
    "Evaluates the FA policy using a VFA and uniformisation, and update targets c + V(s') - gt, where s' is simulated next state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e894ba39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apeFAUnifApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs APE of FA policy in uniformised setting, approximating E(h(s')) for update targets using just h(s'), where s' is the next simulated state\n",
    "function apeFAUnifApprox(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; delScale = 1.0, printProgress = false, modCounter = 100000, forceActive = false)\n",
    "    #initialise\n",
    "    del = 1.0/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        c = instantCostUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "        bestV = c + v(sPrime, vParams, features) - v(s0, vParams,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = v(s, vParams, features)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        c = result[2]\n",
    "        s = sPrime\n",
    "        flows = result[3]\n",
    "        g += (1/n)*(c - g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e96581e",
   "metadata": {},
   "source": [
    "Similar to above, but uses full expectation for updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ccde3d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apeFAUnifFull (generic function with 1 method)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs APE of FA policy in uniformised setting, approximating E(h(s')) using all possible transitions\n",
    "function apeFAUnifFull(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; delScale = 1.0, printProgress = false, modCounter = 100000, forceActive = false)\n",
    "    #initialise\n",
    "    del = 1.0/(delScale*(beta*sum(alpha_d) + sum(alpha_r) + tau(N)))\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        c = instantCostUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, del)\n",
    "        bestV = c + expectedNextValueUnif(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, del, vParams, features) - v(s0, vParams,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = v(s, vParams, features)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        c = result[2]\n",
    "        s = sPrime\n",
    "        flows = result[3]\n",
    "        g += (1/n)*(c - g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d7bdaa9",
   "metadata": {},
   "source": [
    "Performs SMARPE on FA policy, with update target c + V(s') - gt where s' is the next simulated state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd7df03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeFAApprox (generic function with 1 method)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs SMARPE on FA policy, approximating E(h(s')) as h(s') where s' is the next simulated state\n",
    "function smarpeFAApprox(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        if bestA == zeros(Int64,N)\n",
    "            c = instantCostCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            t = sojournTime(s, bestA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            bestV = c + v(sPrime, vParams, features) - g*t - v(s0, vParams,features)\n",
    "        else\n",
    "            bestV = v(s - bestA, vParams, features) - v(s0, vParams,features)\n",
    "        end \n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af073bb3",
   "metadata": {},
   "source": [
    "Similar to above, but uses full expectation in update target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8865800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeFAFull (generic function with 1 method)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smarpeFAFull(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        if bestA == zeros(Int64,N)\n",
    "            c = instantCostCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            t = sojournTime(s, bestA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            bestV = c + expectedNextValueCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t - v(s0, vParams,features)\n",
    "        else\n",
    "            bestV = v(s - bestA, vParams, features) - v(s0, vParams,features)\n",
    "        end\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = vParams[1] + sum(vParams[i+1]*features[i](s) for i in 1:numFeatures)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[vParams])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ceece53",
   "metadata": {},
   "source": [
    "Similar to smarpeFAApprox, but incorporates state trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b68eb6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeFAApproxST (generic function with 1 method)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs APE on FA policy in continuous time setting, approximating E(h(s')) as h(s') where s' is the next simulated state\n",
    "#Also incorporates the state trace when actions are taken\n",
    "function smarpeFAApproxST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    stateTrace = []\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        #update state trace\n",
    "        append!(stateTrace, [s])\n",
    "        \n",
    "        #formulate action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #for passive action, do proper update\n",
    "        if bestA == zeros(Int64,N)\n",
    "            #find value of v^n\n",
    "            c = instantCostCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            t = sojournTime(s, bestA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            bestV = c + v(sPrime, vParams, features) - g*t - v(s0, vParams,features)\n",
    "\n",
    "            #update VFA\n",
    "            for sTrace in stateTrace\n",
    "                currentEst = v(sTrace, vParams, features)\n",
    "                grad = append!([1.0],[features[i](sTrace) for i in 1:numFeatures])\n",
    "                vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "                append!(paramHist,[vParams])\n",
    "            end\n",
    "            \n",
    "            stateTrace = []\n",
    "            \n",
    "            #update g, state, and flows\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "\n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "            \n",
    "        #for other action, simply update state and move on\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c19d280d",
   "metadata": {},
   "source": [
    "Similar to above, but uses full expectation for update target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47d8caaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeFAFullST (generic function with 1 method)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs APE on FA policy in continuous time setting, approximating E(h(s')) using all possible transitions\n",
    "#Also incorporates the state trace when actions are taken\n",
    "function smarpeFAFullST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, vParams, features; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    stateTrace = []\n",
    "    flows = zeros(N)\n",
    "    paramHist = [vParams]\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        #update state trace\n",
    "        append!(stateTrace, [s])\n",
    "        \n",
    "        #formulate action\n",
    "        bestA = faAction(s)\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #for passive action, do proper update\n",
    "        if bestA == zeros(Int64,N)\n",
    "            #find value of v^n\n",
    "            c = instantCostCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            t = sojournTime(s, bestA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            bestV = c + expectedNextValueCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, vParams, features) - g*t - v(s0, vParams,features)\n",
    "\n",
    "            #update VFA\n",
    "            for sTrace in stateTrace\n",
    "                currentEst = v(sTrace, vParams, features)\n",
    "                grad = append!([1.0],[features[i](sTrace) for i in 1:numFeatures])\n",
    "                vParams = vParams + (stepsize)*(bestV - currentEst)*grad\n",
    "                append!(paramHist,[vParams])\n",
    "            end\n",
    "            \n",
    "            stateTrace = []\n",
    "            \n",
    "            #update g, state, and flows\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "\n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "            \n",
    "        #for other action, simply update state and move on\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return vParams, paramHist, g\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f5b89",
   "metadata": {},
   "source": [
    "# SMARPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54992054",
   "metadata": {},
   "source": [
    "## Semi-Markov Approximate Relative Policy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be11b69",
   "metadata": {},
   "source": [
    "- SMARPE takes some trained VFA as input, and seeks to learn the associated long run cost g and the value function of the policy derived from the given VFA\n",
    "\n",
    "- Standard SMARPE uses the online training value of g for action selection, allowing the policy to vary throughout training\n",
    "\n",
    "- SMARPE_g0 takes a pre-learned value of g0 to be used for action selection, keeping the policy constant throughout. This value of g0 might be taken directly from SMARVI or from some gEval function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffc082",
   "metadata": {},
   "source": [
    "Worth also discussing is the exact behaviour of the gEval functions.\n",
    "\n",
    "- Standard gEval simply evaluates a VFA, and learns g throughout. In turn, this value of g is used for action selection, so the policy may vary throughout evaluation.\n",
    "\n",
    "- gEval_g0 evaluates a VFA-g0 pair, keeping the policy constant throughout. It may be good practice to always follow standard gEval with gEval_g0, due to the lack of policy variability.\n",
    "\n",
    "gEval functions are the part that actually calculate the PI actions based on the VFAs derived from SMARPE."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a0e5de3",
   "metadata": {},
   "source": [
    "Given a VFA-g pair, evaluates the PI policy derived from the pair via a new VFA with the same architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6082e341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpe (generic function with 1 method)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs APE in the continuous time setting, approximating E(h(s')) using all possible transitions, and with a fixed g0 for action selection\n",
    "function smarpe(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, stepsize, paramsIn, paramsOut, features, g0; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    numFeatures = length(features)\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    paramHist = [paramsOut]\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        optAandV = smarActionAndVFromVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, paramsIn, features, g0)\n",
    "        \n",
    "        bestA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #recalculate optA in terms of new VFA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, paramsOut, features) - g*t\n",
    "        else\n",
    "            optV = v(s - bestA, paramsOut, features)\n",
    "        end \n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV - v(s0, paramsOut ,features)\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = v(s, paramsOut, features)\n",
    "        grad = append!([1.0],[features[i](s) for i in 1:numFeatures])\n",
    "        paramsOut = paramsOut + (stepsize)*(bestV - currentEst)*grad\n",
    "        append!(paramHist,[paramsOut])\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        append!(gs, [g])\n",
    "        \n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return paramsOut, paramHist, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38d24567",
   "metadata": {},
   "source": [
    "# Tabular SMARVI and gEval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b101ab9",
   "metadata": {},
   "source": [
    "Tabular SMARVI algorithms (non e-greedy, e-greedy, and e-greedt with state trace), associated gEval function, and helper functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a829f15",
   "metadata": {},
   "source": [
    "Given a state s, its flows, and a h-g pair, return the optimal action and V value for s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d500f4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarActionAndVFromTable (generic function with 1 method)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smarActionAndVFromTable(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, h, g)\n",
    "    #find optimal action\n",
    "    optA = zeros(Int64,N)\n",
    "    t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "        \n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64, N)\n",
    "            a[i] = 1\n",
    "               \n",
    "            if h[s-a] <= optV\n",
    "                optV = h[s-a]\n",
    "                optA = a\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "        \n",
    "    #Fix choose optimal non-passive action if state is [3,3,...,3]\n",
    "    if s == fill(3,N) && optA == zeros(Int64, N)\n",
    "        optA[1] = 1\n",
    "        optV = h[s-optA]\n",
    "            \n",
    "        for i in 2:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "                testV = h[s-a]\n",
    "                if testV <= optV\n",
    "                    optV = testV\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return optA, optV\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94fd262e",
   "metadata": {},
   "source": [
    "Given a state-action pair and a h table, compute the next expected h value given that a transition has occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd0e5b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueContTab (generic function with 1 method)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculates E(h(s')) given a state-action pair, and tabular h\n",
    "function expectedNextValueContTab(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h)\n",
    "    del = sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    #different treatment for all-damaged state\n",
    "    if sPrime == fill(3,N)\n",
    "        return h[sPrime]\n",
    "    end\n",
    "    \n",
    "    runningTotal = 0\n",
    "    \n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*h[sNext]\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            runningTotal += alpha_r[k]*del*h[sNext]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                runningTotal += (tau(repair)/repair)*del*h[sNext]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal\n",
    "end   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e27d5cd6",
   "metadata": {},
   "source": [
    "Tabular version of SMARVI, with no state trace or e-greedy actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6447836b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviTab (generic function with 1 method)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in the continuous time setting, approximating E(h(s')) using all possible transitions\n",
    "#Uses tabular representation instead of VFA\n",
    "function smarviTab(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "\n",
    "    h = Dict()\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "    end\n",
    "    \n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #formulate optimal action\n",
    "        optAandV = smarActionAndVFromTable(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, h, g)\n",
    "        bestA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        if bestA == zeros(Int64,N)\n",
    "            bestV = optV - h[s0]\n",
    "        else\n",
    "            bestV = optV - h[s0]\n",
    "        end \n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = h[s]\n",
    "        h[s] += (b/(b + numVisits[s]))*(bestV - currentEst)\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2833561",
   "metadata": {},
   "source": [
    "e-greedy version of the above. e can be chosen to depend on the state or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf860122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviTab_epsGreedy (generic function with 1 method)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performs AVI in the continuous time setting, approximating E(h(s')) using all possible transitions\n",
    "#Uses tabular representation instead of VFA and e-greedy action selection\n",
    "function smarviTab_epsGreedy(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; printProgress = false, modCounter = 100000, stateDepEpsilon = false)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "\n",
    "    h = Dict()\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "    end\n",
    "    \n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #formulate optimal action\n",
    "        optAandV = smarActionAndVFromTable(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, h, g)\n",
    "        optA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        epsilon = c/(c + n)\n",
    "        if stateDepEpsilon\n",
    "            epsilon = c/(c + numVisits[s])\n",
    "        end\n",
    "\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            optA = randomAction(s, N)\n",
    "            if optA == zeros(Int64, N)\n",
    "                t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "                optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "            else\n",
    "                optV = h[s - optA]\n",
    "            end    \n",
    "        end \n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV - h[s0]\n",
    "        \n",
    "        #update VFA\n",
    "        currentEst = h[s]\n",
    "        h[s] += (b/(b + numVisits[s]))*(bestV - currentEst)\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6f7777e",
   "metadata": {},
   "source": [
    "Similar to above, but incorporates the state trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de3e948e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviTab_epsGreedyST (generic function with 1 method)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uses tabular representation instead of VFA, e-greedy action selection, and state trace \n",
    "function smarviTab_epsGreedyST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; printProgress = false, modCounter = 100000, stateDepEpsilon = false)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateTrace = []\n",
    "    h = Dict()\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "    end\n",
    "    \n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #formulate optimal action\n",
    "        optAandV = smarActionAndVFromTable(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, h, g)\n",
    "        optA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #choose epsilon\n",
    "        epsilon = c/(c + n)\n",
    "        if stateDepEpsilon\n",
    "            epsilon = c/(c + numVisits[s])\n",
    "        end\n",
    "\n",
    "        #choose actual action\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            optA = randomAction(s, N)\n",
    "            if optA == zeros(Int64, N)\n",
    "                t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "                optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "            else\n",
    "                optV = h[s - optA]\n",
    "            end    \n",
    "        end \n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV - h[s0]\n",
    "        \n",
    "        #update VFA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            for st in stateTrace\n",
    "                currentEst = h[st]\n",
    "                h[st] += (b/(b + numVisits[st]))*(bestV - currentEst)\n",
    "            end\n",
    "            stateTrace = []\n",
    "        end\n",
    "\n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5619d4e1",
   "metadata": {},
   "source": [
    "Similar to above (so e-greedy and state trace), but uses a moving average window to approximate g, allowing old estimates to be discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e0f86bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviTabMA (generic function with 1 method)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tabular SMARVI with moving average online approximation for g, e-greedy action selection, and state trace\n",
    "function smarviTabMA(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; window = 2500000, printProgress = false, modCounter = 100000, stateDepEpsilon = false)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    totalCosts = [0.0]\n",
    "    timePassed = 0.0\n",
    "    totalTimes = [0.0]\n",
    "    lenTotals = 1\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateTrace = []\n",
    "    h = Dict()\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "    end\n",
    "    \n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #formulate optimal action\n",
    "        optAandV = smarActionAndVFromTable(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, h, g)\n",
    "        optA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        \n",
    "        #choose epsilon\n",
    "        epsilon = c/(c + n)\n",
    "        if stateDepEpsilon\n",
    "            epsilon = c/(c + numVisits[s])\n",
    "        end\n",
    "\n",
    "        #choose actual action\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            optA = randomAction(s, N)\n",
    "            if optA == zeros(Int64, N)\n",
    "                t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "                optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "            else\n",
    "                optV = h[s - optA]\n",
    "            end    \n",
    "        end \n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV - h[s0]\n",
    "        \n",
    "        #update VFA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            for st in stateTrace\n",
    "                currentEst = h[st]\n",
    "                h[st] += (b/(b + numVisits[st]))*(bestV - currentEst)\n",
    "            end\n",
    "            stateTrace = []\n",
    "        end\n",
    "\n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            push!(totalCosts, runningTotal)\n",
    "            push!(totalTimes, timePassed)\n",
    "            lenTotals += 1\n",
    "            if lenTotals <= window\n",
    "                g = runningTotal/timePassed\n",
    "            else\n",
    "                g = (runningTotal - totalCosts[lenTotals - window])/(timePassed - totalTimes[lenTotals - window])\n",
    "            end\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0ca583e",
   "metadata": {},
   "source": [
    "Given a state, a h table and g, return the PI action for s. Uses the Q(s,a) = h(s+a) approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a89e1d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piActionExactCont (generic function with 1 method)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates PI action using exact h table, based off continuous model\n",
    "function piActionExactCont(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, g)\n",
    "    if s == fill(1, N)\n",
    "        return zeros(Int64, N)\n",
    "    end\n",
    "    \n",
    "    flows = calculateFlows(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r)[1]\n",
    "    \n",
    "    optA = zeros(Int64, N)\n",
    "    t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    optH = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s, optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows,h) - g*t\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64,N)\n",
    "            a[i] = 1\n",
    "            testH = h[s-a]\n",
    "            if testH < optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if s == fill(3,N) && optA == zeros(Int64, N)\n",
    "        optA[1] = 1\n",
    "        optH = h[s - optA]\n",
    "\n",
    "        for i in 2:N\n",
    "            a = zeros(Int64, N)\n",
    "            a[i] = 1\n",
    "            testH = h[s - a]\n",
    "            if testH < optH\n",
    "                optA = a\n",
    "                optH = testH\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return optA\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5696a2b2",
   "metadata": {},
   "source": [
    "Constructs a PI policy using the above method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "47ec161d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyExactCont (generic function with 1 method)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function piPolicyExactCont(h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, g)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    policy = Dict()\n",
    "    for s in stateSpace\n",
    "        policy[s] = piActionExactCont(s, h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, g)\n",
    "    end\n",
    "\n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c7cc371",
   "metadata": {},
   "source": [
    "Given a h table and fixed g0, approximates the g of the PI policy derived using the above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "161485ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationTab (generic function with 1 method)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gEvaluationTab(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, h, g0; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    println(\"State Space Completed\")\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    policy = piPolicyExactCont(h, N, alpha_d, alpha_r, beta, tau, c0, c1, r, g0)\n",
    "    println(\"Policy Completed\")\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        bestA = policy[s]\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return g, gs, policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6efb11fd",
   "metadata": {},
   "source": [
    "Returns an array of feasible actions for N-dim state s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c00dff36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enumerateFeasibleActions (generic function with 1 method)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function enumerateFeasibleActions(s,N)\n",
    "    actionSpace = []\n",
    "    if s == fill(3, N)\n",
    "        for i in 1:N\n",
    "            a = zeros(Int64, N)\n",
    "            a[i] = 1\n",
    "            push!(actionSpace, a)\n",
    "        end\n",
    "        return actionSpace\n",
    "    end\n",
    "\n",
    "    push!(actionSpace, zeros(Int64,N))\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64, N)\n",
    "            a[i] = 1\n",
    "            push!(actionSpace, a)\n",
    "        end\n",
    "    end\n",
    "    return actionSpace\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "884ee22f",
   "metadata": {},
   "source": [
    "# SMART Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc90c99f",
   "metadata": {},
   "source": [
    "Tabular SMART algorithm, associated gEvaluation function, and helper functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6bef550",
   "metadata": {},
   "source": [
    "Given a state and a q-table, return optimal action and associated Q-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b86ab9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actionFromQTab (generic function with 1 method)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function actionFromQTab(s, N, q)\n",
    "    feasibleActions = enumerateFeasibleActions(s,N)\n",
    "\n",
    "    #formulate action\n",
    "    optA = zeros(Int64, N)\n",
    "    if s == fill(3,N)\n",
    "        optA[1] = 1\n",
    "    end\n",
    "    optQ = q[s,optA]\n",
    "    for a in feasibleActions\n",
    "        testQ = q[s,a]\n",
    "        if testQ < optQ\n",
    "            optQ = testQ\n",
    "            optA = a\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return optA, optQ\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93d0c99a",
   "metadata": {},
   "source": [
    "Construct policy using above method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "233657b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piPolicyExactContQ (generic function with 1 method)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function piPolicyExactContQ(q, N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    policy = Dict()\n",
    "    for s in stateSpace\n",
    "        policy[s] = actionFromQTab(s, N, q)[1]\n",
    "    end\n",
    "\n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bcb0dda",
   "metadata": {},
   "source": [
    "Performs SMART, using a state-action trace and e-greedy action selection, where e can be chosen to depend on the state or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f7db3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smartTab (generic function with 1 method)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smartTab(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; printProgress = false, modCounter = 100000, stateDepEpsilon = false)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    actionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateActionTrace = []\n",
    "    q = Dict()\n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        for a in enumerateFeasibleActions(s,N)\n",
    "            q[s,a] = 0.0\n",
    "        end\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    optAandQ = actionFromQTab(s, N, q)\n",
    "    optA = optAandQ[1]\n",
    "    optQ = optAandQ[2]\n",
    "\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        numVisits[s] += 1\n",
    "        \n",
    "        optFlag = true\n",
    "        \n",
    "        #choose e-greedy action\n",
    "        epsilon = c/(c + n)\n",
    "        if stateDepEpsilon\n",
    "            epsilon = c/(c + numVisits[s])\n",
    "        end\n",
    "\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            optA = randomAction(s, N)\n",
    "            optQ = q[s,optA]\n",
    "            optFlag = false\n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        push!(stateActionTrace, (s,bestA))\n",
    "\n",
    "        nextOptA = zeros(Int64, N)\n",
    "        nextOptQ = 0.0\n",
    "        #update q, flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            #simulate transition\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "  \n",
    "            #update g if optimal action taken\n",
    "            if optFlag\n",
    "                runningTotal += c\n",
    "                timePassed += time\n",
    "                g = runningTotal/timePassed\n",
    "            end\n",
    "\n",
    "            #find next optimal action and q value\n",
    "            nextOptAandQ = actionFromQTab(sPrime, N, q)\n",
    "            nextOptA = nextOptAandQ[1]\n",
    "            nextOptQ = nextOptAandQ[2]\n",
    "\n",
    "            for saPair in stateActionTrace\n",
    "                st = saPair[1]\n",
    "                q[saPair] += (b/(b + numVisits[st]))*(c + nextOptQ - g*time - q[saPair])\n",
    "            end\n",
    "\n",
    "            stateActionTrace = []\n",
    "        else\n",
    "            sPrime = s - bestA\n",
    "\n",
    "            nextOptAandQ = actionFromQTab(sPrime, N, q)\n",
    "            nextOptA = nextOptAandQ[1]\n",
    "            nextOptQ = nextOptAandQ[2]\n",
    "        end\n",
    "        \n",
    "        s = sPrime\n",
    "        optA = nextOptA\n",
    "        optQ = nextOptQ\n",
    "\n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return q, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb19c603",
   "metadata": {},
   "source": [
    "Taking a Q table as input, formulates the associated policy and simulates it to approximate g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0943848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationTabQ (generic function with 1 method)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gEvaluationTabQ(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, q; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    println(\"State Space Completed\")\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    \n",
    "    policy = piPolicyExactContQ(q, N)\n",
    "    println(\"Policy Completed\")\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action\n",
    "        bestA = policy[s]\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #update flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return g, gs, policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15b7f9ed",
   "metadata": {},
   "source": [
    "On-Policy equivalent of SMART, using next chosen action instead of next optimal action for the update target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "433d3d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smartOnPolicyTab (generic function with 1 method)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smartOnPolicyTab(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; printProgress = false, modCounter = 100000, stateDepEpsilon = false)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    actionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateActionTrace = []\n",
    "    q = Dict()\n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        for a in enumerateFeasibleActions(s,N)\n",
    "            q[s,a] = 0.0\n",
    "        end\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #choose only action for s = s0\n",
    "    optA = zeros(Int64, N)\n",
    "    optQ = q[s,optA]\n",
    "    optFlag = true\n",
    "\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        numVisits[s] += 1\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        push!(stateActionTrace, (s,bestA))\n",
    "\n",
    "        nextOptA = zeros(Int64, N)\n",
    "        nextOptQ = 0.0\n",
    "\n",
    "        #update q, flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            #simulate transition\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "  \n",
    "            #update g\n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "\n",
    "            #find next e-greedy action and q value\n",
    "            #find optimal action and q-value\n",
    "            optFlag = true\n",
    "            nextOptAandQ = actionFromQTab(sPrime, N, q)\n",
    "            nextOptA = nextOptAandQ[1]\n",
    "            nextOptQ = nextOptAandQ[2]\n",
    "\n",
    "            #choose epsilon\n",
    "            epsilon = c/(c + n)\n",
    "            \n",
    "            if stateDepEpsilon\n",
    "                epsilon = c/(c + numVisits[sPrime])\n",
    "            end\n",
    "\n",
    "            #select random action with probability epsilon\n",
    "            if rand(Uniform(0,1)) < epsilon\n",
    "                nextOptA = randomAction(sPrime, N)\n",
    "                nextOptQ = q[sPrime,nextOptA]\n",
    "                optFlag = false\n",
    "            end\n",
    "            \n",
    "            for saPair in stateActionTrace\n",
    "                st = saPair[1]\n",
    "                q[saPair] += (b/(b + numVisits[st]))*(c + nextOptQ - g*time - q[saPair])\n",
    "            end\n",
    "\n",
    "            stateActionTrace = []\n",
    "        else\n",
    "            sPrime = s - bestA\n",
    "\n",
    "            optFlag = true\n",
    "            nextOptAandQ = actionFromQTab(sPrime, N, q)\n",
    "            nextOptA = nextOptAandQ[1]\n",
    "            nextOptQ = nextOptAandQ[2]\n",
    "\n",
    "            #choose epsilon\n",
    "            epsilon = c/(c + n)\n",
    "            \n",
    "            if stateDepEpsilon\n",
    "                epsilon = c/(c + numVisits[sPrime])\n",
    "            end\n",
    "\n",
    "            #select random action with probability epsilon\n",
    "            if rand(Uniform(0,1)) < epsilon\n",
    "                nextOptA = randomAction(sPrime, N)\n",
    "                nextOptQ = q[sPrime,nextOptA]\n",
    "                optFlag = false\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        s = sPrime\n",
    "        optA = nextOptA\n",
    "        optQ = nextOptQ\n",
    "\n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return q, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70994d31",
   "metadata": {},
   "source": [
    "Version of SMART using moving average window to approximate g, discarding older data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8fa137b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smartTabMA (generic function with 1 method)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SMART with an MA approximation for g\n",
    "function smartTabMA(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; window = 1000000, printProgress = false, modCounter = 100000, stateDepEpsilon = false)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    actionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    totalCosts = [0.0]\n",
    "    lenTotalCosts = 1\n",
    "    totalTimes = [0.0]\n",
    "    lenTotal = 1\n",
    "    stateActionTrace = []\n",
    "    q = Dict()\n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        for a in enumerateFeasibleActions(s,N)\n",
    "            q[s,a] = 0.0\n",
    "        end\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    optAandQ = actionFromQTab(s, N, q)\n",
    "    optA = optAandQ[1]\n",
    "    optQ = optAandQ[2]\n",
    "\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        numVisits[s] += 1\n",
    "        \n",
    "        optFlag = true\n",
    "        \n",
    "        #choose e-greedy action\n",
    "        epsilon = c/(c + n)\n",
    "        if stateDepEpsilon\n",
    "            epsilon = c/(c + numVisits[s])\n",
    "        end\n",
    "\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            optA = randomAction(s, N)\n",
    "            optQ = q[s,optA]\n",
    "            optFlag = false\n",
    "        end\n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        push!(stateActionTrace, (s,bestA))\n",
    "\n",
    "        nextOptA = zeros(Int64, N)\n",
    "        nextOptQ = 0.0\n",
    "        #update q, flows and average\n",
    "        if bestA == zeros(Int64, N)\n",
    "            #simulate transition\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "\n",
    "            c = result[2]\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "  \n",
    "            #update g if optimal action taken\n",
    "            if optFlag\n",
    "                runningTotal += c\n",
    "                timePassed += time\n",
    "                push!(totalCosts, runningTotal)               \n",
    "                push!(totalTimes, timePassed)\n",
    "                lenTotal += 1\n",
    "                if lenTotal <= window\n",
    "                    g = runningTotal/timePassed\n",
    "                else\n",
    "                    g = (runningTotal - totalCosts[lenTotal - window])/(timePassed - totalTimes[lenTotal - window])\n",
    "                end\n",
    "            end\n",
    "\n",
    "            #find next optimal action and q value\n",
    "            nextOptAandQ = actionFromQTab(sPrime, N, q)\n",
    "            nextOptA = nextOptAandQ[1]\n",
    "            nextOptQ = nextOptAandQ[2]\n",
    "\n",
    "            for saPair in stateActionTrace\n",
    "                st = saPair[1]\n",
    "                q[saPair] += (b/(b + numVisits[st]))*(c + nextOptQ - g*time - q[saPair])\n",
    "            end\n",
    "\n",
    "            stateActionTrace = []\n",
    "        else\n",
    "            sPrime = s - bestA\n",
    "\n",
    "            nextOptAandQ = actionFromQTab(sPrime, N, q)\n",
    "            nextOptA = nextOptAandQ[1]\n",
    "            nextOptQ = nextOptAandQ[2]\n",
    "        end\n",
    "        \n",
    "        s = sPrime\n",
    "        optA = nextOptA\n",
    "        optQ = nextOptQ\n",
    "\n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return q, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "199fc408",
   "metadata": {},
   "source": [
    "# Tabular SMARPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "29ea47f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeTabST (generic function with 1 method)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SMARPE with tabular representation instead of VFA, and state trace \n",
    "function smarpeTabST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, hIn, g0, nMax, b; copyH = false, printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    policy = piPolicyExactCont(hIn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, g0)\n",
    "    println(\"Policy Constructed\")\n",
    "    stateTrace = []\n",
    "    \n",
    "    h = Dict()\n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        if copyH\n",
    "            h[s] = hIn[s]\n",
    "        else\n",
    "            h[s] = 0.0\n",
    "        end\n",
    "        \n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of SMARPE\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #formulate optimal action\n",
    "        optA = policy[s]\n",
    "        if optA == zeros(Int64, N)\n",
    "            t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "        end\n",
    "\n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #if action is passive, update VFA across state trace and simulate the next state, and update g. otherwise, simply update current state\n",
    "        if bestA == zeros(Int64, N)\n",
    "            bestV = optV - h[s0]\n",
    "            for st in stateTrace\n",
    "                currentEst = h[st]\n",
    "                h[st] += (b/(b + numVisits[st]))*(bestV - currentEst)\n",
    "            end\n",
    "            stateTrace = []\n",
    "\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9483ef10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeTabStochST (generic function with 1 method)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uses tabular representation instead of VFA, e-greedy action selection, and state trace \n",
    "function smarpeTabStochST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateTrace = []\n",
    "    \n",
    "    h = Dict()\n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        h[s] = 0.0\n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of SMARPE\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #choose random action\n",
    "        optA = randomAction(s,N)\n",
    "        if optA == zeros(Int64, N)\n",
    "            t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "        end\n",
    "\n",
    "        bestA = optA\n",
    "        \n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #if action is passive, update VFA across state trace and simulate the next state, and update g. otherwise, simply update current state\n",
    "        if bestA == zeros(Int64, N)\n",
    "            bestV = optV - h[s0]\n",
    "            for st in stateTrace\n",
    "                currentEst = h[st]\n",
    "                h[st] += (b/(b + numVisits[st]))*(bestV - currentEst)\n",
    "            end\n",
    "            stateTrace = []\n",
    "\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2da93d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarpeTabST_epsSoft_onPolicy (generic function with 1 method)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tabular SMARPE with state trace using e-soft policy\n",
    "function smarpeTabST_epsSoft_onPolicy(N,alpha_d, alpha_r, beta, tau, c0, c1, r, hIn, g0, nMax, b, c; copyH = false, printProgress = false, modCounter = 100000, stateDepEpsilon = true)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    stateSpace = enumerateStates(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    policy = piPolicyExactCont(hIn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, g0)\n",
    "    println(\"Policy Constructed\")\n",
    "    stateTrace = []\n",
    "    \n",
    "    h = Dict()\n",
    "    numVisits = Dict()\n",
    "    for s in stateSpace\n",
    "        if copyH\n",
    "            h[s] = hIn[s]\n",
    "        else\n",
    "            h[s] = 0.0\n",
    "        end\n",
    "        \n",
    "        numVisits[s] = 0\n",
    "    end\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    #do nMax iterations of SMARPE\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        numVisits[s] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #formulate action\n",
    "        optA = policy[s]\n",
    "        optV = 0.0\n",
    "        if optA == zeros(Int64, N)\n",
    "            t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "            optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "        end\n",
    "\n",
    "        #e-greedy action\n",
    "        bestA = optA\n",
    "        epsilon = c/(c + n)\n",
    "        if stateDepEpsilon\n",
    "            epsilon = c/(c + numVisits[s])\n",
    "        end\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            bestA = randomAction(s,N)\n",
    "            if bestA == zeros(Int64, N)\n",
    "                t = sojournTime(s, bestA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "                optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContTab(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, h) - g*t\n",
    "            end\n",
    "        end\n",
    "\n",
    "        #find simulated next state\n",
    "        result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "        sPrime = result[1]\n",
    "        \n",
    "        #if action is passive, update VFA across state trace and simulate the next state, and update g. otherwise, simply update current state\n",
    "        if bestA == zeros(Int64, N)\n",
    "            bestV = optV - h[s0]\n",
    "            for st in stateTrace\n",
    "                currentEst = h[st]\n",
    "                h[st] += (b/(b + numVisits[st]))*(bestV - currentEst)\n",
    "            end\n",
    "            stateTrace = []\n",
    "\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return h, g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe61cfb6",
   "metadata": {},
   "source": [
    "# New Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2411428a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subStates (generic function with 1 method)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns substates of edges in an array, and state of destination node\n",
    "function subStates(s, N, flows)\n",
    "    sis = []\n",
    "    sn = 0\n",
    "    for i in 1:N\n",
    "        if s[i] == 2 || s[i] == 3\n",
    "            push!(sis, s[i])\n",
    "        elseif flows[i] == 0\n",
    "            push!(sis, 0)\n",
    "        else\n",
    "            push!(sis, 1)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if flows == fill(0.0, N)\n",
    "        sn = 1\n",
    "    end\n",
    "    \n",
    "    return sis, sn\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b40410e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v (generic function with 4 methods)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates v from seperate ve and vn tables\n",
    "function v(s::Vector{Int64}, N::Int64, flows::Vector{Float64}, ve::Dict, vn::Dict)\n",
    "    substates = subStates(s, N, flows)\n",
    "    sis = substates[1]\n",
    "    sn = substates[2]\n",
    "\n",
    "    v = 0.0\n",
    "    for i in 1:N\n",
    "        si = sis[i]\n",
    "        v += ve[i,si]\n",
    "    end\n",
    "\n",
    "    v += vn[sn]\n",
    "\n",
    "    return v\n",
    "end\n",
    "\n",
    "function v(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "    flowsAndCost = calculateFlows(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r)\n",
    "    return v(s, N, flowsAndCost[1], ve, vn)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bdcbb3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedNextValueContNewVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculates E(h(s')) given a state-action pair, and VFA from ve and vn tables\n",
    "function expectedNextValueContNewVFA(s,a,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, ve, vn)\n",
    "    del = sojournTime(s, a, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    #immediate change\n",
    "    sPrime = s - a\n",
    "    healthy = sum(i == 1 for i in sPrime)\n",
    "    repair = sum(i == 2 for i in sPrime)\n",
    "    damaged = sum(i == 3 for i in sPrime)\n",
    "    \n",
    "    #different treatment for all-damaged state\n",
    "    if sPrime == fill(3,N)\n",
    "        return v(sPrime,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "    end\n",
    "    \n",
    "    runningTotal = 0\n",
    "    \n",
    "    #demand degs\n",
    "    for k in 1:N\n",
    "        sNext = copy(sPrime)\n",
    "        sNext[k] = 3\n",
    "        runningTotal += flows[k]*alpha_d[k]*del*v(sNext,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "    end\n",
    "    \n",
    "    #rare degs\n",
    "    for k in 1:N\n",
    "        if sPrime[k] != 3\n",
    "            sNext = copy(sPrime)\n",
    "            sNext[k] = 3\n",
    "            runningTotal += alpha_r[k]*del*v(sNext,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #repairs\n",
    "    if repair > 0\n",
    "        for k in 1:N\n",
    "            if sPrime[k] == 2\n",
    "                sNext = copy(sPrime)\n",
    "                sNext[k] = 1\n",
    "                runningTotal += (tau(repair)/repair)*del*v(sNext,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return runningTotal\n",
    "end   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e63f3219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarActionAndVFromNewVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function smarActionAndVFromNewVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn, g)\n",
    "    #find optimal action\n",
    "    optA = zeros(Int64,N)\n",
    "    t = sojournTime(s, optA, flows, N, alpha_d, alpha_r, beta, tau)\n",
    "    optV = instantCostCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows) + expectedNextValueContNewVFA(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows, ve, vn) - g*t\n",
    "    zeroV = optV\n",
    "\n",
    "    for i in 1:N\n",
    "        if s[i] == 3\n",
    "            a = zeros(Int64, N)\n",
    "            a[i] = 1\n",
    "            \n",
    "            testV = v(s-a, N, flows, ve, vn)\n",
    "            if testV <= optV\n",
    "                optV = testV\n",
    "                optA = a\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "        \n",
    "    #Fix choose optimal non-passive action if state is [3,3,...,3]\n",
    "    if s == fill(3,N) && optA == zeros(Int64, N)\n",
    "        optA[1] = 1\n",
    "        optV = v(s-optA, N, flows, ve, vn)\n",
    "            \n",
    "        for i in 2:N\n",
    "            if s[i] == 3\n",
    "                a = zeros(Int64, N)\n",
    "                a[i] = 1\n",
    "\n",
    "                testV = v(s-a, N, flows, ve, vn)\n",
    "                if testV <= optV\n",
    "                    optV = testV\n",
    "                    optA = a\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return optA, optV, zeroV\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "66a7c3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updateVFA (generic function with 3 methods)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function updateVFA(s, substates, target, ve, vn, numVisitsE, numVisitsN, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "    currentEst = v(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "    sis = substates[1]\n",
    "    sn = substates[2]\n",
    "\n",
    "    for i in 1:N \n",
    "        si = sis[i]\n",
    "        ve[i, si] += (b/(b + numVisitsE[i, si]))*(target - currentEst)\n",
    "    end\n",
    "\n",
    "    vn[sn] += (b/(b + numVisitsN[sn]))*(target - currentEst)\n",
    "\n",
    "    return ve, vn\n",
    "end\n",
    "\n",
    "function updateVFA(s, substates, target, ve, vn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, stepsize)\n",
    "    currentEst = v(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "    sis = substates[1]\n",
    "    sn = substates[2]\n",
    "\n",
    "    for i in 1:N \n",
    "        si = sis[i]\n",
    "        ve[i, si] += stepsize*(target - currentEst)\n",
    "    end\n",
    "\n",
    "    vn[sn] += stepsize*(target - currentEst)\n",
    "\n",
    "    return ve, vn\n",
    "end\n",
    "\n",
    "function updateVFA(s, substates, target, ve, vn, n, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "    currentEst = v(s,N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn)\n",
    "    sis = substates[1]\n",
    "    sn = substates[2]\n",
    "\n",
    "    for i in 1:N \n",
    "        si = sis[i]\n",
    "        ve[i, si] += (b/(b + n))*(target - currentEst)\n",
    "    end\n",
    "\n",
    "    vn[sn] += (b/(b + n))*(target - currentEst)\n",
    "\n",
    "    return ve, vn\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "379e3f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smarviNewVFA_ST (generic function with 1 method)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uses new VFA architecture, e-greedy action selection, and state trace \n",
    "#stepsizeType options: \n",
    "# - varyByNumVisits: uses stepsize b/(b + numVisits)\n",
    "# - varyByIteration: uses stepsize b/(b + n) where n is the iteration modCounter\n",
    "# - constant: uses stepsize b\n",
    "function smarviNewVFA_ST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, b, c; stepsizeType = \"varyByNumVisits\", printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateTrace = []\n",
    "    \n",
    "    #initialise ve and vn tables\n",
    "    ve = Dict()\n",
    "    numVisitsE = Dict()\n",
    "    for i in 1:N\n",
    "        for si in 0:3\n",
    "            ve[i,si] = 0.0\n",
    "            numVisitsE[i,si] = 0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    vn = Dict()\n",
    "    numVisitsN = Dict()\n",
    "    for i in 0:1\n",
    "        vn[i] = 0.0\n",
    "        numVisitsN[i] = 0\n",
    "    end\n",
    "\n",
    "    vs0Hist = [0.0]\n",
    "\n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    \n",
    "    flows0 = copy(flows)\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #update numVisits\n",
    "        substates = subStates(s, N, flows)\n",
    "        sis = substates[1]\n",
    "        sn = substates[2]\n",
    "        for i in 1:N\n",
    "            numVisitsE[i,sis[i]] += 1\n",
    "        end\n",
    "\n",
    "        numVisitsN[sn] += 1\n",
    "\n",
    "        #update trace\n",
    "        push!(stateTrace, s)\n",
    "\n",
    "        #formulate optimal action and v value\n",
    "        optAandV = smarActionAndVFromNewVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn, g)\n",
    "        optA = optAandV[1]\n",
    "        optV = optAandV[2]\n",
    "        zeroV = optAandV[3]\n",
    "\n",
    "        #choose epsilon\n",
    "        epsilon = c/(c + n)\n",
    "\n",
    "        #if random action chosen, choose action action and v value\n",
    "        if rand(Uniform(0,1)) < epsilon\n",
    "            optA = randomAction(s, N)\n",
    "            if optA == zeros(Int64, N) \n",
    "                optV = zeroV\n",
    "            else \n",
    "                optV = v(s - optA, N, flows, ve, vn)\n",
    "            end \n",
    "        end \n",
    "        \n",
    "        bestA = optA\n",
    "        \n",
    "        #find value of v^n:\n",
    "        bestV = optV \n",
    "        \n",
    "        #update VFA\n",
    "        if bestA == zeros(Int64, N)\n",
    "            for st in stateTrace\n",
    "                if stepsizeType == \"varyByNumVisits\"\n",
    "                    ve,vn = updateVFA(st, substates, bestV, ve, vn, numVisitsE, numVisitsN, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "                elseif stepsizeType == \"constant\"\n",
    "                    ve,vn = updateVFA(st, substates, bestV, ve, vn, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "                elseif stepsizeType == \"varyByIteration\"\n",
    "                    ve,vn = updateVFA(st, substates, bestV, ve, vn, n, N, alpha_d, alpha_r, beta, tau, c0, c1, r, b)\n",
    "                else\n",
    "                    println(\"Invalid stepsize rule\")\n",
    "                    return 0\n",
    "                end\n",
    "\n",
    "                push!(vs0Hist, v(s0, N, flows0, ve, vn))\n",
    "            end\n",
    "            stateTrace = []\n",
    "        end\n",
    "\n",
    "        #update state, flows and g\n",
    "        if bestA == zeros(Int64, N)\n",
    "            #find simulated next state, cost, flows and sampled sojourn time\n",
    "            result = updateStateAndFlowsCont(s,bestA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - bestA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return ve, vn, g, gs, vs0Hist\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fba49dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gEvaluationNewVFA (generic function with 1 method)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gEvaluationNewVFA(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, ve, vn, g0; printProgress = false, modCounter = 100000)\n",
    "    #initialise\n",
    "    s = [1 for i in 1:N]\n",
    "    s0 = [1 for i in 1:N]\n",
    "    flows = zeros(N)\n",
    "    reducedActionSpace = enumerateRestrictedActions(N)\n",
    "    runningTotal = 0.0\n",
    "    timePassed = 0.0\n",
    "    g = 0.0\n",
    "    gs = [g]\n",
    "    stateTrace = []\n",
    "    \n",
    "    #initialise flows\n",
    "    bestCost = maximum(c0) + 1\n",
    "    bestLink = 0\n",
    "    for i in 1:N\n",
    "        if c0[i] < bestCost\n",
    "            bestCost = c0[i]\n",
    "            bestLink = i\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    flows[bestLink] = beta\n",
    "    #do nMax iterations of AVI\n",
    "    for n in 1:nMax\n",
    "        \n",
    "        #formulate optimal action and v value\n",
    "        optAandV = smarActionAndVFromNewVFA(s, flows, N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn, g)\n",
    "        optA = optAandV[1]\n",
    "\n",
    "        #update state, flows and g\n",
    "        if optA == zeros(Int64, N)\n",
    "            #find simulated next state, cost, flows and sampled sojourn time\n",
    "            result = updateStateAndFlowsCont(s,optA,N,alpha_d, alpha_r, beta, tau, c0, c1, r, flows)\n",
    "            sPrime = result[1]\n",
    "            c = result[2]\n",
    "            s = sPrime\n",
    "            flows = result[3]\n",
    "            time = result[4]\n",
    "            \n",
    "            runningTotal += c\n",
    "            timePassed += time\n",
    "            g = runningTotal/timePassed\n",
    "        else\n",
    "            s = s - optA\n",
    "        end\n",
    "        \n",
    "        push!(gs, g)\n",
    "        if printProgress == true && n%modCounter == 0\n",
    "            sleep(0.001)\n",
    "            println(n)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return g, gs\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b30394b",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9bce9bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 100.0\n",
       " 200.0\n",
       " 300.0\n",
       " 400.0\n",
       " 500.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "function tau(x)\n",
    "    return x\n",
    "end\n",
    "\n",
    "alpha_d = [0.01*i for i in 1:N]\n",
    "alpha_r = [0.001*i for i in 1:N] \n",
    "beta=10.0\n",
    "c0=[1.0*i for i in 1:N] \n",
    "c1=100.0\n",
    "r=[100.0*i for i in 1:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f00d0796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27.523593356932984"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nMax = 2000000\n",
    "resultNewVFA = smarviNewVFA_ST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, 100.0, 10.0; stepsizeType = \"varyByNumVisits\", printProgress = true, modCounter = 500000)\n",
    "resultNewVFA[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "443cd336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x000000008F5392E0>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = floor(Int64, nMax/10)\n",
    "PyPlot.plot(resultNewVFA[4][1:nMax])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b89a343",
   "metadata": {},
   "source": [
    "Not converged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e237426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3230922371202055e27\n",
      "-1.3221878468776487e27\n"
     ]
    }
   ],
   "source": [
    "ve = resultNewVFA[1]\n",
    "vn = resultNewVFA[2]\n",
    "println(v([1,1,1,1,1],N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn))\n",
    "println(v([3,3,3,3,3],N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3a80d675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 2 entries:\n",
       "  0 => -2.58585e26\n",
       "  1 => -1.85392e26"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "69284c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x0000000066733D90>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs0Hist = resultNewVFA[5]\n",
    "PyPlot.plot(vs0Hist[500000:nMax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "12456d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.17023950691293"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalNMax = 1000000\n",
    "g0 = resultNewVFA[3]\n",
    "gs = gEvaluationNewVFA(N,alpha_d, alpha_r, beta, tau, c0, c1, r, evalNMax, ve, vn, g0; printProgress = false, modCounter = 100000)\n",
    "gs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b45924c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x000000008F4C3C10>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PyPlot.plot(gs[2][100000:evalNMax])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a3e1fa1",
   "metadata": {},
   "source": [
    "## Constant Stepsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "52017ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n",
      "2500000\n",
      "3000000\n",
      "3500000\n",
      "4000000\n",
      "Complete\n",
      "26.570057230682146\n"
     ]
    }
   ],
   "source": [
    "nMax = 4000000\n",
    "resultNewVFA_CStep = smarviNewVFA_ST(N,alpha_d, alpha_r, beta, tau, c0, c1, r, nMax, 0.01, 10.0; stepsizeType = \"constant\", printProgress = true, modCounter = 500000)\n",
    "println(\"Complete\")\n",
    "println(resultNewVFA_CStep[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9197b38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x000000006605E7F0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PyPlot.plot(resultNewVFA_CStep[4][1:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "712a3b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x000000008F13FD30>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs0Hist = resultNewVFA_CStep[5]\n",
    "PyPlot.plot(vs0Hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fc6c2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-303.00214413340655\n",
      "909.8320858374173\n"
     ]
    }
   ],
   "source": [
    "ve = resultNewVFA_CStep[1]\n",
    "vn = resultNewVFA_CStep[2]\n",
    "println(v([1,1,1,1,1],N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn))\n",
    "println(v([3,3,3,3,3],N,alpha_d, alpha_r, beta, tau, c0, c1, r, ve, vn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d8219338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 2 entries:\n",
       "  0 => 45.5698\n",
       "  1 => 416.651"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8330a4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
